# MIT 6.824 Distributed Systems Spring 2022

## Introduction

### 课程的组成部分：

- Lectures
  - big ideas, paper discussion, lab guidance.will be video-taped, available online
- papers
  - there's a paper assigned for almost every lecture
      research papers, some classic, some new
      problems, ideas, implementation details, evaluation
      please read papers before class!
      each paper has a short question for you to answer 
      and we ask you to send us a question you have about the paper
      submit answer and question before start of lecture
- lab
  -  goal: deeper understanding of some important ideas
      goal: experience with distributed programming
      first lab is due a week from Friday
      one per week after that for a while
  - Lab 1: distributed big-data framework (like MapReduce)
    Lab 2: fault tolerance library using replication (Raft)
    Lab 3: a simple fault-tolerant database
    Lab 4: scalable database performance via sharding
- final Project
  - Optional final project at the end, in groups of 2 or 3.
      The final project substitutes for Lab 4.
      You think of a project and clear it with us.
      Code, short write-up, demo on last day.
- We grade the labs using a set of tests  we give you all the tests; none are secret

### 主要话题

> This is a course about infrastructure for applications.
>   * Storage.
>   * Communication.
>   * Computation.
>
> A big goal: hide the complexity of distribution from applications.
>
> Topic: fault tolerance
>   1000s of servers, big network -> always something broken
>     We'd like to hide these failures from the application.
>     "High availability": service continues despite failures
>   Big idea: replicated servers.
>     If one server crashes, can proceed using the other(s).
>     Labs 2 and 3
>
> Topic: consistency
>   General-purpose infrastructure needs well-defined behavior.
>     E.g. "Get(k) yields the value from the most recent Put(k,v)."
>   Achieving good behavior is hard!
>     "Replica" servers are hard to keep identical.
>
> Topic: performance
>   The goal: scalable throughput
>     Nx servers -> Nx total throughput via parallel CPU, disk, net.
>   Scaling gets harder as N grows:
>     Load imbalance.
>     Slowest-of-N latency.
>     Some things don't speed up with N: initialization, interaction.
>   Labs 1, 4
>
> Topic: tradeoffs
>   Fault-tolerance, consistency, and performance are enemies.
>   Fault tolerance and consistency require communication
>     e.g., send data to backup
>     e.g., check if my data is up-to-date
>     communication is often slow and non-scalable
>   Many designs provide only weak consistency, to gain speed.
>     e.g. Get() does *not* yield the latest Put()!
>     Painful for application programmers but may be a good trade-off.
>   We'll see many design points in the consistency/performance spectrum.
>
> Topic: implementation
>   RPC, threads, concurrency control, configuration.
>   The labs...
>
> This material comes up a lot in the real world.
>   All big web sites and cloud providers are expert at distributed systems.
>   Many big open source projects are built around these ideas.
>   We'll read multiple papers from industry.
>   And industry has adopted many ideas from academia.



# Lecture 1: Introduction

什么是分布式系统？

发展历史

课程架构

主要的主题

## 什么是分布式系统？

很多台计算机通过网络连接，通过收发包(Packet)来交互，协作来提供服务 



分布式系统的用途？为什么要有分布式系统？

- 连接物理上隔离的机器
- 通过并行提高容量
- 容错。一部分机器出问题不影响提供服务。
- 安全性

## 历史

略

## 课程架构

lecture：聚焦于Big Ideas。通常由论文驱动。Paper经常是课上的BigIdea的CaseStudy

Paper：推荐在上课前阅读

Labs：MapReduce、Raft、KV存储、分表KV

## MapReduce



> MapReduce overview
>   context: multi-hour computations on multi-terabyte data-sets e.g. build search index, or sort, or analyze structure of web
>    only practical with 1000s of computers applications not written by distributed systems experts
>    overall goal: easy for non-specialist programmers
>    programmer just defines Map and Reduce functions
>    often fairly simple sequential code
>   MR manages, and hides, all aspects of distribution!

### 抽象的视角

- 有一系列的输入文件f1,f2,f3....

- 对于每个文件，都使用`Map()`函数对其进行处理，产生一些中间输出。

  - 举例：单词计数，计算输入中每个不同单词出现的次数，数据集包含许多文件，数据集很大。

  - > Abstract view of a MapReduce job -- word count
    >   Input1 -> Map -> a,1 b,1
    >   Input2 -> Map ->     b,1
    >   Input3 -> Map -> a,1     c,1
    >                     |   |   |
    >                     |   |   -> Reduce -> c,1
    >                     |   -----> Reduce -> b,2
    >                     ---------> Reduce -> a,2
    >   1) input is (already) split into M files
    >   2) MR calls Map() for each input file, produces set of k2,v2
    >      "intermediate" data
    >      each Map() call is a "task"
    >   3) when Maps are done,
    >      MR gathers all intermediate v2's for a given k2,
    >      and passes each key + values to a Reduce call
    >   4) final output is set of <k2,v3> pairs from Reduce()s

  - 对于f1使用wordcount（也就是Map）处理，对于每个单词生成一个KV对，K是单词，V是计数值。如果一个单词a（同一个文件？）出现了多次，那么会有多个K-V对`<a,1>`

    - 对于f2、f3做类似的处理。
    - 比如f1：<a,1>、<b,1>。
    - f2：<b,1>
    - f3：<a,1>、<c,1>。
    - 这些Map函数全部并行运行的，彼此之间完全独立，没有通信。于是这样会有更大的吞吐量

  - 生成了这些中间数据KV对之后，来到第二个阶段：对于每一行（按Key分行）使用Reduce函数。

    - Reduce函数基本上就是，对于一个特定的Key，聚集这一行所有的Value，在WordCount的情况下就是将其求和。
    - <img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301062046022.png" alt="image-20230106204552835" style="zoom:67%;" />

- 在老师读论文的时候学生提了一些很好的问题，尤其是看FIG1的时候。在读了论文之后需要汇总。

- GFS：GLOBAL FileSystem

- 基本的容错策略：如果某个Worker没有响应，那么Coordinator会Rerun那个Worker的MapReduce过程，找一个新的Worker重新跑一遍。

  - Can a Map run or even complete twice?

    - 可以的。比如协调者认为某个Worker已经Down了，但是实际上它并没有，只是因为NetworkFailure联系不上。这时协调者会找另外一个Worker重新跑一边Map，而此前的Worker也在跑同一个Map。发生这种情况没事，因为两次Map的输出会是一模一样的，只需要挑其中一个用于Reduce。

  - Can a coordinator fail?No.when the Coordinator fails,the whole job has to be rerun.

    > We'll see later in semester techniques that we could use to make the coordinator fault tolerant if we wanted to.But they decided not to do so.One reason they decided not to do so is because like a single machine uh they're hoping basically that the single machine that just runs the coordinator is unlikely to crash while it's very likely that one of the thousands of machines that run some mapper will crash.

  - How about slow Workers?如果有一些Worker很慢（比如Job快完成的时候有一些Worker迟迟不完成，拖慢了整体的速度）？

    - 直接引用学生和老师的回答。

    > 学生：um i think i recall reading something about uh when the job is getting somewhat close to finishing, the coordinator will assign the remaining tasks to additional machines just in case there are like machines that are lagging and then they will take the results that
    >
    > finish first
    >
    > 老师：yeah exactly so.These slow workers are called stragglers(掉队者) and what they do is like they sort of do backup tasks. So for example when they're close to the indeed as you say when you know the computation is almost done ,to say, like there's a handful of reduced tasks left or a handful of map task left, the coordinator actually just basically runs a second instance or maybe third instance of that task on a separate machine and that's totally okay to do so because you know it's functional and so it's no problem we will run the same computation several times because it will reduce exactly the same output because it's given the same input and the hope is that like one of these other guys will finish quickly and so therefore then we we're not the performer is not limited by the slowest worker but basically the fastest of the ones that got replicated and so this is like one of the issues where like you know basically this is a common idea to deal with stragglers or to deal with tail latency is to try to basically replicate tasks and go for the first that finishes

## 论文精读

### Section 2

MapReduce的编程模型：不管是Map还是Reduce都由用户编写。

- Map接收输入对，输出中间值KV对的集合。MapReduce库将所有与同一个中间键Key相关联的值放到一组，并将其传递给Reduce函数。
- Reduce函数接收一个中间键K，以及与这个Key关联的值的集合，然后将所有的值合并，以形成一个可能更小的值的集合。
  - 一般一次Reduce调用产生0个或1个输出值。
  - 中间值的集合通过一个Iterator应用于Reduce函数。

### Section 3  Implementation

#### 3.1 Execution Overview 

- Map是分布式运行在多个机器上的，通过将输入文件划分为M个部分来实现。于是这M个部分能够在不同的机器上并行处理

  > The *Map* invocations are distributed across multiple machines by automatically partitioning the input data into a set of M *splits*. The input splits can be processed in parallel by different machines. 

- Reduce同样是分布式运行在多个机器上的。要将中间输出文件使用划分函数来划分为R个部分。R和划分函数由用户指定。

  > *Reduce* invocations are distributed by partitioning the intermediate key space into R pieces using a partitioning function (e.g.,hash(key) mod R). The number of partitions (R) and the partitioning function are specified by the user.

MapReduce的流程（图片中的标签数字和下面的文字是一一对应的）：

1. 用户程序中的MapReduce库首先将输入文件分成M块，每块通常为16MB到 64MB（可由用户通过可选参数控制）。 然后它在一组机器上启动程序的许多副本。

2. 其中一个副本比较特殊，叫做Master，也叫做Coordinator。它负责分配工作，其他的机器就是被Master分配任务的Worker。总共有 M 个 map 任务和 R 个 reduce 任务要分配。 Master挑选空闲的Worker，给每个挑选出来的空闲Worker分配一个 map 任务或 reduce 任务。

3. 被分配了 map 任务的 worker 读取相应输入的内容（也就是被拆分后的输入的某个部分的内容）。 它从输入数据中解析出键/值对，并将每一对传递给用户定义的 Map 函数。 Map 函数生成的中间键/值对被缓冲在内存中。

4. 周期性地，缓冲对被写入worker的本地磁盘，由分区函数划分为 R 个区域。 这些缓冲对在本地磁盘上的位置被传递回Master，Master负责将这些位置转发给reduce worker。

5. 当 master 通知 reduce worker 有关缓冲的数据的位置时，它会使用远程过程调用（RPC）从 map worker 的本地磁盘读取缓冲的数据。当 reduce worker读完了所有的中间数据时，它会按中间数据的Key对其进行排序，这样Key相同的数据会聚集在一起出现。 之所以要进行排序，是因为通常许多不同的Key会被映射到同一个 reduce 任务上去。 如果中间数据量太大在内存里放不下，使用外部排序

6. reduce worker 遍历(iterates over)排好序的中间数据，对于遇到的每个唯一的中间Key，它将键（key）和相应的中间值集（set of intermediate values ）传递给用户的 Reduce 函数。 Reduce 函数的输出附加到此 reduce 分区的最终输出文件

   >  The output of the *Reduce* function is appended to a final output fifile for this reduce partition.

7. 当所有的map任务和reduce任务都完成后，master唤醒用户程序。 此时，用户程序中的MapReduce调用返回到用户代码。

任务成功完成后，mapreduce 的输出会保存在 R 个输出文件中（每个 reduce 任务一个，文件名由用户指定）。 通常，用户不需要将这R个输出文件组合成一个文件——他们通常将这些文件作为输入传递给另一个MapReduce调用，或者在另一个能够处理被分割成多个文件的输入的分布式应用程序中使用它们。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301071922410.png" alt="image-20230107192212276" style="zoom: 67%;" />

#### 3.2 Master Data Structures

Master维护的几个数据结构：

- 对于每个Map和Reduce任务，Master需要保存其状态（*idle*, *in-progress*,or *completed*）。对于 non-idle的任务，还需要保存Worker Machine的Identity
- Master还是中间文件的保存位置从Map任务传递给Reduce的中间管道，所以对于每个已经完成的Map任务，Master需要保存Map任务生成的R个中间文件的位置和大小。位置和大小的信息是随着Map任务的完成而更新的。这些信息被不断地推送给有*in-progress*状态的Reduce任务的Worker。

>  Updates to this location and size information are received as map tasks are completed.The information is pushed incrementally to workers that have *in-progress* reduce tasks.

#### 3.3 Fault Tolerance

MapReduce的容错

##### Worker Failure

Master周期性地Ping每个worker，如果在一定时间内没有收到Worker的响应，则Master将该Worker标记为失败的。这个Worker**完成的**任何Map任务都会重置回其初始空闲状态（idle），因此这些任务有资格调度给其他的Worker执行。类似地，Failed Worker上**正在进行的**任何Map任务或Reduce任务也会被重置为空闲状态，并有资格被重新调度。

- 注意这里的黑体的区别，只有已完成的Map任务需要被重置（已完成的Reduce任务不需要）。而正在进行的（in-progress）Map任务和Reduce任务**都**需要被重置。

- 已完成的Map任务在发生故障的时候之所以需要被重置（然后在其他机器上重新执行），是因为它们的输出存储在故障机器的本地磁盘上，因此无法被其他机器访问。而已完成的reduce任务**不需要重新执行**，因为输出存储在全局文件系统中（GFS）。

当一个先被Worker A执行的Map任务由于A故障而被Worker B执行时，所有执行Reduce任务的机器都会被告知这个重新执行，任何尚未从A读取数据的reduce任务都将从B读取数据。

- 因为每台Reduce Worker都需要从同一台机器取走由他们负责处理的那一部分中间文件。换句话说，故障的MapWorker产生的中间输出会被划分成R个分区，分别发送给每个ReduceWorker。所以每台ReduceWorker都需要被告知故障。

> MapReduce is resilient to large-scale worker failures.For example, during one MapReduce operation, network maintenance on a running cluster was causing groups of 80 machines at a time to become unreachable for several minutes. The MapReduce master simply re-executed the work done by the unreachable worker machines, and continued to make forward progress, eventually completing the MapReduce operation

##### Master Failure

- 周期性地写入上面提到的Master的数据结构的定期检查点还是比较容易的。如果Master寄了，新的Master可以从最新的检查点开始。然而，鉴于只有一个Master，它失败的可能性不大；因此，如果Master发生故障，我们当前的实现将中止MapReduce计算。 客户端可以检查此条件并在需要时重试 MapReduce 操作。

> It is easy to make the master write periodic checkpoints of the master data structures described above. If the master task dies, a new copy can be started from the last checkpointed state. However, given that there is only a single master, its failure is unlikely; therefore our current implementation aborts the MapReduce computation if the master fails. Clients can check for this condition and retry the MapReduce operation if they desire

##### Semantics in the Presence of Failures

出现故障的时候的语义

- 当用户提供的 map 和 reduce 运算符是其输入值的确定性函数时，我们的分布式实现产生的输出与整个程序的无故障顺序执行产生的输出相同。

  - 这句话的后半部分强调的是并行执行（分布式，同时执行）和顺序执行（一个任务接着一个任务轮流执行）的输出是相同的。
  - 同一个任务不管执行几次，这几次的输出都会是一样的。这也是我们能够使用Re-execute来容错的理由之一——换一台机器重新执行并不会产生不同的结果。

- 为了保证这个属性，我们需要map任务和Reduce任务的输出的提交是原子性的。

  - 每个处于in-progress状态的任务都将其输出写入到私有的临时文件里。一个Reduce任务产生一个临时文件，而一个Map任务产生R个这样的文件（为每个Reduce产生任务一个）

  - 当一个Map任务完成的时候，Worker向Master发送消息，消息中会包含R个临时文件的名字。如果Master此前已经收到了来自另外一个已完成的Map任务的消息，就忽略这个消息，否则Master在数据结构中记录下这R个临时文件的名字。

    > If the master receives a completion message for an already completed map task, it ignores the message. Otherwise, it records the names of R files in a master data structure.

  - 当一个Reduce任务完成的时候，ReduceWorker会自动将其临时文件重命名为最终的输出文件。如果相同的Reduce任务在多个机器上同时执行，那么对于同一个最终输出文件会有多个重命名调用，此时我们依赖文件系统所提供的原子性的重命名操作来保证最终的文件的内容只包含来自同一次Reduce任务的执行。

    - 概括一下就是多台机器上将相同内容的临时文件重命名为同一个名字的最终输出文件的多个操作，最终只会有一个成功。基于文件系统提供的重命名操作的原子性来保证。那个成功了的机器的临时文件，就会成为最终的输出文件。
    - 注意一下就是Reduce任务之所以只需要重命名，是因为最终的输出的临时文件都是处于全局文件系统的，而不是本地的硬盘上。

    >  If the same reduce task is executed on multiple machines, multiple rename calls will be executed for the same final output file. We rely on the atomic rename operation provided by the underlying file system to guarantee that the final file system state contains just the data produced by one execution of the reduce task.

- map和reduce运算符中的绝大多数都是确定性的情况下，我们的语义相当于顺序执行，这使得程序员很容易理解他们的程序行为。当Map和(或)Reduce是非确定性的情况下，我们提供更弱但是也合理的语义。

  > In the presence of non-deterministic operators,the output of a particular reduce task R1 is equivalent to the output for R1 produced by a sequential execution of the non-deterministic program. However, the output for a different reduce task R2 may correspond to the output for R2 produced by a different sequential execution of the non-deterministic program.
  >
  > sequential execution：一个任务接着一个任务执行

这个例子其实没太读懂？

> Consider map task M and reduce tasks $R_1$ and $R_2$. Let e($R_i$) be the execution of Ri that committed (there is exactly one such execution). The weaker semantics arise because e(R1) may have read the output produced by one execution of M and e(R2) may have read the output produced by a different execution of M.

#### 3.4 Locality

局部性

由于网络带宽是一个相对稀有的资源，所以需要尽量节约带宽。

节约的方法：利用一个事实：输入文件是存储在由GFS管理的组成集群的机器的本地磁盘上。分配Map任务的时候尽量将任务分配给本地就存储了输入文件的副本的机器，（如果前者失败）或者是离存储了数据副本的机器很近的机器（比如处于同一个交换机网络）。这样大部分的输入数据都从本地读取，不消耗带宽。

>  GFS divides each file into 64 MB blocks, and stores several copies of each block (typically 3 copies) on different machines. The MapReduce master takes the location information of the input files into account and attempts to schedule a map task on a machine that contains a replica of the corresponding input data. Failing that, it attempts to schedulea map task near a replica of that task’s input data (e.g., on a worker machine that is on the same network switch as the machine containing the data).

#### 3.5 Task Granularity

任务的粒度？

正如最开始说的那样，我们将Map阶段细分为M个片段，将Reduce阶段细分为R个片段。理想情况下，M和R应该比工作机器的数量大得多。让每个Worker执行许多不同的任务可以改善动态负载均衡，并在Worker失败时加快恢复速度：它完成的许多Map任务可以分散到所有其他Worker计算机上。

> There are practical bounds on how large M and R can be in our implementation

- Master需要做出$O(M + R)$个调度决定（因为有这么多个任务），需要在内存中保存$O(M*R)$个状态（每个Map任务会产生R个中间输出文件，这些中间输出文件的位置信息和大小需要保存，而总共有M个Map任务）

进一步讲，R经常是被用户限制的（用户可以指定），因为每一个Reduce任务的输出都会在一个单独的文件中。（因为R可以被用户指定，我们对R的控制力没有那么强）所以实践中我们倾向于选择合适的M来使得每个单独的任务大约有16 MB到64 MB的输入数据（因此3.4的局部性优化是最有效的）。

对于R：使R成为我们期望使用的工作机器数量的小倍数。

> We often perform MapReduce computations with M = 200, 000 and R = 5, 000, using 2,000 worker machines.

#### 3.6 Backup Tasks

针对计算中那些拖后腿的机器使用的策略：后备任务？

所谓的拖后腿的机器：完成仅剩的最后几个Map或Reduce计算任务所花费的时间异常长的机器（大部分任务都算完了，整个计算接近结束，但是有几个机器算的很慢，大伙都在等这几个机器算完）。

> One of the common causes that lengthens the total time taken for a MapReduce operation is a “straggler”: a machine that takes an unusually long time to complete one of the last few map or reduce tasks in the computation.

拖后腿的机器出现的可能的原因：

> Stragglers can arise for a whole host of reasons. For example, a machine with a bad disk may experience frequent correctable errors that slow its read performance from 30 MB/s to 1 MB/s. The cluster scheduling system may have scheduled other tasks on the machine,causing it to execute the MapReduce code more slowly due to competition for CPU, memory, local disk, or network bandwidth. A recent problem we experienced was a bug in machine initialization code that caused processor caches to be disabled: computations on affected machines slowed down by over a factor of one hundred.

具体的缓解方法：Backup Task。老师上课讲了一下，这里直接引用论文原文吧。

> When a MapReduce operation is close to completion, the master schedules backup executions of the remaining *in-progress* tasks. The task is marked as completed whenever either the primary or the backup execution completes. We have tuned this mechanism so that it typically increases the computational resources used by the operation by no more than a few percent

论文说发现这个方法减少时间的效果还是蛮好的，举了个关闭后备任务，时间多44个百分点的例子。

### Section 4 Refifinements

#### 4.1 Partitioning Function

对于划分函数的选择优化。可以根据中间Key的特点来选择合适的划分函数，这样使得划分的结果会更加均衡一点。

- 这个划分是用于将输出的中间文件划分为R部分的。
- 划分函数是一个关于中间输出的Key的函数。

> Data gets partitioned across these tasks using a partitioning function on the intermediate key.

- 默认的划分函数是$HashValue(Key) mod R$
- In Some Cases:某些情况下使用其他Partitioning Function的举例

> In some cases, however, it is useful to partition data by some other function of the key. For example, sometimes the output keys are URLs, and we want all entries for a single host to end up in the same output file. To support situations like this, the user of the MapReduce library can provide a special partitioning function. For example,using “*hash(Hostname(urlkey)) mod R*” as the partitioning function causes all URLs from the same host to end up in the same output file.
>

#### 4.2 Ordering Guarantees

输出的中间文件是按照Key排好升序的。有序便于查找。

直接贴原文

> We guarantee that within a given partition, the intermediate key/value pairs are processed in increasing key order. This ordering guarantee makes it easy to generate a sorted output file per partition, which is useful when the output file format needs to support efficient random access lookups by key, or users of the output find it convenient to have the data sorted.

#### 4.3 Combiner Function

在某些情况下，每个Map任务产生的中间键中存在显著的重复，并且用户指定的Reduce函数是满足交换律和结合律的。在这种情况下可以在将中间数据发送给ReduceWorker之前，使用Combiner Function来去重。拿第2.1节中的单词计数来举例。由于单词频率倾向于遵循Zipf分布，每个Map任务将产生数百或数千条`<the，1>`形式的记录。所有这些计数都将通过网络发送到(同)一个reduce任务，然后通过reduce函数将其相加，生成一个数字（也就是the的总次数）。我们允许用户指定可选的Combiner函数，在数据通过网络发送之前对其进行部分合并。

- Combiner Function在每台执行Map任务的机器上执行。典型来说Combiner Function的代码会被用于实现combiner and the reduce functions。
- 两种Function的唯一的不同就是ReduceFunction的输出被写入到最终文件，而Combiner Function的输出被写入中间文件（中间文件会被发送给ReduceWorker） 。
- 关于其效用，论文的评价是：Partial combining significantly speeds up certain classes of MapReduce operations.

> The only difference between a reduce function and a combiner function is how the MapReduce library handles the output of the function. The output of a reduce function is written to the final output file. The output of a combiner function is written to an intermediate file that will be sent to a reduce task.

#### 4.4 Input and Output Types

感觉没什么价值。讲了一些输入类型和输出类型，一个Reader接口。

#### 4.5 Side-effects

所谓的副作用：为了方便用户可能会产生备用文件作为Map和Reduce运算的额外输出。这种情况下我们依赖于应用的编写者来保证这种副作用的原子性和幂等性。

懒得写了，引用原文吧

> We rely on the application writer to make such side-effects atomic and idempotent. Typically the application writes to a temporary file and atomically renames this file once it has been fully generated.We do not provide support for atomic two-phase commits of multiple output files produced by a single task.Therefore, tasks that produce multiple output files with cross-file consistency requirements should be deterministic. This restriction has never been an issue in practice.

#### 4.6 Skipping Bad Records

有时候用户的代码会有Bug，这些Bug可能会导致Map或者Reduce在遇到特定的记录时会确定性的崩溃。像这样的Bug会阻止整个MapReduce运算的完成（因为一到那个记录程序就崩了）。一般的方法是把Bug修了，但有时候这是不可行的，出Bug的可能是用户代码中所引用的某个第三方库，而这个第三方库的源代码是没办法获得的。而有的时候，在做MapReduce的时候忽略掉一些记录是可以接受的，所以可以提供另外一个可选的模式：MapReduce库检查哪些记录会导致确定性的崩溃，然后在计算的时候跳过这些记录，这样就可以make forward progress。

具体的机制：

> Each worker process installs a signal handler that catches segmentation violations and bus errors. Before invoking a user Map or Reduce operation, the MapReduce library stores the sequence number of the argument in a global variable. If the user code generates a signal,the signal handler sends a “last gasp” UDP packet that contains the sequence number to the MapReduce master. When the master has seen more than one failure on a particular record, it indicates that the record should be skipped when it issues the next re-execution of the corresponding Map or Reduce task.
>
> 机翻：
>
> 每个工作进程都会安装一个信号处理程序，用于捕获分段违规和总线错误。 在调用用户 Map 或 Reduce 操作之前，MapReduce 库将参数的序列号存储在全局变量中。 如果用户代码生成信号，信号处理程序会向 MapReduce 主机发送包含序列号的“最后一口气（指的应该是程序死之前遇到的最后一个记录？）”UDP 数据包。 当 master 在一条特定记录上看到不止一次失败时，它表明在下一次重新执行相应的 Map 或 Reduce 任务时应该跳过该记录。

#### 4.7 Local Execution

讲了一下作者对于调试的支持。

> To help facilitate debugging, profiling, and small-scale testing, we have developed an alternative implementation of the MapReduce library that sequentially executes all of the work for a MapReduce operation on the local machine.

#### 4.8 Status Information

Master保存的状态信息：用于给用户看的

- 计算的进度：多少任务已完成，多少正在做，输入的字节数，输出的字节数，中间数据的字节数，处理速率等等
- 由任务生成的标准错误和标准输出文件的链接
- 哪些Worker失败了，失败的时候它们在做哪些Map或者Reduce任务

#### 4.9 Counters

MapReduce库提供了一些用于计数的基础设施。例如，这些基础设施可以用来计数WordCount中总共处理了多少个单词。

> To use this facility, user code creates a named counter object and then increments the counter appropriately in the *Map* and/or *Reduce* function.

来自每个个体WorkerMachine的计数器的值会被周期性地带回给Master（在Master Ping它的时候，在响应中捎带）。Master会对这些来自成功的Map和Reduce任务的计数器的值做聚集计算，在MapReduce计算完成的时候返回给用户代码。

- 当前的计数器的值也会被保存在Master的状态信息中实时展示给人看。
- **在做聚集计算的时候，Master会去重**

> When aggregating counter values, the master eliminates thhe effects of duplicate executions of the same map or reduce task to avoid double counting. (Duplicate executions can arise from our use of backup tasks and from re-execution of tasks due to failures.)
>
> Some counter values are automatically maintained by the MapReduce library, such as the number of in put key/value pairs processed and the number of output key/value pairs produced.

### Section 5 Performance

举了两个例子来说性能，以及Backup Task的加速作用，以及容错的性能。

后面都没什么价值

# Lecture 2 Infrastructure: RPC and threads

讲了Go的Go程、互斥锁、条件变量、RPC

看下源代码。

RPC在服务端出错的时候的语义：

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301092117420.png" alt="image-20230109211730231" style="zoom:67%;" />

# Lecture 3: GFS

## The Google File System论文精读

### Abstract

GFS：运行在廉价商用硬件上的具有容错性和高聚合性能的可扩展的分布式文件系统，用于数据密集型的应用

> Google File System, a scalable distributed file system for large distributed data-intensive applications

> While sharing many of the same goals as previous distributed file systems,our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions.This has led us to reexamine traditional choices and explore radically different design points
>
> 虽然与以前的分布式文件系统有许多相同的目标，但我们的设计是由对当前和预期的应用程序工作负载和技术环境的观察所驱动的，这反映了与早期文件系统假设的明显背离。

### 1. INTRODUCTION

- GFS的目标：（与之前的分布式文件系统一样的）性能、可扩展性、可靠性、可用性，**以及更多**。
- 第一，组件故障是常态，而不是例外。因为GFS由成百上千的机器组成，有相当大数量的客户端访问。组件的数量和质量决定了在任何给定时刻都有某些组件没办法正常工作，某些组件没办法从当前的错误恢复。这也决定了GFS还需要有以下的特性：
  - 持续监测
  - 错误检测
  - 容错
  - 自动恢复
- 第二，GFS上的文件以传统的标准看是巨大的，几十GB是非常平常的，而以KB为块来管理这么大的文件是很不方便的（即使文件系统支持），所以GFS需要一些与传统文件系统不一样的设计，块大小和I/O操作都需要再次讨论。

> Second, files are huge by traditional standards. Multi-GB files are common. Each file typically contains many application objects such as web documents. When we are regularly working with fast growing data sets of many TBs comprising billions of objects, it is unwieldy to manage billions of approximately KB-sized files even when the file system could support it. As a result, design assumptions and parameters such as I/O operation and block sizes have to be revisited.

- 第三，GFS上的大部分文件的更改方式是从末尾追加，而不是覆盖现有数据。文件内的随机写实践上基本上不存在，一旦文件被写入，基本上就只读，并且经常是顺序地只读。考虑到在大文件上的这种访问模式，追加操作成了性能优化和原子性保证的焦点。

> most files are mutated by appending new data rather than overwriting existing data. Random writes within a file are practically non-existent. Once written, the files are only read, and often only sequentially. Given this access pattern on huge files, appending becomes the focus of performance optimization and atomicity guarantees,while caching data blocks in the client loses its appeal.

- 第四，协同设计文件系统的API接口和应用，有利于文件系统整体的灵活性。引入了一个原子性的`Append()`操作，这样多个客户端可以并发地追加内容，而不需要彼此之间额外的同步措施。更多细节见后续。

### 2. DESIGN OVERVIEW

#### 2.1 Assumptions

机遇与挑战并存的一些假设。

- 整个系统是建立在许多廉价且经常失败的商用机器上的。所以系统必须持续性地监测自身，检测、容错和（例行公事一样）从组件故障中快速恢复。

> The system is built from many inexpensive commodity components that often fail. It must constantly monitor itself and detect, tolerate, and recover promptly from component failures on a routine basis.

- 系统存储少量的大文件。预期是几百万100MB以上的文件，几个GB的文件很常见，需要高效管理。小文件也需要支持但是不需要做优化。

> We expect a few million files, each typically 100 MB or larger in size. Multi-GB files are the common case and should be managed efficiently.

- 工作负载主要有两种读取：大的流式读取（也就是连续读取一大块）和小的随机读取（读取任意位置的一小块）。对性能敏感的应用会批处理和排序其小型读取，以便在文件中稳步前进而不是来回横跳。

>  In large streaming reads, individual operations typically read hundreds of KBs, more commonly 1 MB or more.Successive operations from the same client often read through a contiguous region of a file. A small random read typically reads a few KBs at some arbitrary offset. 

- 系统必须为多客户端并发给同一个文件追加内容高效实现一个良定义语义。最小同步开销下的原子性是至关重要的。

> Our files are often used as producer consumer queues or for many-way merging. Hundreds of producers, running one per machine, will concurrently append to a file.The file may be read later, or a consumer may be reading through the file simultaneously.

- 高可持续带宽比低延迟更重要。原因：

> Most of our target applications place a premium on processing data in bulk at a high rate, while few have stringent response time requirements for an individual read or write。
>
> 重视高速批量处理数据，对于单次的读写没有严格的延迟要求

#### 2.2 Interface

GFS的接口：

> We support the usual operations to *create*, *delete*,*open*, *close*, *read*, and *write* files.

Snapshot和Record Append：

- 前者是快照功能，Section 3.3
- 后者是原子性地并发地往同一个文件追加内容。这允许客户端不需要额外的锁即可并发追加。Section 3.4

> Snapshot creates a copy of a file or a directory tree at low cost. 
>
> Record append allows multiple clients to append data to the same file concurrently while guaranteeing the atomicity of each individual client’s append. 

#### 2.3 Architecture

架构

- 一个GFS集群包含一个Master，很多个*chunkservers*，并且能够被多个客户端访问。其中的每一个通常都是运行了用户级别的服务器进程的一台商用Linux机器。

> Each of these is typically a commodity Linux machine running a user-level server process. 

- 可以在一台机器上同时运行chunkserver和Client，只要你能接受由此带来的更低的可靠性。

- 文件被划分为固定大小的块（chunk），每个Chunk由一个**不可更改的、全局唯一的**64位的chunk handle来标识。

  - chunk handle由Master在创建块时分配。

  - > Each chunk is identified by an immutable and globally unique 64 bit *chunkhandle* assigned by the master at the time of chunk creation

- ChunkSever在它们本地的磁盘上将Chunk保存为**Linux文件**。对于Chunk的读取和写入由ChunkHandle和字节范围来指定。为了可靠性每个Chunk都会在多个ChunkSever上存有副本。默认保存三份副本，用户可以为不同的文件命名空间区域指定不同的复制级别。

- Master保存文件系统的所有元数据：

  - 命名空间
  - 访问控制信息
  - 从文件到Chunk的Mapping
  - Chunks的当前位置
  - 它还控制系统范围的活动，例如块租用管理（?）、孤立块的垃圾收集以及块服务器之间的块迁移。

- Master周期性地与每个ChunkSever通信，用*HeartBeat*messages来发指令和收集状态。

- 链接到每个应用的GFS客户端代码实现了文件系统的API，与ChunkSever和Master通信以代表应用读写数据。

  - 客户端与Master交互以进行元数据操作，但所有数据承载通信直接转向chunkservers。

- 客户端和ChunkSever都不会缓存文件数据。**但是客户端会缓存元数据**。

  - 简单来讲，客户端那边要么是流式访问大文件，要么工作集太大缓存不下。ChunkSever那边不需要缓存，因为文件就存在本地，Linux的文件系统会做好缓存的工作。
  - 没有缓存可以消除缓存一致性问题，可以简化客户端和整个系统

> Client caches offer little benefit because most applications stream through huge files or have working sets too large to be cached.
>
> Chunkservers need not cache file data because chunks are stored as local files and so Linux’s buffer cache already keeps frequently accessed data in memory

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301101906785.png" alt="image-20230110190649651" style="zoom:67%;" />

#### 2.4 Single Master

关于单独一个Master的评价：

- 简化设计，使得Master能够使用全局知识做出复杂的块放置和复制决策。
- 要最小化Master对于读写操作的参与，以免其成为瓶颈。

> Having a single master vastly simplifies our design and enables the master to make sophisticated chunk placement and replication decisions using global knowledge. However, we must minimize its involvement in reads and writes so that it does not become a bottleneck.

如何最小化Master对于读写操作的参与：

- 客户端从不通过Master读写文件数据，而是向Master询问它应该与哪个（哪些）ChunkSever联系，然后把这个信息缓存下来。后续的操作都直接与ChunkSever交互。
- 举个例子：客户端要读取某个文件的某个地方，它有<FileName,Offset>。文件名和文件内偏移量。
  1. 使用固定大小的ChunkSize，将Offset转化为文件内的块索引（ChunkIndex），以及块内偏移量。
  2. 客户端给Master发消息，把文件名和ChunkIndex发过去。
  3. Master响应，把ChunkHandle和块复制品的位置发回去。
  4. 客户端缓存收到的信息，使用文件名和ChunkIndex作为Key。
  5. 客户端往其中一个副本发送请求（很有可能是最近的那个），请求指定了ChunkHandle以及在这个Chunk内的字节范围。
  6. 对于同一个块的进一步的读取不再需要client-master interaction，直到缓存的信息过时，或者文件被再次打开。
- 实际上客户端通常会在一次请求中请求多个块，Master也会一次发回多个块的信息。这些额外的信息实践上没有带来额外的开销，但是避免了后续的几次client-master interaction。

#### 2.5 Chunk Size

- 块大小是64MB，每个块副本都作为普通的 Linux 文件存储在块服务器上，并且仅在需要时进行扩展。Lazy space allocation是为了避免在如此大的块大小之下产生的内部碎片问题。

- 大块的好处：

  - 减少客户端与Master交互的需要。因为客户端读或者写的大概率在同一块，只需要最开始的一次交互就够了。具体一点就是：

  >  it reduces clients’ need to interact with the master because reads and writes on the same chunk require only one initial request to the master for chunk location information.The reduction is especially significant for our workloads because applications mostly read and write large files sequentially. Even for small random reads, the client can comfortably cache all the chunk location information for a multi-TB working set.

  - 由于是同一大块，一个客户端很有可能在给定的块上做许多操作，它可以在更长的时间段内保持和ChunkSever持久的TCP连接来减少网络开销。
  - 减少了Master上存储的元数据的大小。使得元数据可以缓存在内存里，带来了其他好处（2.6.1）。

- 缺点：小文件的块数会很少，可能只有一个。这就使得假如有很多客户端同时访问这个文件的话，存储这个文件的块的ChunkSever可能会变成热点。

  - 实践上不是一个主要问题，因为几乎都是连续读取多块的大文件

>  A small file consists of a small number of chunks, perhaps just one. The chunkservers storing those chunks may become hot spots if many clients are accessing the same file.

#### 2.6 Metadata

Master主要存储三种类型的元数据：

- 文件和块的命名空间
- 文件到块的映射
- 每个块的副本的位置

所有的元数据都保存在Master的内存中。前两种还会被持久化在Master本地的硬盘中，通过将更改写入操作日志的形式。

>  The first two types (namespaces and file-to-chunk mapping) are also kept persistent by logging mutations to an *operation log* stored on the master’s local disk and replicated on remote machines.

**Matser不将块位置信息持久化保存，而是在Master启动的时候询问每个ChunkSever它的块信息，以及当有新的ChunkSever加入集群的时候**。

- 很简单，因为位置信息是会变化的，持久化的可能是过期的。位置的变化不一定能及时的反映在持久化的位置信息中。

##### *2.6.1 In-Memory Data Structures*

由于元数据存储在内存中，Master操作速度很快。 master在后台定期简单又高效地扫描其整个状态以实现chunk垃圾回收、chunkserver故障时的重新复制以及chunk迁移以平衡负载和ChunkSever之间的磁盘空间使用情况。

> This periodic scanning is used to implement chunk garbage collection, re-replication in the presence of chunkserver failures, and chunk migration to balance load and disk space usage across chunkservers. Sections 4.3 and 4.4 will discuss these activities further

- 由于元数据都存储在内存中，所以Master的内存的大小会限制元数据的数量，进而限制Chunk的数量，进而限制整个系统的容量。但是实践上不是问题。
- 实在不行可以加内存嘛

> The master maintains less than 64 bytes of metadata for each 64 MB chunk. Most chunks are full because most files contain many chunks, only the last of which may be partially filled. Similarly, the file namespace data typically requires less than 64 bytes per file because it stores file names compactly using prefix compression.

##### *2.6.2 Chunk Locations*

Master并不会持久化块的副本的位置信息，而是在启动的时候为了这个信息轮询ChunkSever。Master可以保持自己的信息是最新的，通过定期的心跳消息。

> The master does not keep a persistent record of which chunkservers have a replica of a given chunk. It simply polls chunkservers for that information at startup. The master can keep itself up-to-date thereafter because it controls all chunk placement and monitors chunkserver status with regular *HeartBeat* messages

不持久化位置信息而是向ChunkSever询问的好处是：消除了Master和ChunkSever之间的位置信息一致性问题。

> This eliminated the problem of keeping the master and chunkservers in sync as chunkservers join and leave the cluster, change names, fail, restart, and so on. In a cluster with hundreds of servers, these events happen all too often.

##### *2.6.3 Operation Log*

操作日志包含对于元数据的关键更改的历史记录。GFS的中心

- 元数据的唯一持久化记录
- 作为一个定义并发操作的顺序的逻辑时间线

> The operation log contains a historical record of critical metadata changes. It is central to GFS. Not only is it the only persistent record of metadata, but it also serves as a logical time line that defines the order of concurrent operations.

文件和块，以及它们的版本（见第 4.5 节），都由它们创建的逻辑时间唯一且永久地标识。

由于操作日志如此关键，所以我们必须可靠地存储它，并且在元数据的更改持久化之前，不要使更改对客户端可见。否则，即使块本身幸存，我们也会有效地丢失整个文件系统或最近的客户端操作。因此，我们将它复制到多台远程机器上，只有在本地和远程将相应的日志记录刷新到磁盘后才响应客户端操作。 master 在刷新之前将多个日志记录一起批处理，从而减少刷新和复制对整个系统吞吐量的影响。



Master通过ReplayOperationLog来恢复其文件系统的状态。为了最小化启动时间，避免需要Replay的Log太大，Master会建立检查点，从检查点之后的Log开始Replay。Master会在Log变大超过特定大小的时候建立检查点。

> The master checkpoints its state whenever the log grows beyond a certain size so that it can recover by loading the latest checkpoint from local disk and replaying only the limited number of log records after that.

关于检查点： 

- 能被直接映射到内存的类B-树

> The checkpoint is in a compact B-tree like form that can be directly mapped into memory and used for namespace lookup without extra parsing. This further speeds up recovery and improves availability.

- 其建立的过程中不会延迟传入的更改

> Because building a checkpoint can take a while, the master’s internal state is structured in such a way that a new checkpoint can be created without delaying incoming mutations. The master switches to a new log file and creates the new checkpoint in a separate thread. The new checkpoint includes all mutations before the switch. It can be created in a minute or so for a cluster with a few million files. When completed, it is written to disk both locally and remotely

- 恢复只需要最新的检查点以及这个检查点后续的Log。对于旧的检查点和Log文件，可以自由地删除，但是也会保留一部分以应对灾难。建立检查点的时候出错也没事，因为恢复代码会跳过不完整的检查点。

> Recovery needs only the latest complete checkpoint and subsequent log files. Older checkpoints and log files can be freely deleted, though we keep a few around to guard against catastrophes. A failure during checkpointing doesnot affect correctness because the recovery code detects and skips incomplete checkpoints

#### 2.7 Consistency Model

##### *2.7.1 Guarantees by GFS*

文件的命名空间的更改是原子性的，由Master互斥地处理，Master的OperationLog定义了一个全局的全序。

> namespace locking guarantees atomicity and correctness (Section 4.1);the master’s operation log defines a global total order of these operations (Section 2.6.3).

数据更改后文件区域的状态取决于更改类型、成功还是失败以及是否存在并发更改。总结如下表：

如果所有客户端，无论从哪个副本读取，读到的数据都一样，那么我们认为文件 region 是“一致的”； 如果对文件的数据修改之后，region 是一致的，并且客户端能够看到写入操作写入的全部的内容，那么这个 region是“已定义的”

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301141717217.png" alt="image-20230114171704102" style="zoom:67%;" />

一致的：

> A file region is *consistent* if all clients will always see the same data, regardless of which replicas they read from.

已定义的：

> A region is *defined* after a file data mutation if it is consistent and clients will see what the mutation writes in its entirety

- 当一个更改成功，并且没有其他并发更改的干扰时，受更改影响的区域是已定义的（并且隐含着一致的）。因为：所有的客户端都总是能完整地看到这次更改写了什么。
- 并发的更改会使得文件的区域一致但是未定义，因为：所有的客户端都能看到相同的数据，但是这些数据可能不会反映出任意**一个**更改所写入的**完整**内容。通常情况下，文件region内包含了来自多个修改操作的、混杂的数据片段。(更改A写一段，更改B接着写一段，然后C写一段，但是ABC没有哪一个是完整写入了更改的全部内容的，它们的部分的更改混杂在一些)

> Concurrent successful mutations leave the region undefined but consistent: all clients see the same data, but it may not reflect what any one mutation has written. Typically, it consists of mingled fragments from multiple mutations.

失败的更改使得文件不一致且未定义：

> A failed mutation makes the region inconsistent (hence also undefined): different clients may see different data at different times.

接下来讲讲应用如何区分已定义区域和未定义区域：对于未定义区域，不需要做进一步的区分。

数据更改分为两种类型：*writes* or *record appends*。写入或者记录追加。

写入：在应用指定的文件偏移量处写入数据

> A write causes data to be written at an application-specified file offset

记录追加：将记录原子性地至少一次追加到GFS选定的偏移量处，即便是在并发更改的情况下。GFS选定的偏移量被返回到客户端，并且标记着一个包含写入记录的已定义区域的开始。GFS可能会插入填充或者重复记录，这些东西占据的区域看做是不一致的。

- 作为对比，一个普通的追加就是往客户端所认为是文件末尾的偏移量处写入内容。

> A record append causes data (the “record”) to be appended *atomically at least once* even in the presence of concurrent mutations, but at an offset of GFS’s choosing(Section 3.3).(In contrast, a “regular” append is merely a write at an offset that the client believes to be the current end of file.)The offset is returned to the client and marks the beginning of a defined region that contains the record.In addition, GFS may insert padding or record duplicates in between. They occupy regions considered to be inconsistent and are typically dwarfed by the amount of user data.

经过了一系列的成功的修改操作之后，GFS 确保被修改的文件 region 是已定义的，并且包含最后一次修改操作写入的数据。GFS的确保措施有如下两种：

- 对所有的Chunk副本使用一样的更改操作顺序
- 使用Chunk的版本号来检测副本是否因为它所在的Chunk 服务器宕机而错过了修改操作而导致其失效

> (a) applying mutations to a chunk in the same order on all its replicas(Section 3.1),
>
> (b) using chunk version numbers to detect any replica that has become stale because it has missed mutations while its chunkserver was down (Section 4.5).

- 对于过时的副本，不再参与更改，Master服务器也不再返回这个Chunk副本的位置信息给客户端。会被尽快垃圾回收。

> Stale replicas will never be involved in a mutation or given to clients asking the master for chunk locations. They are garbage collected at the earliest opportunity.

如果客户端读到了过期的副本怎么办？

- 由于客户端会缓存Chunk的位置信息，这就使得客户端缓存了过期的位置信息而不自知（刚开始缓存的时候信息没落后，在缓存超时过期之前，缓存的信息落后了）。于是客户端就有可能会在缓存信息被刷新之前读取了过时的副本。这个窗口期受缓存项的超时和文件的下一次打开的限制（重新打开文件将从缓存中清除该文件的所有块信息）。

- 并且，由于GFS大部分的文件都是只追加的，所以一个过期的副本经常只是返回一个提前结束的块，而不是过期的数据。（只追加的情况下，过期的副本中，数据没有过期，只不过这个副本比最新的版本少了后面一截）。
- 客户端在重试并联络Master的时候，会得到最新的Chunk位置信息。

GFS如何处理机器宕机？

- GFS通过主服务器和所有数据块服务器之间的定期握手来识别故障的数据块服务器，并通过校验和来检测数据损坏（5.2）
- 一旦出现问题，数据将尽快从有效副本中恢复（4.3）。
- 只有在GFS做出反应之前（通常在几分钟内）丢失了所有副本，数据块才会不可逆地丢失。
- 即便是在所有数据副本都丢失的情况下，它也是变得不可用，而不是损坏。**GFS会给客户端返回明确的错误信息，而不是返回损坏的数据**

##### *2.7.2 Implications for Applications*

 对应用的影响

GFS应用可以使用如下技术来实现宽松的数据一致性模型：这些技术也可以用于其他目的

- 依赖追加而不是覆盖
- 检查点
- 写入自验证、自识别的记录

实践上所有的应用程序的更改都采用追加的方式而不是覆盖的方式。

典型的应用一：写者从头到尾生成文件之后，原子性地将文件重命名为永久文件名，或者周期性地建立检查点记录成功写入了多少内容，检查点中可以包含应用级别的校验和。

Reader只处理直到上一个检查点的文件区域，因为这些区域是已知处于已定义状态的。抛开一致性和并发不谈，这种方法很有用。

- 从论文的下文可以推测，所谓的“直到”（Up to），指的是检查点截止以及之前的，检查点之后写入的不处理，因为可能从应用程序的视角看还是不完整的。

> Readers verify and process only the file region up to the last checkpoint, which is known to be in the defined state.Regardless of consistency and concurrency issues, this approach has served us well.

追加写入比随机位置写入更加有效率， 对应用程序的失败处理更具有弹性。

检查点允许写者以增量的方式重新启动（而不是重新从零开始），并防止读者处理已经成功写入但是从应用程序的视角看不完整的数据。

> Checkpointing allows writers to restart incrementally and keeps readers from processing successfully written file data that is still incomplete from the application’s perspective.
>
> 从这句话可以推测出，所谓的Up to指的是从检查点往前推。
>
> 1.最开始在纠结，“直到”有两个方向，一个是从检查点开始，时间往后推移，另外一个是从检查点开始，时间往更早时候推移，那么Reader处理的是检查点之前的，还是之后的？
>
> 2.这里告知我们，检查点可以防止Reader处理已经成功写入但是从应用程序视角看还不完整的数据（这也就是检查点之后的数据），因此排除可得到底是哪一种。

典型应用二：许多应用程序并发地追加数据到同一个文件，比如进行结果的合并或者是一个生产者-消费者队列。RecordAppend的“至少一次追加”的语义保证了Writer的输出都能被写入。

对于偶尔的填充和重复记录，Reader的处理方式：

- Writer写入的每条记录都包含额外的信息，比如校验和，可以用来校验检查其有效性。Reader可以使用校验和来识别和丢弃额外的填充和记录碎片。
- 如果它不能容忍偶尔的重复（例如，如果它们会触发非幂等操作），它可以使用记录中的唯一标识符将它们过滤掉
  - 在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“setTrue()”函数就是一个幂等函数,无论多次执行，其结果都是一样的.更复杂的操作幂等保证是利用唯一交易号(流水号)实现。


> A reader can identify and discard extra padding and record fragments using the checksums. If it cannot tolerate the occasional duplicates (e.g., if they would trigger non-idempotent operations), it can filter them out using unique identifiers in the records

### 3. SYSTEM INTERACTIONS

讲述Master、ChunkSever、Client三方如何交互以实现数据更改、原子记录追加、快照

> We designed the system to minimize the master’s involvement in all operations. With that background, we now describe how the client, master, and chunkservers interact to implement data mutations, atomic record append, and snapshot.

#### 3.1 Leases and Mutation Order

更改的定义：一个更改是一个改变Chunk的内容或者元数据的操作，比如一个写或者追加操作。每个变更操作会在一个Chunk的所有副本上执行。

我们使用租约在副本之间保持一致的更改顺序：

- Master向其中一个副本授予租约，我们将这个副本称作主副本（Primary）
- 主副本为对Chunk的所有更改选择一个序列顺序。
- 所有的副本在应用更改时都应该遵从这个顺序
- 因此，全局的修改顺序先由Master授予租约的顺序确定，然后在租约内由主副本分配的序列号决定

租约的机制：租约必须要按照最小化Master的管理开销来设计

- 一个租约初始时有60秒的超时时间。但是只要对块的更改还在继续，PrimaryChunk就可以无限地向Master请求延期。
  - 扩展请求以及授权都使用心跳消息来捎带

> These extension requests and grants are piggybacked on the *HeartBeat* messages regularly exchanged between the master and all chunkservers.

- Master可能会在租约到期之前就废除租约，比如Master想终止对某个文件的更改。
- 即便Master失去了与主副本的联系，Master也可以在旧的租约过期之后安全地将新的租约授予另外一个副本。

举个例子说明流程如下图：

1. 客户端询问Master哪个Chunk服务器持有该chunk的当前租约以及其他副本的位置。如果没有人拥有租约，则主服务器将租约授予其选择的副本（图中未显示）。
   - 这个过程应该发生在客户端向Master发出的初始请求中，也就是向Master询问Chunk位置以及ChunkHandle的时候
2. Master回复主副本的标识（Identity）和其他（次级，Secondary）副本的位置。客户端缓存这些数据以备将来更改。只有当主副本（*Primary*）无法访问或它不再持有租约时（比如租约过期），客户端才需要再次联系Master服务器。
   - 所以副本的位置信息和租约信息是一起缓存的
3. 客户端将数据推送到所有副本。客户端可以按任何顺序执行数据推送（什么的顺序？按图猜测，是指先推送给哪个副本的顺序？）。每个chunkserver将数据存储在内部LRU缓冲缓存中，直到数据被使用或过时。
   - 通过将数据流与控制流解耦，我们可以通过基于网络拓扑来调度昂贵的数据流来提高性能（也就是说可以调度先把数据传递给谁？），而不管哪个chunkserver是主要的。第3.2节对此进行了进一步讨论。
4. 一旦所有的副本都确认收到了数据，客户端就给主副本发送一个写的请求。主副本将连续的序列号分配给它接收到的所有更改，这些更改可能来自多个客户端，这提供了必要的序列化。它按照序列号顺序将更改应用于自己的本地状态。
5. 主副本将写入请求转发到所有辅助副本。每个次级复制品都按照主复制品指定的相同序列号顺序应用更改。
6. 所有的次级副本都会回复主副本，表示它们已完成操作。
7. 主副本回复客户端。在任何副本中遇到的任何错误都会报告给客户端。如果发生错误，则主副本和**所有子副本的任意子集(an arbitrary subset of the secondary replicas)**的写入可能已成功（如果在主副本上失败，则不会为其分配序列号并转发）。客户端请求被视为失败，修改的区域将处于不一致状态。我们的客户端代码通过重试失败的更改来处理这些错误。它将在步骤（3）到（7）进行几次尝试，然后从写入开始返回到重试。

如果应用程序的写入很大或超过了块上限，GFS客户端代码将其分解为多个写入操作。它们都遵循上述控制流程，但可能与来自其他客户端的并发操作交错并被其覆盖。因此，共享文件区域可能最终包含来自不同客户端的片段，尽管副本将是完全一致的（identical），因为在所有副本上以相同的顺序成功完成了单独的操作。这使文件区域处于一致但未定义的状态，如第2.7节所述。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301151444724.png" alt="image-20230115144438579" style="zoom:67%;" />

#### 3.2 Data Flow

我们将数据流与控制流解耦以有效利用网络。

这一节讲述什么：如何最大化利用网络带宽以避免网络瓶颈和高延迟，最小化推送数据到所有机器的延迟

> While control flows from the client to the primary and then to all secondaries, data is pushed linearly along a carefully picked chain of chunkservers in a pipelined fashion. Our goals are to fully utilize each machine’s network bandwidth, avoid network bottlenecks and high-latency links, and minimize the latency to push through all the data.

为了充分利用每台机器的网络带宽，数据沿着一条ChunkSever链线性传输，而不是以其他形式的拓扑结构（比如树）的形式传播，这样每个机器的全部外传带宽可用于尽快传输数据，而不是被分为几个部分给多个接收方传播。

> To fully utilize each machine’s network bandwidth, the data is pushed linearly along a chain of chunkservers rather than distributed in some other topology (e.g., tree). Thus, each machine’s full outbound bandwidth is used to transfer the data as fast as possible rather than divided among multiple recipients

为了尽可能的避免网络瓶颈和高延迟链路，每台机器都将数据转发给离它“最近”且还没有收到数据的机器。

- “最近”要打引号是因为距离是使用IP地址来估计的

> each machine forwards the data to the “closest” machine in the network topology that has not received it.
>
> Our network topology is simple enough that “distances” can be accurately estimated from IP addresses.

为了最小化传输延迟，传输数据使用流水线传输。

一旦一台机器收到数据，它就立即开始转发。流水线很有用，因为我们使用的是全双工的链路，立即转发数据并不会降低接收速率。

> Finally, we minimize latency by pipelining the data transfer over TCP connections. 
>
> Without network congestion, the ideal elapsed time for transferring *B* bytes to *R* replicas is *B/T* + *RL* where *T* is the network throughput and *L* is latency to transfer bytes between two machines

#### 3.3 Atomic Record Appends

关于RecordAppend的描述：

> GFS provides an atomic append operation called *record* *append*. In a traditional write, the client specifies the offset at which data is to be written. Concurrent writes to the same region are not serializable: the region may end up containing data fragments from multiple clients. In a record append, however, the client specifies only the data. GFS appends it to the file at least once atomically (i.e., as one continuous sequence of bytes) at an offset of GFS’s choosing and returns that offset to the client.

对于RecordAppend的评价：很好用，在分布式应用中重度使用。如果使用传统的文件写，需要额外的复杂且昂贵的同步措施。

> Record append is heavily used by our distributed applications in which many clients on different machines append to the same file concurrently. Clients would need additional complicated and expensive synchronization, for example through a distributed lock manager, if they do so with traditional writes.

对于RecordAppend的流程：

> Record append is a kind of mutation and follows the control flow in Section 3.1 with only a little extra logic at the primary

1. 客户端将所有的数据推送到文件的最后一个Chunk的所有副本（The client pushes the data to all replicas of the last chunk of the file）
2. 客户端给主副本发送请求。主副本检查如果将记录追加到当前块，会不会导致当前块的大小超过最大大小64MB。
3. 如果会，主副本将当前块填充到64MB，告诉所有的次级块也这样做，然后回复客户端，要客户端在下一个块上重新进行记录追加操作。
4. 如果不会，也就是追加记录不会使得Chunk超过64MB，也是通常的情况，那么主Chunk把数据追加到自己的副本内， 然后通知二级副本把数据写在跟主Chunk 一样的位置上，最后回复客户机操作成功

如果一个记录追加操作在任意一个副本上失败了，那么客户端会重试操作。因此，同一个块的不同副本可能会包含不同的数据，很可能是同一个记录的部分或全部副本。GFS并不保证所有的副本在字节的尺度上是完全一致的，它只保证数据至少以原子单位写入一次。

- 问题：所以失败的时候，是不会进行回滚操作的？
  - 看过Lecture之后，应该不会。直接在失败的基础之上每个副本都重新追加一遍。


> This property follows readily from the simple observation that for the operation to report success, the data must have been written at the same offset on all replicas of some chunk. Furthermore, after this, all replicas are at least as long as the end of record and therefore any future record will be assigned a higher offset or a different chunk even if a different replica later becomes the primary.

#### 3.4 Snapshot

什么是快照：

> The snapshot operation makes a copy of a file or a directory tree (the“source”) almost instantaneously, while minimizing any interruptions of ongoing mutations.

快照可以用来干什么：

> Our users use it to quickly create branch copies of huge data sets (and often copies of those copies, recursively), or to checkpoint the current state before experimenting with changes that can later be committed or rolled back easily

**快照使用Copy-On-Write实现。**

当Master收到一个快照请求的时候，它首先废除即将进行快照的文件的块上的任何未完成的租约。这个措施保证了后续对这些Chunk 的写操作都必须与 Master交互以找到租约持有者。这将给Master一个率先创建一个新的Chunk的拷贝的机会。

> When the master receives a snapshot request, it first revokes any outstanding leases on the chunks in the files it is about to snapshot

在租约被撤销或到期后，Master会将操作记录到磁盘。然后，它通过复制源文件或目录树的元数据（也就是被快照的对象），将此日志记录应用于其内存状态。新创建的快照文件指向与源文件相同的块。

在快照操作之后，当客户端第一次想写入数据到Chunk C，它首先会发送一个请求到 Master 节点查询当前的租约持有者。Master节点注意到Chunk C的引用计数超过了1。Master节点不会马上回复客户机的请求， 而是选择一个新的Chunk 句柄 `C'`。之后，Master 节点要求每个拥有 Chunk C当前副本的ChunkSever创建一个叫做`C'`的新Chunk。通过在源Chunk所在ChunkSever上创建新的Chunk，我们确保数据在本地复制而不是通过网络复制（我们的硬盘比我们的100Mb以太网大约快 3 倍）。从这点来讲，请求的处理方式和任何其它Chunk 没什么不同：Master 节点确保新 Chunk `C'`的一个副本拥有租约，之后回复客户端，客户端得到回复后就可以 正常的写这个Chunk，而不必理会它是从一个已存在的Chunk 克隆出来的。

### 4. MASTER OPERATION

Master所负责的操作：

- 命名空间操作
- 管理块副本：
  - 决定块的存储位置
  - 创建新的块以及它的副本
  - 协调各种系统活动以保证块被完全复制
  - 回收未使用的存储空间

接下来一一讨论

#### 4.1 Namespace Management and Locking

为什么会有Locking？

> Many master operations can take a long time.We do not want to delay other master operations while they are running. Therefore,we allow multiple operations to be active and use locks over regions of the namespace to ensure proper serialization.

GFS管理命名空间的方式与传统的文件系统不同，它并没有一个每个目录的列出目录中所有文件的数据结构（也就是目录的inode），也不支持别名操作（比如Unix的软链接）。GFS从逻辑上来说维护了一个从完整路径名到元数据的映射的查找表。使用前缀压缩使得这个表可以高效的放入内存。

**命名空间树的每个节点都有一个与之关联的读-写锁**。

每个Master操作在进行之前都需要获取一个锁的集合：

> Typically, if it involves /d1/d2/.../dn/leaf, it will acquire read-locks on the directory names /d1, /d1/d2, ...,/d1/d2/.../dn, and either a read lock or a write lock on the full pathname /d1/d2/.../dn/leaf. Note that leaf may be a file or directory depending on the operation.
>
> 对每个目录名获取读锁，对整个完整路径名获取一个读锁或者写锁

举例说明这个锁机制是如何阻止一个文件`/home/user/foo`在`/home/user`被快照到`/save/user`时被创建的：

- 快照操作需要获取`/home`和`/save`的读锁，以及`/home/user`和`/save/user`的写锁。
  - 问题：为什么需要获取`/home/user`的写锁？ 
  - 答：获取写锁不一定是为了写入，也可能是为了阻止其他人写入。任意一方在写入之前都需要先获取写锁，所以如果我先行一步拿到写锁，那我可以阻止别人写，而我自己获取写锁的目的不一定是为了写，可能仅仅只是为了阻止别人写。
- 文件创建操作需要获取`/home`和`/home/user`的读锁，以及`/home/user/foo`的写锁。
- 这两个操作会被适当的序列化，因为它们试图在`/home/user`获取相互冲突的锁

这一段不是很理解：

> File creation does not require a write lock on the parent directory because there is no “directory”, or *inode*-like, data structure to be protected from modification.The read lock on the name is sufficient to protect the parent directory from deletion

这种锁的方法同样很适用于对于同一个目录的并发更改：

> For example, multiple file creations can be executed concurrently in the same directory: each acquires a read lock on the directory name and a write lock on the file name. The read lock on the directory name suffices to prevent the directory from being deleted, renamed, or snapshotted. The write locks on file names serialize attempts to create a file with the same name twice.

读-写锁是惰性分配的，并且一旦不再使用就被删除。并且，锁的获取也要依据一个全局一致的顺序来避免死锁：首先按名称空间的层次排序，在同一个层次内按字典顺序排序。

> Since the namespace can have many nodes, read-write lock objects are allocated lazily and deleted once they are not in use. Also, locks are acquired in a consistent total order to prevent deadlock: they are first ordered by level in the namespace tree and lexicographically within the same level.

#### 4.2 Replica Placement

副本放置策略的两个目标：

- 最大化数据的可靠性和可用性
- 最大化网络带宽的利用率

对于二者来说，光在多台机器之间分别存储副本是不够的，它只能防止硬盘损坏或者机器宕机以及最大化利用每台机器的网络带宽。

还要在多个机架之间分布存储Chunk的副本，以保证即便整个机架都损坏或者掉线而变得不可用了，也会有副本幸存并且可用。

这还意味着在网络流量方面，尤其是针对Chunk的读操作，能够有效利用多个机架的 整合带宽。另一方面，写操作必须和多个机架上的设备进行网络通信，但是这个代价是我们愿意付出的。

#### 4.3 Creation, Re-replication, Rebalancing

Chunk副本会因为以下三个原因而被创造出来：

- Chunk创建
- 重新复制
- 重新负载均衡

> Chunk replicas are created for three reasons: chunk creation, re-replication, and rebalancing.

关于Chunk创建：

当一个Chunk被Master创建出来的时候，Master需要考虑如下几个因素以决定在哪里放置初始的空副本：

- 我们想将副本放置在硬盘空间利用率低于平均水平的ChunkSever。随着时间的推移这会平衡ChunkSever之间的空间利用率
- 我们想要限制在每个ChunkSever上的“最近”创建数。虽然创建操作本身是廉价的，但是创建操作也意味着随之会有大量的写入数据的操作，因为Chunk在Writer真正写入数据的时候才被创建，而在我们的“追加一次，读取多次”的工作模式下，Chunk一旦写入成功之后就会变为只读的了。
- 综上所述，我们会想把副本放置在多个机架之间。



关于Chunk重新复制：

> The master *re-replicates* a chunk as soon as the number of available replicas falls below a user-specified goal

当可用的副本数跌至用户指定的临界值之下时，Master会重新创建Chunk副本。

发生re-replication的原因可能有：

> This could happen for various reasons: a chunkserver becomes unavailable, it reports that its replica may be corrupted, one of its disks is disabled because of errors, or the replication goal is increased.
>
> 服务器掉了
>
> 服务器没掉但是Chunk坏了或者硬盘坏了
>
> 或者干脆就是用户提高了临界值

当有多个Chunk需要重新复制的时候，它们的优先级由如下的几个因素来决定：

- 它离它的副本数量目标有多远。丢失两个副本的Chunk的优先级比只丢失一个副本的Chunk高
- 优先重新复制最近活跃的（Live）的文件的Chunk，而不是最近刚被删除的文件的Chunk
- 为了最小化失效的Chunk对正在运行的应用程序的影响，我们提高会阻塞客户端程序处理流程的Chunk的优先级。也就是如果有哪个Chunk阻塞住了客户端，先重新复制它的。

Master选定优先级最高的Chunk，然后通过以下方式来克隆Chunk：指示某些ChunkSever直接从某个现存合法副本复制数据。

选择新副本的位置的策略和创建时类似：平衡硬盘使用率、限制同一台 Chunk 服务器上的正在进行的 克隆操作的数量、在机架间分布副本

为了防止克隆流量超过客户端流量，Master限制集群和每个ChunkSever的活跃克隆数。此外，每个ChunkSever通过限制其对源ChunkSever的读请求数目来限制它花费在每个克隆上的带宽。



关于Chunk的负载均衡：

Master会周期性地重新平衡副本：检查当前的副本分布，移动副本以获得更好的磁盘利用率和负载均衡。

通过这个过程，Master可以逐渐填充一个新的ChunkSever，而不是立即用新的块和随之而来的大量写入流量来淹没它。

- 因为我们希望限制在每个ChunkSever上的“最近”创建数，即便这是一个新加入的服务器。

新副本的放置标准和上面讨论的是一致的。

Master还需要选择重新移动哪个现有副本，而它偏向于选择磁盘可用空间低于平均的ChunkSever（来移走副本） ，以平衡磁盘空间利用率。

> In addition, the master must also choose which existing replica to remove. In general, it prefers to remove those on chunkservers with below-average free space so as to equalize disk space usage.

#### 4.4 Garbage Collection

在文件被删除之后，GFS并不会立即回收可用的物理存储空间，而是在周期性的垃圾回收中惰性地做。这样使得系统更简单可靠

> After a file is deleted, GFS does not immediately reclaim the available physical storage. It does so only lazily during regular garbage collection at both the file and chunk levels.

##### *4.4.1 Mechanism*

当应用删除一个文件时，Master将这个行为立即Log下来，但是不会立即回收资源，而是将文件重命名为隐藏文件的形式，新的文件名包含删除时间戳。在Master周期性的对文件系统的命名空间的扫描中，它会删除任何已经存在超过三天的隐藏文件。在此之前，这样的文件都可以使用它们的特别名字（也就是带时间戳的那个）访问到，也可以通过重命名回去的方式撤销删除。而当隐藏文件被删除之后，Master服务器保存的对应的元数据也被抹除。

在相似的周期性的对Chunk命名空间的扫描中，Master会辨别孤儿Chunk（也就是无法从任意文件访问的Chunk）并且删除它们的元数据。

如何辨别出OrphanChunk？

> In a *HeartBeat* message regularly exchanged with the master, each chunkserver reports a subset of the chunks it has, and the master replies with the identity of all chunks that are no longer present in the master’s metadata. The chunkserver is free to delete its replicas of such chunks.

##### *4.4.2 Discussion*

如何辨别垃圾：

> We can easily identify all references to chunks: they are in the file to-chunk mappings maintained exclusively by the master. We can also easily identify all the chunk replicas: they are Linux files under designated directories on each chunkserver.Any such replica not known to the master is “garbage.”

垃圾回收的优点：

- 在组件失败很普遍的大规模分布式系统中很简单和可靠

>  Chunk creation may succeed on some chunkservers but not others, leaving replicas that the master does not know exist. Replica deletion messages may be lost, and the master has to remember to resend them across failures, both its own and the chunkserver’s. Garbage collection provides a uniform and dependable way to clean up any replicas not known to be useful.

- 将垃圾回收的过程融合到了Master常规的后台行为中，比如周期性的命名空间扫描和与ChunkSever的握手。
- 是批量处理的，因此开销被均摊。
- 仅在Master相对空闲的时候做，Master可以更快响应时间敏感的客户端请求。
- 延缓存储空间回收为意外的、不可逆转的删除操作提供了安全保障。（在删除之前还有三天的后悔期）

实践中总结出来的缺点：

- 阻碍用户在存储空间吃紧时对于存储空间的优化。

> hinders user effort to fine tune usage when storage is tight. 

- 不停创建和删除临时文件的应用没办法及时重用空间

解决方法：

- 如果一个已删除的文件被再次显式删除，那么加速空间回收。
- 允许用户在命名空间的不同部分使用不同的复制和回收策略。比如指定某些目录树下面的文件不做复制，删除的文件被即时的、 不可恢复的从文件系统移除。

#### 4.5 Stale Replica Detection

过期副本检测

为什么副本会过期？

> Chunk replicas may become stale if a chunkserver fails and misses mutations to the chunk while it is down.For each chunk, the master maintains a *chunk version number* to distinguish between up-to-date and stale replicas.

无论何时当Master授予一个租约时，Master都会提高chunk版本号，并且通知所有的未过时的副本。Master和这些未过时的副本都将新的版本号记录到它们的持久状态中。这个动作发生在任何客户端得到通知之前，也就是对这个Chunk开始写之前。

如果某个副本所在的Chunk 服务器正好处于离线状态，那么副本的版本号就不会被增加。Master节点在这个ChunkSever重新启动，并且向Master节点报告它拥有的Chunk的集合以及相应的版本号的时候，就会检测出它包含过期的Chunk。

如果Master看到比自己持有的版本号更高的版本号怎么办？问题：为什么会出现ChunkSever的版本号更高的情况？就是分配租约的时候自己寄了？在把新的版本号持久化之前寄了，但是新的版本号已经发给ChunkSever了？

> If the master sees a version number greater than the one in its records, the master assumes that it failed when granting the lease and so takes the higher version to be up-to-date.

Master在周期性的垃圾回收过程中消除所有的过期失效的副本，在那之前它简单的当这些过期的副本不存在，在回复客户端的时候也不会把它们包含在内。

并且，Master在告知客户端哪个ChunkSever持有租约、指示一个ChunkSever从另外一个ChunkSever读取数据做克隆操作的时候，都会在消息中附带版本号。客户端或者服务器在执行操作之前会先确认版本号以确保访问的是最新的版本，这是另外一重保障。

### 5. FAULT TOLERANCE AND DIAGNOSIS

设计系统最大的挑战之一是如何应对频繁的组件失灵。组件的质量和数量使得这个问题不是意外而是常态，我们没有办法完全信任机器也没有办法完全信任硬盘。组件失灵可能导致系统不可用或者数据损坏。这一节讨论如何应对挑战以及内置在系统中的诊断工具

#### 5.1 High Availability

GFS使用两个简单高效的策略来保证系统整体上的高可用性：快速恢复和复制

##### *5.1.1 Fast Recovery*

Master和ChunkSever都被设计成，不管它们是以什么样的方式被终止的，它们都能在几秒钟之内恢复状态重启。

我们不区分服务器的正常终止和异常终止，服务器的关闭一般就是直接把进程杀掉。

在服务器关闭的时候，客户端未完成的请求会超时，然后重新连接到重启后的服务器，然后重试请求。

##### *5.1.2 Chunk Replication*

直接贴原文吧

> As discussed earlier, each chunk is replicated on multiple chunkservers on different racks. Users can specify different replication levels for different parts of the file namespace. The default is three. The master clones existing replicas as needed to keep each chunk fully replicated as chunkservers go offline or detect corrupted replicas through checksum verification (see Section 5.2). Although replication has served us well, we are exploring other forms of cross-server redundancy such as parity or erasure codes for our increasing read only storage requirements. We expect that it is challenging but manageable to implement these more complicated redundancy schemes in our very loosely coupled system because our traffic is dominated by appends and reads rather than small random writes.

##### *5.1.3 Master Replication*

Master的状态同样出于可靠性的目的复制了多份。它的OperationLog和Checkpoint会被复制到多台机器上。

一个对于状态的更改只有在其LogRecord被写入到本地和所有副本的硬盘上之后，才会被看做已提交。

为了简单性，只有一个Master进程负责管理所有的更改以及诸如垃圾回收等各种后台活动。当它失败的时候，几乎可以立即启动。

如果机器或者硬盘出故障，位于GFS外部的监控设施会在其他拥有完整操作日志的机器上重新启动一个新的Master进程。

客户端使用规范名访问Master，这个规范名就类似DNS的别名，因此当Master进程转移到另外一台机器上时，让别名指向新的机器就可以了。



另外一个东西：ShadowMaster，影子Master。

- 影子Master在主Master宕机的时候提供对于文件系统的只读访问。
- 它们是影子，不是镜像，因为它们的数据更新可能会比主Master更慢，通常慢个零点几秒。
- 对于那些不经常改变的文件、或者那些允许获取的数据有少量过期的应用程序，“影子”Master 服务器能够提高读取的效率。

但是实际上因为文件的内容是从ChunkSever上读取的，所以文件的内容是不会过期的，在这滞后的零点几秒里过期的可能是文件的元数据。



影子服务器通过读取操作日志的副本，并且按照日志中的顺序来应用改变，以保证自己的状态是最新的。

> To keep itself informed, a shadow master reads a replica of the growing operation log and applies the same sequence of changes to its data structures exactly as the primary does.

和主Master一样，影子在启动的时候也会轮询每个ChunkSever以得到Chunk的位置信息（之后也会定期拉取），以及与ChunkSever握手以监察他们的最新状态。只有由于Master的决定更改导致的Chunk位置变化需要Master来通知影子。

> It depends on the primary master only for replica location updates resulting from the primary’s decisions to create and delete replicas.

#### 5.2 Data Integrity

每个ChunkSever都使用校验和来检测数据损坏。**不能通过在ChunkSever之间比较副本的内容来检测数据损坏，因为GFS并不保证所有副本在字节尺度上的完全一致**。所以，每个ChunkSever都必须要独立地确定其数据副本的完整性，也要独立维护校验和。

损坏的Chunk副本可以使用其他的副本来恢复。

每个Chunk被分成64KB的小块，每个小块有一个对应的32位的校验和。校验和保存在内存中，通过log持久化存储。

对于读取请求，每个ChunkSever都会在返回任何数据之前，先确认与读取范围重叠的小块的校验和。这样数据损坏就不会被扩散到其他的机器。

如果某个块的校验和对不上记录，那么ChunkSever返回一个Error给请求者，同时给Master报告一个校验和不匹配。

请求者对于Error的应对是从另外一个副本读取，Master则从另外一个副本克隆（做Chunk重新复制）。

在新的副本就位之后，Master指示那个报告不匹配的ChunkSever删除它的副本。

校验和对于读取的性能的影响：

> Checksumming has little effect on read performance for several reasons. Since most of our reads span at least a few blocks, we need to read and checksum only a relatively small amount of extra data for verification. GFS client code further reduces this overhead by trying to align reads at checksum block boundaries. Moreover, checksum lookups and comparison on the chunkserver are done without any I/O, and checksum calculation can often be overlapped with I/Os.

对于在Chunk末尾追加写的校验和计算：只增量更新最后一个不完整的小块的校验和以及新增的小块的校验和（还记得一个Chunk被分成64KB的小块，每个块都有校验和，只更新末尾的那个小块的校验和，以及后面新增的小块的校验和）

> We just incrementally update the check sum for the last partial checksum block, and compute new checksums for any brand new checksum blocks filled by the append.

对于覆盖一个Chunk现有内容范围的覆盖写：先检验和范围重叠的第一个块和最后一个块的校验和，然后再执行写操作，然后再重新计算和记录各个校验和

- 处于第一个和最后一个小块中间的那些小块直接一整个小块全部被覆盖掉了，即使数据损坏也没事，但是第一个和最后一个块可能只是部分的被覆盖，我们不能保证没被覆盖的那一部分不存在损坏，所以要校验一下它们的校验和，校验和对得上的话就说明数据没出错，这个时候才可以开始覆盖写。如果不计算和校验第一个和最后一个块的校验和，假如未被覆盖的部分损坏，那我们就不知道，那么计算新的校验和的时候会把损坏的数据当成完好的数据，于是新的校验和就掩盖了损坏的数据。

在闲暇的时候ChunkSever会对那些不活跃的Chunk做校验和检查。

> During idle periods, chunkservers can scan and verify the contents of inactive chunks. This allows us to detect corruption in chunks that are rarely read. Once the corruption is detected, the master can create a new uncorrupted replica and delete the corrupted replica. This prevents an inactive but corrupted chunk replica from fooling the master into thinking that it has enough valid replicas of a chunk.

#### 5.3 Diagnostic Tools

> GFS servers generate diagnostic logs that record many significant events (such as chunkservers going up and down) and all RPC requests and replies. These diagnostic logs can be freely deleted without affecting the correctness of the system. However, we try to keep these logs around as far as space permits. The RPC logs include the exact requests and responses sent on the wire, except for the file data being read or written. By matching requests with replies and collating RPC records on different machines, we can reconstruct the entire interaction history to diagnose a problem. The logs also serve as traces for load testing and performance analysis. 
>
> The performance impact of logging is minimal (and far outweighed by the benefits) because these logs are written sequentially and asynchronously. The most recent events are also kept in memory and available for continuous online monitoring

## FAQ

> Q: Why is atomic record append at-least-once, rather than exactly once?
>
> Section 3.1, Step 7, says that if a write fails at one of the secondaries, the client re-tries the write. That will cause the data to be appended more than once at the non-failed replicas. A different design could probably detect duplicate client requests despite arbitrary failures (e.g. a primary failure between the original request and the client's retry). You'll implement such a design in Lab 3, at considerable expense in complexity and performance.
>
> 
>
> Q: How does an application know what sections of a chunk consist of padding and duplicate records?
>
> A: To detect padding, applications can put a predictable magic number at the start of a valid record, or include a checksum that will likely only be valid if the record is valid. The application can detect duplicates by including unique IDs in records. Then, if it reads a record that has the same ID as an earlier record, it knows that they are duplicates of each other. GFS provides a library for applications that handles these cases.
>
> 
>
> Q: How can clients find their data given that atomic record append writes it at an unpredictable offset in the file?
>
> A: Append (and GFS in general) is mostly intended for applications that sequentially read entire files. Such applications will scan the file looking for valid records (see the previous question), so they don't need to know the record locations in advance. For example, the file might contain the set of link URLs encountered by a set of concurrent web crawlers. The file offset of any given URL doesn't matter much; readers just want to be able to read the entire set of URLs.
>
> 
>
> Q: The paper mentions reference counts -- what are they?
>
> A: They are part of the implementation of copy-on-write for snapshots.When GFS creates a snapshot, it doesn't copy the chunks, but instead increases the reference counter of each chunk. This makes creating a snapshot inexpensive. If a client writes a chunk and the master notices the reference count is greater than one, the master first makes a copy so that the client can update the copy (instead of the chunk that is part of the snapshot). You can view this as delaying the copy until it is absolutely necessary. The hope is that not all chunks will be modified and one can avoid making some copies.
>
> 
>
> Q: If an application uses the standard POSIX file APIs, would it need to be modified in order to use GFS?
>
> A: Yes, but GFS isn't intended for existing applications. It is designed for newly-written applications, such as MapReduce programs.
>
> 
>
> Q: How does GFS determine the location of the nearest replica?
>
> A: The paper hints that GFS does this based on the IP addresses of the servers storing the available replicas. In 2003, Google must have assigned IP addresses in such a way that if two IP addresses are close to each other in IP address space, then they are also close together
> in the machine room.
>
> Q: What's a lease?
>
> A: For GFS, a lease is a period of time in which a particular chunkserver is allowed to be the primary for a particular chunk. Leases are a way to avoid having the primary have to repeatedly ask the master if it is still primary -- it knows it can act as primary for the next minute (or whatever the lease interval is) without talking to the master again.
>
> 
>
> Q: 64 megabytes sounds awkwardly large for the chunk size!
>
> A: The 64 MB chunk size is the unit of book-keeping in the master, and the granularity at which files are sharded over chunkservers. Clients could issue smaller reads and writes -- they were not forced to deal in whole 64 MB chunks. The point of using such a big chunk size is to reduce the size of the meta-data tables in the master, and to avoid limiting clients that want to do huge transfers to reduce overhead. On the other hand, files less than 64 MB in size do not get much parallelism.
>
> 
>
> Q: What if the master fails?
>
> A: There are replica masters with a full copy of the master state; the paper's design requires some outside entity (a human?) to decide to switch to one of the replicas after a master failure (Section 5.1.3). We will see later how to build replicated services with automatic cut-over to a backup, using Raft.
>
> 
>
> Q: Why 3 replicas?
>
> A: Perhaps this was the line of reasoning: two replicas are not enough because, after one fails, there may not be enough time to re-replicate before the remaining replica fails; three makes that scenario much less likely
>
> 
>
> Q: Did having a single master turn out to be a good idea?
>
> A: That idea simplified initial deployment but was not so great in the long run. This article (GFS: Evolution on Fast Forward,https://queue.acm.org/detail.cfm?id=1594206) says that as the years went by and GFS use grew, a few things went wrong. The number of files grew enough that it wasn't reasonable to store all files' metadata in the RAM of a single master. The number of clients grew enough that a single master didn't have enough CPU power to serve them. The fact that switching from a failed master to one of its backups required human intervention made recovery slow. Apparently Google's replacement for GFS, Colossus, splits the master over multiple servers, and has more automated master failure recovery.
>
> 
>
> Q: What is internal fragmentation? Why does lazy allocation help?
>
> A: Internal fragmentation is the space wasted when a system uses an allocation unit larger than needed for the requested allocation. If GFS allocated disk space in 64MB units, then a one-byte chunk would waste almost 64MB of disk. GFS avoids this problem by allocating disk space lazily. Every chunk is a Linux file, and Linux file systems use block sizes of a few tens of kilobytes; so when an application creates a 1-byte GFS file, the file's chunk consumes only one Linux disk block, not 64 MB













## Lecture

### Storage

整体上讲存储为什么在6.824很重要

- 建造容错系统的重要BuildingBlock

为什么困难？

- 需要高性能
- 会有很多机器（以提高吞吐量和性能）——带来另外一个问题，机器日常出错
- 因此需要容错——Replica，副本
- 由副本所带来的的问题——数据一致性问题
- 如果使用强一致性——可能会降低性能

### Ideal Consistency

简单来讲就是，机器表现的像单个的系统。也是我们想要的表现。

使得我们想要的表现很难达到的两个困难：

- 并发：并发可能会带来数据一致性问题
- failure，故障

### GFS:FS for MapReduce

GFS所具有的的属性：

- Big：large dataset
- Fast
- Global：All APPs See same FS
- Fault Tolerance

#### Master

Master维护的状态信息：

- 映射关系：`<FileName, ArrayOfChunkHandles>`，文件名到ChunkHandle的数组。因为一个文件由多个块组成。
  - 需要持久化保存，否则就丢文件。
- 对于每个ChunkHandle：版本号、持有这个Chunk的副本的Sever的List（其中一个Primary，其他的Secondary）、租用时间。
  - 版本号需要持久化保存在Master：这样Master才能知道最新的版本。假如有一个文件最新版本是15，然后整个系统都寄了，然后Master不保存版本号，假如最新版本的ChunkSever没有重新上线，而一个老一点版本14的ChunkSever上线了，那么Master会误以为最新版本是14。但是如果Master自身保存了版本号，就不存在这个问题。
- OperationLog
  - 持久化保存，在响应客户端之前先把操作持久写入日志。如果不这样做：客户端请求创建文件，Master先响应而不是先写入Log，在创建之前崩溃，于是客户端以为文件已经创建了，但是实际上它不存在，而Master的Log里面也没有记录。
- CheckPoints
  - 持久化保存。
  - 为了减少需要Replay的Log的数目，只需要Replay那些时间上位于CheckPoint之后的Log

#### Reading From GFS

读取：

- 客户端发送给Master的是文件名和偏移量
- Master返回：ListOfChunkSevers、Handle、VersionNumber
- 客户端把收到的信息缓存，然后给最近的ChunkSever S发消息，读取
- 缓存和找最近的ChunkSever都是为了最小化网络流量
- ChunkSever S检查版本号，版本号没问题就发数据

#### Append

- 客户端给Master发消息，想找到ChunkHandle等信息
- Master选择Primary，提升版本号，并把提升后的版本号告知Primary，Primary告知所有Secondary。

> Version Number lives on disk both at Master and ChunkSever

1. 在Primary和所有的Secondary都向Master确认收到版本号并且Primary收到了租约之后，Master将版本号写入硬盘，然后再响应客户端
2. 客户端收到的响应则包含：Primary是谁、List Of Secondary、List Of Severs、VersionNumber
3. 然后客户端选择离自己最近的Secondary发送数据，然后由它链式传输给其他机器。细节见论文精读。
4. 数据发送过去之后并不是直接就追加上去了，而是被缓冲存起来留待使用（LRU队列）
5. 客户端给Primary发送Append消息。Primary检查版本号能不能对上，检查Primary的租约过期了没有，因为如果过期的话可能外面还有另外一个Primary。
6. 版本号对得上且租约没过期的话，Primary选个偏移量，然后把记录写到那个偏移量处（写到硬盘），然后给Secondary们发消息，要他们在同样的偏移量处写同样的内容。
7. 如果所有的Secondary都通知Primary成功写入，Primary自己也成功写入，就回复客户端Success。否则回复Error。
8. 如果回复Error，客户端那边的Library会重试5-7.

问题：重试的时候，Primary选定的偏移量是否还和第一次是相同的？

- 不同。假如第一次，Primary选定偏移量125写入一个记录X，通知Secondary S1 S2 也在此写入，只有S2失败了。重试，成功，那么情况就会如下图，P和S1 S2都会重新追加一遍那个记录（会存在重复记录），而Primary选定的偏移量只能是在125之后的某个值。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301191631226.png" alt="image-20230119163115085" style="zoom:67%;" />

- 这个时候学生问了一个问题，这样是否会导致MapReduce出现重复计数问题，比如做WordCount的时候`<a,1>`写入了两次，然后Reduce的时候会重复计数

- 其他学生和老师的回答：

  - 使用CheckSums、UniqueID来去重
  - 而且客户端并不是直接与GFS交互，它是调库，库会负责在Append的时候加个ID到记录里去，也会在读取的时候对重复记录去重

- > 另外一个学生问的问题：instead of rewriting to every replica wouldn't it be better to remember which replica is failing and to stop until it can be written to that one

> 回答：yeah so there's a bunch of different designs possible let's return to that later um。you know i think one reason that they do this this way is like if there's a prayer you know temporary failure like a network disconnection or whatever you know at least the write will succeed and they will continue and there doesn't have to be any reconfiguration there has to be nothing you know out to the right can just keep going right and so the right doesn't have to fail

#### Consistency

如果Master在分配租约了之后联系不上Primary？他什么时候能再分配租约？

- 只有等旧的租约过期之后才能分配新的，不然可能会同时存在两个Primary
- Master联系不上旧Primary，不代表Client也联系不上它。到时候就存在多个客户端分别联系两个不同的Primary的情况，并发写会出错。

如何实现更强的一致性？改变写策略，要么全部更新，要么都不更新。

> you could instead of like updating the primary and then reporting or making rights visible incrementally it's probably not a good idea right so probably what you want to do is like update all secondary primaries or none but not as in this you know particular design where like somebody get updated and some may not get updated and that's actually visible to the client



# Lecture 4: VM-FT

## 论文 The Design of a Practical System for Fault-Tolerant Virtual Machines


### ABSTRACT

> We have implemented a commercial enterprise-grade system for providing fault-tolerant virtual machines, based on the approach of replicating the execution of a primary virtual machine

这篇Paper介绍基本的思想，讨论可选的替代设计选择，以及一些实现细节

### 1. INTRODUCTION

一种常用的实现容错的服务器的方法是：主从方法（Primary/Backup Approach），Backup在Primary失败时总是可以直接接手。

- Backup服务器的状态必须总是和Primary服务器的状态几乎相同，这样才能保证在Primary Fail的时候Backup能立即接手。
- 以这种方式就可以将失败对外部客户端隐藏，同时没有数据丢失。

在Backup服务器上复制Primary状态的两种方法：

1. 状态转移：几乎持续地将对于Primary状态的所有更改都运输给Backup，包括CPU、内存、I/O设备。这种方法发送状态需要消耗很大的带宽，尤其发送内存状态的改变，消耗可能很大。

> primary 持续地将所有状态（包括 CPU、内存和 I/O 设备等或者整个状态机实例）变化发送给 backup，backup 不需要耗费太多 CPU 资源就可以达到跟 leader 相同的状态，这也导致传输的数据量往往会大很多

2. 复制状态机：将Primary和Backup建模为两台确定性的（处于同步的）状态机，只要保证它们从相同的初始状态开始，然后以同样的顺序接收同样的输入请求，它们就会处于同样的最终状态。
   - 这个方法要求所有的输入操作都是确定性的，但是实践中总会有一些Operation是非确定性的，所以需要传输一些额外的协调信息来保证Primary和Backup是In Sync的。但是传输消耗的带宽要远小于状态转移。

> The idea is to model the servers as deterministic state machines that are kept in sync by starting them from the same initial state and ensuring that they receive the same input requests in the same order. Since most servers or services have some operations that are not deterministic, extra coordination must be used to ensure that a primary and backup are kept in sync

> Two main replication approaches:
>   State transfer
>     Primary executes the service
>     Primary sends state snapshots over network to a storage system
>     On failure:
>       Find a spare machine (or maybe there's a dedicated backup waiting)
>       Load software, load saved state, execute
>   Replicated state machine
>     Clients send operations to primary,
>       primary sequences and sends to backups
>     All replicas execute all operations
>     If same start state,
>       same operations,
>       same order,
>       deterministic,
>       then same end state.
>
> State transfer is conceptually simple
>   But state may be large, slow to transfer over network
>
> Replicated state machine often generates less network traffic
>   Operations are often small compared to state
>   But complex to get right
>   VM-FT uses replicated state machine, as do Labs 2/3/4



使用虚拟机（VM）来作为状态机的载体实现复制状态机的方法。

- VM本身就看做是一个良定义的状态机。
- 此外，使用VM来实现可以隔离硬件的影响。实现软硬分层，不需要修改硬件。
- 使得将VM运行在不同地点的不同物理机上变为可能，可以提供更高的可靠性。

确保Backup虚拟机能够完全一致地执行Primary执行过的操作的技术：

VM-FT基于这个技术，也加入了额外的协议和功能性以建立一个完整的容错系统。VM-FT还会在Backup接手之后在其他可用机器上启动一个新的BackupVM，自动恢复冗余性。

> The base technology that allows us to record the execution of a primary and ensure that the backup executes identically is known as deterministic replay

在论文的时代，VMFT和Replay技术都只支持单处理器虚拟机。不支持多处理器是因为其不确定性带来的性能问题。



只支持Fail-Stop Failure：

> Similar to most other practical systems discussed, we only attempt to deal with fail-stop failures, which are server failures that can be detected before the failing server causes an incorrect externally visible action

文章结构：

> The rest of the paper is organized as follows. First, wedescribe our basic design and detail our fundamental protocols that ensure that no data is lost if a backup VM takesover after a primary VM fails. Then, we describe in detail many of the practical issues that must be addressed tobuild a robust, complete, and automated system. We alsodescribe several design choices that arise for implementing fault-tolerant VMs and discuss the tradeoffs in these choices.Next, we give performance results for our implementation for some benchmarks and some real enterprise applications.Finally, we describe related work and conclude

### 2. BASIC FT DESIGN

本节内容：

> In the following sections, we provide more details on several important areas. In Section 2.1, we give some details on the deterministic replay technology that ensures that primary and backup VMs are kept in sync via the information sent over the logging channel. In Section 2.2, we describea fundamental rule of our FT protocol that ensures that no data is lost if the primary fails. In Section 2.3, we describe our methods for detecting and responding to a failure in acorrect fashion.

如下图，对于每一个我们想要提供容错的VM（也即Primary），我们在另外一台物理服务器上运行backupVM，这个BackupVM与Primary保持同步，并且与PrimaryVM的执行完全一致，只不过会在时间上稍微滞后一点。我们称两台机器虚拟步调一致。

- 两台VM使用的虚拟硬盘处于共享的存储上，于是Primary和Backup都能共享输入和输出。4.1节会讨论另外一种设计：Primary和Backup使用独立的非共享的虚拟硬盘。

- 只有PrimaryVM会在网络上宣布自己的存在，所以所有的网络输入流量都流向Primary，相似的，所有的其他输入，比如鼠标键盘输入，也只流向PrimaryVM。
- PrimaryVM收到的所有的输入都会通过网络连接发送给BackupVM，这个网络连接叫做LoggingChannel。
  - 问题：为什么不是通过共享的存储来传递？是否是因为硬盘I/O开销太大了？

- 服务器工作负载的中，占据主要地位的输入流量是网络和磁盘。用于确保BackupVM以和Primary相同方式执行非确定性操作的额外信息也会传输。
- BackupVM的输出会被监视器抛弃，只有Primary的输出会被返回给客户端
- 如何检测出Primary或者Backup Failure：使用心跳消息和监测LoggingChannel上的流量

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301241729199.png" alt="image-20230124172943048" style="zoom:67%;" />

#### 2.1 Deterministic Replay Implementation

确定性重放

除了VM的各种输入，比如网络包、硬盘读取、键盘鼠标输入会改变VM的状态以外，非确定性的事件（比如虚拟中断）、非确定性的操作（比如读取CPU的时钟周期计数器）也会影响VM的状态。这给复制运行任意操作系统和工作负载的任意VM的执行带来了三个挑战：

- 正确捕获所有的输入，以及保证BackupVM确定性执行所必要的不确定性。
- 在BackupVM上正确地应用输入和不确定性
- 在不降低性能的要求之下执行上述两个要求

> (1) correctly capturing all the input and non-determinism necessary to ensure deterministic execution of a backup virtual machine
>
> (2) correctly applying the inputs and non-determinism to the backup virtual machine, and (3) doing so in a manner that doesn't degrade performance. 
>
> In addition, many complex operations in x86 microprocessors have undefined, hence non-deterministic, side effects. Capturing these undefined side effects and replaying them to produce the same state presents an additional challenge

VMware的确定性重放就提供了如上的功能性，它会记录VM的所有输入以及与VM的执行关联的所有非确定性，以LogEntry流的形式写入Log中。

通过读取Log文件就可以准确重放VM的执行。对于非确定性的操作，会记录足够的信息，以保证在重放时这个操作会产生完全一致的状态改变以及输出。对于非确定性的事件，比如计时器或者I/O完成中断，事件出现时执行的指令会被Log下来，在Replay时，会在指令流的相同节点推送事件（就是记录一下事件出现时正在执行哪条指令，然后Replay的时候在相同的时间点上推送事件）。

> For non-deterministic operations, sufficient information is logged to allow the operation to be reproduced with the same state change and output.For non-deterministic events such as timer or IO completion interrupts, the exact instruction at which the event occurred is also recorded.During replay, the event is delivered at the same point in the instruction stream.

#### 2.2 FT Protocol

对于VMFT，我们使用确定性重放产生LogEntry来记录Primary的执行，但是产生的日志项不是写入硬盘中，而是通过LoggingChannel发送给BackupVM。而BackupVM会实时执行收到的Log，因而能够做到和PrimaryVM完全一致的执行。

要在LoggingChannel上执行严格的FT协议，要满足如下要求：

- 输出要求：如果BackupVM在PrimaryVM故障之后接管，那么BackupVM必须以一种与Primary已经发送给外界的输出完全一致的方式继续运行。

> **Output Requirement**: if the backup VM ever takes over after a failure of the primary, the backup VM will continue executing in a way that is entirely consistent with all outputs that the primary VM has sent to the external world

保证输出要求的方法：延迟Primary的输出，直到Backup收到的Log信息至少足以它Replay的时候能够Play到这个输出操作。其中一个必要条件就是BackupVM此前必须已经收到了在这个输出操作之前生成的所有的LogEntry。

> The Output Requirement can be ensured by delaying any external output (typically a network packet) until the backupVM has received all information that will allow it to replay execution at least to the point of that output operation.One necessary condition is that the backup VM must have received all log entries generated prior to the output operation. These log entries will allow it to execute up to the point of the last log entry

但是这样还不够，万一通过LoggingChannel传输的时候丢包了，然后Primary又恰好在发出了Log之后宕机了呢？这时候Backup在Replay之后就会和Primary的状态对不上。

> 举个例子：假设虚拟机运行的是数据库，主机备机的数据都是 10。现在客户端发送自增请求，主机做了 +1 并回复给客户端 11，之后马上宕机了，更糟糕的是主机发送给备机的 +1 操作也丢包了。这时候备机还是10，并接管了主机的工作，客户端再次请求+1（注意是再次请求，而不是重试请求），又会收到 11 的回复。客户端会得到一个怪异的结果(自增两次还是11)

因此这需要新的措施来确保LoggingChannel传输的时候没有丢包，使得用于保证输出要求的方法生效，Backup收到了截止输出之前的完整的Log，才能保证输出要求生效。

最简单的方法：对于每个输出操作，创建一个特殊的日志项。然后，输出要求就能被下面的要求实现：

输出规则：PrimaryVM不能向外界发送输出，直到BackupVM收到并且确认了与产生这个输出相关联的操作的LogEntry

> **Output Rule**: the primary VM may not send an output to the external world, until the backup VM has received and acknowledged the log entry associated with the operation producing the output

如果BackupVM已经收到所有的LogEntry，包含输出产生操作的LogEntry，那么BackupVM就可以准确复现PrimaryVM在那个输出点时的状态，于是如果Primary寄了，Backup就能正确到达与输出一致的状态。相反，如果备份VM在没有接收到所有必要的日志项的情况下接管，则其状态可能会很快发生变化，从而与主VM的输出不一致。

注意，输出规则并没有说什么停止PrimaryVM的执行，我们只需要延迟输出的发送，但是VM其自身是可以继续执行的。



FIG2举了一个例子，直接贴原文：

> As an example, we show a chart illustrating the requirements of the FT protocol in Figure 2. This figure shows a timeline of events on the primary and backup VMs. The arrows going from the primary line to the backup line represent the transfer of log entries, and the arrows going from the backup line to the primary line represent acknowledgments. Information on asynchronous events, inputs, and output operations must be sent to the backup as log entries and acknowledged. As illustrated in the figure, an output to the external world is delayed until the primary VM has received an acknowledgment from the backup VM that it has received the log entry associated with the output operation.Given that the Output Rule is followed, the backup VM will be able to take over in a state consistent with the primary's last output

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301242218858.png" alt="image-20230124221835690" style="zoom:67%;" />

我们没有办法保证所有的输出都只产生一次，因为我们没有办法在不使用2PC事务的情况下，让BackupVM确定Primary是在发出输出之前还是发出输出之后就立即崩溃的。

#### 2.3 Detecting and Responding to Failure

如果BackupVM故障，那么PrimaryVM就会立即Go Live——停止向LoggingChannel发送日志，开始正常运行。相似的，如果Primary故障，BackupVM会立即Go Live，但是这个过程会复杂一点，因为延迟的原因，BackupVM很可能会有一些已经收到并确认，但是还没执行的LogEntry。当BackupVM吸收了最后一个LogEntry之后，它就停止重放模式，开始作为一个正常的VM运行。这本质上就是将BackupVM提升为了PrimaryVM（并且它现在缺少一个BackupVM）。因为它不再是一个BackupVM了，它会对外部世界产生输出，也会在网络上公开宣布自己的存在（广播Mac地址）。



检测PrimaryVM和BackupVM Failure的方法：

- Primary和Backup之间的UDP心跳消息
- 监管LoggingChannel上的流量

> VMware FT monitors the logging traffic that is sent from the primary to the backup VM and the acknowledgments sent from the backup VM to the primary VM. Because of regular timer interrupts, the logging traffic should be regular and never stop for a functioning guest OS. Therefore, a halt in the flow of log entries or acknowledgments could indicate the failure of a VM. A failure is declared if heartbeating or logging traffc has stopped for longer than a specific timeout(on the order of a few seconds)

如果心跳消息或者LoggingTraffic超时，那么宣称发现VM故障。

但是上面的方法都会受分裂脑问题的困扰：

举个例子：

> If the backup server stops receiving heartbeats from the primary server, that may indicate that the primary server has failed, or it may just mean that all network connectivity has been lost between still functioning servers. If the backup VM then goes live while the primary VM is actually still running, there will likely be data corruption and problems for the clients communicating with theVM. 

因此，我们必须保证，在检测到故障的时候，只有Primary和Backup的其中之一会Go Live。

方法：概括一下就是，在共享存储上做原子性的TestAndSet，谁成功了谁上，说白了就是加锁，拿到锁的上。如果访问不到共享存储，那就等到可以访问，如果真访问不到，那就寄。

> To avoid split-brain problems, we make use of the shared storage that stores the virtual disks of the VM. When either a primary or backup VM wants to go live, it executes an atomic test-and-set operation on the shared storage. If the operation succeeds, the VM is allowed to go live. If the operation fails, then the other VM must have already gone live, so the current VM actually halts itself (“commits suicide”). If the VM cannot access the shared storage when trying to do the atomic operation, then it just waits until it can. Note that if shared storage is not accessible because of some failure in the storage network, then the VM would likely not be able to do useful work anyway because the virtual disks reside on the same shared storage. Thus, using shared storage to resolve split-brain situations does not introduce any extra unavailability.



当Primary和Backup的其中一台发生故障，另外一台都会Go Live，然后自动在新的机器上重新启动一个新的BackupVM。

> One final aspect of the design is that once a failure has occurred and one of the VMs has gone live, VMware FT automatically restores redundancy by starting a new backup VM on another host. Though this process is not covered in most previous work, it is fundamental to making fault-tolerant VMs useful and requires careful design. More details are given in Section 3.1.

### 3. PRACTICAL IMPLEMENTATION OF FT

#### 3.1 Starting and Restarting FT VMs

启动和重启VM的机制：用于启动一个与Primary同样状态的BackupVM。同时也用于重启BackupVM。

- 这个机制需要适用于处于任意状态下的Primary（而不只是处于启动中状态的）
- 不能对Primary的运行产生明显的干扰。否则可能会影响Primary当前的客户端。

方法：修改过的VMotion，使得一个运行中的VM迁移到另外一台服务器的过程中断最小，一般不超过一秒。

- 直接在远程主机上克隆源VM，而不是迁移这台VM。
- VMotion还会设置一个LoggingChannel，使得源VM作为Primary，进入Logging模式
- 目的地VM则作为BackupVM，进入Replay模式。
- 中断也不超过一秒。

启动一个BackupVM的另外一个方面：选择哪一台服务器来运行BackupVM？原文：

> Another aspect of starting a backup VM is choosing a server on which to run it. Fault-tolerant VMs run in a cluster of servers that have access to shared storage, so all VMs can typically run on any server in the cluster. This flexibility allows VMware vSphere to restore FT redundancy even when one or more servers have failed.

当需要一个新的BackupVM时怎么做：

> VMware vSphere implements a clustering service that maintains management and resource information. When a failure happens and a primary VM now needs a new backup VM to re-establish redundancy, the primary VM informs the clustering service that it needs a new backup. The clustering service determines the best server on which to run the backup VM based on resource usage and other constraints and invokes an FT VMotion to create the new backup VM. The result is that VMware FT typically can re-establish VM redundancy within minutes of a server failure, all without any noticeable interruption in the execution of a fault-tolerant VM

#### 3.2 Managing the Logging Channel

- hypervisors为Primary和Backup各维护一个大LogEntry缓冲池。
- Primary向自己的缓冲池填充LogEntry，Backup则从自己的缓冲池消耗LogEntry
- Primary的缓冲池中的内容会尽可能快地被刷新到LoggingChannel中去
- LogEntry一到达就会被Backup从LoggingChannel中读取到缓冲池内。
- 每次Backup从网络中读取一些LogEntry到缓冲池，它就向Primary发送ACK。这些ACK使得VMFT可以决定什么时候可以放出被OutputRule延迟的输出。
- 一旦BackupVM的缓冲池变空，它就停止运行，直到有新的LogEntry到来。不会对外界有任何影响，因为Backup本身就不与外界交流。
- 一旦PrimaryVM的缓冲池变满，**它就停止运行**，直到缓冲池中的LogEntry被刷新出去。这是一个很自然的流量控制机制，能够在Primary产生Log的速度过快时将它降速。但是Primary暂停运行会导致它变得无法响应外界客户端，所以必须最小化Primary缓冲池被填满的可能性。
  - 产生缓冲池填满的一个可能原因是Backup吸收LogEntry的速度太慢，所以要保证Primary产生Log的速度和Backup消耗的速度大体相同。
  - 但是如果BackupVM的服务器的负载太大，Backup可能没办法得到足够的CPU时间和内存资源，没办法赶上Primary的速度。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301271609867.png" alt="image-20230127160932702" style="zoom:67%;" />

我们为什么不希望执行滞后太久？

> Beyond avoiding unexpected pauses if the log buffers fill up, there is another reason why we don't wish the execution lag to become too large. If the primary VM fails, the backupVM must “catch up” by replaying all the log entries that it has already acknowledged before it goes live and starts communicating with the external world. The time to finish replaying is basically the execution lag time at the point of the failure. so the time for the backup to go live is roughly equal to the failure detection time plus the current executionlag time. Hence, we don't wish the execution lag time to be large (more than a second), since that will add significant time to the failover time.

确保Backup不会落后Primary太多，导致Lag太长的流量控制的额外机制：

- 如果BackupVM开始变得有一个极长的Lag（比如一秒），那么VMFT通过指示调度器略微减少给Primary的CPU时间，以降低Primary的速度。
- 使用一个反馈循环，一点一点逐步减少Primary的CPU时间，试图精确确定使得Primary和Backup的运行速度能够相互匹配的临界值。

>  If the backup VM continues to lag behind, we continue to gradually reduce the primary VM's CPU limit.Conversely, if the backup VM catches up, we gradually increase the primary VM's CPU limit until the backup VM returns to having a slight lag.

像这种Primary的降速很罕见，基本上只会发生在系统压力极大的时候。

#### 3.3 Operation on FT VMs

可能会应用于VM的一些控制操作，比如Primary显式关机时，Backup也应该关机而不是试图GoLive。再比如，任何在Primary上的资源管理改动（比如提高CPU时间），都应该应用于Backup。对于这些操作，特殊的ControlEntry会被通过LoggingChannel发送给Backup。

- 操作先在Primary上启动，然后再通过LoggingChannel发送必要的ControlEntry，以使得BackupVM产生合适的改变。
- 只有虚拟机的克隆操作可以独立地在Primary和Backup之间发生。

> In general, most operations on the VM should be initiated only on the primary VM. VMware FT then sends any necessary control entry to cause the appropriate change on the backup VM. The only operation that can be done independently on the primary and backup VMs is VMotion. That is, the primary and backup VMs can be VMotioned independently to other hosts. Note that VMware FT ensures that neither VM is moved to the server where the other VM is, since that situation would no longer provide fault tolerance.

PrimaryVM的VMotion：等待所有的I/O操作都完成，将这些完成的I/O操作发给Backup，然后再开始VMotion。

BackupVM的VMotion：通过LoggingChannel向Primary发送消息，请求Primary暂停所有的I/O，Backup自身也会很自然地Replay这个操作，暂停I/O。然后再开始VMotion。

#### 3.4 Implementation Issues for Disk IOs

某些磁盘I/O的不确定性：

- 由于硬盘访问是非阻塞的，所以可以并行访问，对于同一个硬盘位置的连续访问可能会导致不确定性
- 由于硬盘访问是使用DMA直接从虚拟机的内存来去，访问同一个内存页的磁盘操作也会导致不确定性。

解决方法：检测出这样的竞态条件，然后强制这些操作在Primary和Backup上都以同样的方式顺序执行。



**问题 2：虚拟机上的应用程序(或操作系统)的磁盘操作也可能导致内存的竞争**

解决方案：通过 Bounce buffer—— 一个和磁盘操作正在访问的内存大小一致的临时缓冲来解决。磁盘读操作被修改为在 bounce buffer 中读取特定数据，并且数据仅在IO操作完成并传递完成的时候拷贝到虚拟机内存。类似的，对于磁盘写操作，将要被发送的数据会先拷贝到 bounce buffer，磁盘写操作修改为写数据到 bounce buffer。

Bounce buffer 的使用会减慢磁盘操作，但是论文表示还没有看到任何明显的性能差异。

**问题3：磁盘 IO 因主机故障在主机上没有完成，备份接管后怎么办?**

解决方案：发送错误来表明 IO 失败，然后重试错误的 IO。

#### 3.5 Implementation Issues for Network IO（留坑）

### 4. DESIGN ALTERNATIVES

一些设计上的替代方案

#### 4.1 Shared vs. Non-shared Disk

在默认的设计中，Primary和Backup是共享同一个虚拟硬盘的，所以在发生故障切换的时候，硬盘上的内容很自然地就是可用和正确的。

本质上来说，共享的硬盘是属于外部世界的，所以对于共享硬盘的任意写都看作是与外界的通信，所以只有Primary写硬盘，并且写的输出要遵循OutputRule

**如果使用非共享的虚拟硬盘**：

- Backup实际上也会向它自身的虚拟硬盘写入，因为只有这样才能保证两个虚拟机的硬盘上的内容是同步的。在非共享的情况下，虚拟机的虚拟硬盘被看做是每个虚拟机内部状态的一部分。所以Primary对硬盘的写入不需要遵循OutputRule。
- 在共享存储不可用时的情况下的有用选项。

缺点：

- 两个虚拟硬盘必须要显式同步
- 两个硬盘可能会因为故障失去同步，所以在故障后重启BackupVM时需要显式进行再同步。FT VMotion除了要同步Primary和Backup的运行状态，还要同步它们俩的硬盘状态。
- 没有共享存储，不能使用TestAndSet来解决分裂脑问题。引入外部的第三方Tiebreaker，比如一个两个VM都能通信的第三方服务器。

#### 4.2 Executing Disk Reads on the Backup VM

在BackupVM上执行硬盘读取



默认的设计上，BackupVM从不从它自己的硬盘上读取，无论是否共享硬盘。因为硬盘读取看作是输入，所以它很自然的是由Primary读，然后通过LoggingChannel发送给Backup



替代选择：让Backup也执行硬盘读取。这样可以消除Logging中硬盘读取数据的Log。对于硬盘读取密集型的负载，可以极大减少LoggingChannel上的流量。

问题：

- 由于BackupVM要执行所有的读取，所以会减慢Backup的运行速度。
- 如果在Primary上读取成功了，在Backup上读取失败了，怎么办（反之亦然）？必须做一些额外的工作来处理这个问题。
- 如果将这个方案应用在共享虚拟硬盘上，如果Primary读取硬盘某个位置，随后Primary想要在同样的位置写入，那么这个写入必须被延迟，因为要等待BackupVM读取完毕（必须保证两个VM读取的内容是一致的，所以要延迟写入）。这种情况可以解决，但是会给系统的实现带来额外的复杂性。

评价：VMware 的性能评估显示，在备机上执行磁盘读取会降低 1-4% 的吞吐量，但同时也降低了日志带宽

## Lecture

 今天的内容：

- 哪些故障可以使用主从复制来进行容错
- 备份方法存在的挑战：
- 两种方法：状态传输和复制状态机（Paper，GFS也是使用第二种）
- Case Study：VM-FT

### 第一个话题

- Fail-Stop Failure：如果有一个故障或者计算机的一个组件没用了，这个问题会导致计算机停止。
  - 当计算机工作的时候，它就是在正确工作的。当出现错误的时候，计算机就直接停止。
  - 比如计算机风扇寄了，计算机散热不足，过热关机。比如有人绊了一下电源线，电脑断电了。
  - 不包含：
    - 逻辑错误，比如软件逻辑错误，除零。Backup并不能处理这样的错误，因为Backup也会做同样的事，如果软件在Primary上出错，也就会在Backup上出错，主从复制并不能解决这个问题。
    - 配置错误。
    - 恶意错误。比如外部攻击，恶意发送的错误消息。
  - 可能包含的：比如地震，如果主和从在地理上不处于同一个板块，就有可能。但是我们这里讨论的一般是主和从都在同一个数据中心，如果数据中心寄了，那么就寄。

### 第二个话题

建立主从复制容错系统时，一般会出现的问题和挑战

第一个问题：

- 如果一个故障发生，Primary是否真的已经失败了？带来这个挑战的问题是，分布式系统并不能分辨出一个故障的发生是网络问题，还是真的机器故障了。Primary正在正常工作，只不过由于网络问题有些服务器没有办法与Primary通信也是完全也可能的，这种情况下Backup会认为Primary已经死了然后决定接手，但是Primary实际上还活着。
- 也就是所谓的Split-Brain 问题。两个Primary，一部分服务器与其中一个Primary通信，另外一部分服务器与另外一个通信。这样显然会让系统的状态产生分歧，于是当网络恢复的时候，我们会处于不正确的状态。

第二个问题：

- 如何保证Primary和Backup同步（How to keep Primary And Backup in sync?）
  - 如果Primary失败，故障转移到Backup时，Backup能从Primary离开的地方捡起来继续。
- 这需要：以同样的顺序应用更改、避免不确定性（同一个操作在主和从上结果不一样）
- 故障转移：如果Primary处于一个操作的中途就寄了，那么Backup接手之后如何处理？
- 如果我们有多个Backup，那么谁才是最新的？今天不是问题。



### 第三个话题

状态转移（State Transfer）：

- 类似时不时地建立一个Primary的状态的检查点，然后把检查点发给Backup。
- 如果要保证主从同步，那么每次Primary进行一个操作的时候，在它响应客户端之前，要把操作造成的状态改变发送给Backup

Replicated State Machine(RSM)：

客户端与Primary通信，Primary把它进行过的操作发给Backup，Backup执行同样的操作，改变其状态，给Primary发送ACK，Primary改变自身状态，然后响应客户端。**当然，要保证操作是确定性的，所以挑战之一是避免不确定性**

> picture is we got the primary, we got the clients, they're talking to the primary and of course you know we have the primary talking to the backup to keep the backup in sync. But instead it was sending the state changes or the modifications to the state from the primary to the backup what we do actually we sent the operations to the backup. So before the primary response to the client executing its operation, we sent the operation that the client sent to us to the backup, so the backup can execute the operation to updates its state, acknowledge it to the primary, primary actually updates it's state too , executes the operation and then sends the response back to the client 

两种方法其实做的都是同一件事情：Primary处于某个状态，我们改变这个状态，然后我们对Backup做同样的改变（无论是用状态传输还是操作）。

> the scheme is like the primaries of some particular state, we apply changes to the state and we do exactly the same thing at the backup, so the backup starts out in the same state as the primary,  we apply the same changes to the state whether it's through an operation or state transfer,  we end up in a new state and that state has to be identical to the state that the primary has. So if then ever there's a failure, we know that when we failover to the backup and it's exactly in the same state as the primary and so it can take over 

第一种方法的主要缺点：所以大部分使用第二个方法，比如GFS，发送Append操作给Replicas，而不是发送Append的结果。

> The primary disadvantage of the state transfer approach is that if an operation generates a lot of state then it's going to be expensive. Like if a single operation writes a gigabyte of data then that gigabyte of data needs to be transferred to a backup and it might be much more less expensive to basically just send over the operation to the backup.

学生的问题一：你怎么知道所有程序的所有操作都是确定性的？典型的方法：就只允许确定性操作。稍后讲怎么做

#### Level of Operations to Replicate?

在哪个层级上复制操作？

- Application Level
- Machine Level,or Processor Level（指令、寄存器、内存状态，“操作”就是普通的机器指令）



### VM-FT

利用虚拟化，使得这个Replication透明。在客户端看来，就是只有一台机器

VMMonitor，也叫Hypervisor，负责将一块硬件模拟出有多块硬件的样子，运行多台虚拟机，任意一台虚拟机都建立于Hypervisor的基础之上。实际硬件的外部中断能够被Hypervisor捕获，这也是VM-FT能够复制中断的基础。

任意来自硬件的中断，都会先发给Hypervisor，然后由它决定什么时候发给虚拟机。在VM-FT的情况下，还会通过LoggingChannel发给Backup，Backup的动作一样。

虚拟机的输入和输出都由Hypervisor来代理负责与实际的硬件通信，Backup的Hypervisor会丢弃VM的输出，而Primary的则会负责向硬件发送输出。

共享存储部分：一个StorageSever，通过网络访问，会记录谁是Primary

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301281824952.png" alt="image-20230128182400728" style="zoom:67%;" />

目标：Behave Like a Single Machine

#### Divergence Sources

会导致不确定性的源：

- 非确定性机器指令：比如获取时间，Primary和Backup可能不是完全同时启动的，获取的时间会有所差异。
- 输入/中断：都必须要在指令流的同一位置发出
- 并发：比如双核，双线程竞争同一个锁，没办法保证在Primary上拿到锁的线程和在Backup上拿到锁的线程是同一个核上的线程

#### Interrupts

在VM-FT中，只有那些可能会导致不确定性的指令会通过LoggingChannel传输。

Backup Lag Behind Primary ONE Message of Logging Channel。



对于不确定性指令的处理：VM-FT在运行二进制文件之前，先过一遍整个二进制文件的指令，记录下来那些不确定性指令，将它们标记为非法指令。

然后在执行到不确定性指令的时候：

- Primary：控制转移给Hypervisor，Hypervisor负责执行那条不确定性指令，并把指令产生的结果和效果发送给Backup
- Backup：执行到相同指令的时候，Hypervisor从收到的消息中拿结果和效果，应用于虚拟机。

Q&A：

> Q: sorry so that happens um like the modification of the binary it happens when it creates the virtual machine?
>
> A:  yeah we think about it when it boots the vm
>
> 
>
> Q: so the the backup re-executes the the non-deterministic instruction and then just verifies the result?
>
> A: no what it actually does is if the virtual machine monitor executes the instruction and then you know uh or actually the virtual machine model doesn't execute the instruction at all. it knows that this instruction needs to be executed and it knows what things will be changed like what registers need to be updated as a result of this uh instruction and it sticks the value from the message into the right register so that the uh you know the linux running on the backup sees exactly the same effect as the the linux running on the primary
>
> 
>
> Q: this assumes that the hypervisor will do some work before even uh or while putting up the vm just because of where the locations of these non-determinations 
>
> A: oh yeah yeah I'm wishing any hypervisor does to these days

## FAQ

> Q: The introduction says that it is more difficult to ensure deterministic execution on physical servers than on VMs. Why is this the case?
>
> A: Ensuring determinism is easier on a VM because the hypervisor emulates and controls many aspects of the hardware that might differ between primary and backup executions, for example the precise timing of interrupt delivery
>
> 
>
> Q: What is a hypervisor?
>
> A: A hypervisor is part of a Virtual Machine system; it's the same as the Virtual Machine Monitor (VMM). The hypervisor emulates a computer,
> and a guest operating system (and applications) execute inside the emulated computer. The emulation in which the guest runs is often called the virtual machine. In this paper, the primary and backup are guests running inside virtual machines, and FT is part of the hypervisor implementing each virtual machine.
>
> 
>
> Q: Both GFS and VMware FT provide fault tolerance. How should we think about when one or the other is better?
>
> A: FT replicates computation; you can use it to transparently add fault-tolerance to any existing network server. FT provides fairly strict consistency and is transparent to server and client. You might use FT to make an existing mail server fault-tolerant, for example.
>
> GFS, in contrast, provides fault-tolerance just for storage. Because GFS is specialized to a specific simple service (storage), its replication is more efficient than FT. For example, GFS does not need to cause interrupts to happen at exactly the same instruction on all replicas. GFS is usually only one piece of a larger system to implement complete fault-tolerant services. For example, VMware FT itself relies on a fault-tolerant storage service shared by primary and backup (the Shared Disk in Figure 1), which you could use something like GFS to implement (though at a detailed level GFS wouldn't be quite the right thing for FT)
>
> 
>
> Q: What is "an atomic test-and-set operation on the shared storage"?
>
> A: The system uses a network disk server, shared by both primary and backup (the "shared disk" in Figure 1). That network disk server has a
> "test-and-set service". The test-and-set service maintains a flag that is initially set to false. If the primary or backup thinks the other server is dead, and thus that it should take over by itself, it first sends a test-and-set operation to the disk server. The server executes roughly this code:
>
> ```python
> test-and-set() {
>     acquire_lock()
>     if flag == true:
>     	release_lock()
>     	return false
>     else:
>     	flag = true
>     	release_lock()
>     	return true
> ```
>
> The primary (or backup) only takes over ("goes live") if test-and-set returns true.
>
> The higher-level view is that, if the primary and backup lose network contact with each other, we want only one of them to go live. The danger
> is that, if both are up and the network has failed, both may go live and develop split brain. If only one of the primary or backup can talk to the disk server, then that server alone will go live. But what if both can talk to the disk server? Then the network disk server acts as a tie-breaker; test-and-set returns true only to the first call.
>
> 
>
> Q: What if the application calls a random number generator? Won't that yield different results on primary and backup and cause the executions to diverge?
>
> A: FT arranges that the primary and backup get the same number from their random number generators. All the sources of randomness are controlled by the hypervisor. For example, the application may use the current time, or a hardware cycle counter, or precise interrupt times as sources of randomness. In all three cases the hypervisor intercepts the the relevant instructions on both primary and backup and ensures they produce the same values.
>
> 
>
> Q: What happens if the primary fails just after it sends output to the external world?
>
> A: The backup will likely repeat the output after taking over, so that it's generated twice. This duplication is not a problem for network and disk I/O. If the output is a network packet, then the receiving client's TCP software will discard the duplicate automatically. If the output event is a disk I/O, disk I/Os are idempotent (both write the same data to the same location, and there are no intervening I/Os).
>
> 
>
> Q: How is the backup FT able to deliver an interrupt at a particular point in the backup instruction stream (i.e. at the same instruction at which the interrupt originally occured on the primary)?
>
> A: Many CPUs support a feature (the "performance counters") that lets the FT VMM tell the CPU a number of instructions, and the CPU will interrupt to the FT VMM after that number of instructions.
>
> 
>
> Q: The paper says FT doesn't cope with multi-processor guests. Why not?
>
> A: In general, the results of software running on multiple processors depends on exactly how the instruction streams on the processors were
> interleaved. For FT to ensure that the backup stays in sync with the primary, it would have to cause the interleaving to be the same on both computers. This turns out to be hard: you can't easily find out what the interleaving is on the primary, and you can't easily control it on either machine
>
> A more recent VMware product replicates multi-processor guests,probably using a different technique (replicating memory snapshots rather than operations?).
>
> 
>
> Q: Suppose server S1 is acting as primary, and S2 as backup. The network link between them stops working. S2 sees that it can no longer talk to S1 and "goes live", taking over as sole server after successfully acquiring the test-and-set lock. Will S1 be aware that S2 has gone live? Or could S1 continue operating, thus producing "split brain"?
>
> A: S1 may indeed not realize what is happening, and clients may continue to send requests to S1 for a while. However, the next time S1 wants to produce output (to a client or the shared disk), the Output Rule requires S1 to wait for S2 to acknowledge all outstanding log entries. S2 won't acknowledge; even if S1 and S2 can communicate, S2 knows that since it is no longer the backup, it should not respond to S1's log entries. So S1 will not be able to generate any output after S2 has decided to go live. So the fact that S1 may think it is still the primary does not actually produce split brain.
>
> This pattern, in which a primary is forced to stop if can't get its backups to acknowledge that it is still the primary, arises in many replication systems as part of the story for preventing split brain

# Lecture 5:Fault Tolerance:Raft(1)

## In Search of an Understandable Consensus Algorithm (Extended Version)

### Abstract

Raft

> Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, and it is as efficient as Paxos, but its structure is different from Paxos; this makes Raft more understandable than Paxos and also provides a better foundation for building practical systems.

#### 1 Introduction

共识算法使得一组机器的集合能够作为一个一致的群组工作，并且群组能从部分成员的故障中幸存下来。

> Consensus algorithms allow a collection of machines to work as a coherent group that can survive the failures of some of its members

Paxos在过去的十年里主导了对于共识算法的讨论：大部分的共识算法的实现都基于Paxos或受Paxos影响，并且它也是用于教授共识的主要工具。

但是，Paxos很难理解，并且需要对它的架构进行复杂的修改才能支持实践上的系统。所以不管是学生还是系统建造者都在与Paxos苦苦斗争。

Raft就产生于这样的背景下。

> After struggling with Paxos ourselves, we set out to find a new consensus algorithm that could provide a better foundation for system building and education. 

相较于其他共识算法，Raft的新特性：

> Raft is similar in many ways to existing consensus algorithms (most notably, Oki and Liskov’s Viewstamped Replication [29, 22]), but it has several novel features:
>
> • Strong leader: Raft uses a stronger form of leadership than other consensus algorithms. For example,log entries only flow from the leader to other servers.This simplifies the management of the replicated log and makes Raft easier to understand.
>
> • Leader election: Raft uses randomized timers to elect leaders. This adds only a small amount of mechanism to the heartbeats already required for any consensus algorithm, while resolving conflicts simply and rapidly.
>
> • Membership changes: Raft’s mechanism for changing the set of servers in the cluster uses a new *joint consensus* approach where the majorities of two different configurations overlap during transitions. This allows the cluster to continue operating normally during configuration changes.

论文结构：

> The remainder of the paper introduces the replicated state machine problem (Section 2), discusses the strengths and weaknesses of Paxos (Section 3), describes our general approach to understandability (Section 4), presents the Raft consensus algorithm (Sections 5–8), evaluates
>
> Raft (Section 9), and discusses related work (Section 10).

### 2 Replicated state machines

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301301544408.png" alt="image-20230130154432231" style="zoom:67%;" />

> Consensus algorithms typically arise in the context of *replicated state machines* . In this approach, state machines on a collection of servers compute identical copies of the same state and can continue operating even if some of the servers are down.
>
> Replicated state machines are typically implemented using a replicated log, as shown in Figure 1. Each server stores a log containing a series of commands, which its state machine executes in order. Each log contains the same commands in the same order, so each state machine processes the same sequence of commands. Since the state machines are deterministic, each computes the same state and the same sequence of outputs

Raft（共识算法）的工作：保持所有的状态机上的Log的一致性。

> Keeping the replicated log consistent is the job of the consensus algorithm. 

一个服务器上的共识模块接收来自客户端的命令，将它们加入它的Log中，它与其他服务器上的共识模块通信，以保证每个Log最终都包含相同顺序的相同请求，即便某些服务器故障。一旦命令被正确复制，每个服务器的状态机就按照Log的顺序来处理它们，然后将输出返回给客户端。

>  The consensus module on a server receives commands from clients and adds them to its log. It communicates with the consensus modules on other servers to ensure that every log eventually contains the same requests in the same order, even if some servers fail. Once commands are properly replicated, each server’s state machine processes them in log order, and the outputs are returned to clients. As a result, the servers appear to form a single, highly reliable state machine.

实际系统上的共识算法一般有如下几个特征：

- 在所有的非拜占庭条件下保证安全（不对外输出错误的结果）

> They ensure *safety* (never returning an incorrect result) under all non-Byzantine conditions, including network delays, partitions, and packet loss, duplication, and reordering.

- 只要服务器集群的主体（一半以上）正常运行并且可以相互通信以及与客户端通信，那么整个系统就是完全可用的（功能完整的）。
  - 一个由5台服务器组成的集群可以容纳任意两台服务器的故障。

> They are fully functional (*available*) as long as any majority of the servers are operational and can communicate with each other and with clients. Thus, a typical cluster of five servers can tolerate the failure of any two servers. Servers are assumed to fail by stopping; they may later recover from state on stable storage and rejoin the cluster.

- 不依赖计时来保证Log的一致性：错误的时钟和极端的消息延迟在最坏情况下会导致可用性问题。

> They do not depend on timing to ensure the consistency of the logs: faulty clocks and extreme message delays can, at worst, cause availability problems.

- 在一般情况下，只要集群的主体都已经响应了单轮的RPC，一个命令就可以完成。少数慢的服务器不影响系统整体的性能。

> In the common case, a command can complete as soon as a majority of the cluster has responded to a single round of remote procedure calls; a minority of slow servers need not impact overall system performance.

### 3 What’s wrong with Paxos?

Paxos：牛逼，但是难理解

> Over the last ten years, Leslie Lamport’s Paxos protocol has become almost synonymous with consensus:it is the protocol most commonly taught in courses, and most implementations of consensus use it as a starting point. Paxos first defines a protocol capable of reaching agreement on a single decision, such as a single replicated log entry. We refer to this subset as *single-decree Paxos*.Paxos then combines multiple instances of this protocol to facilitate a series of decisions such as a log (*multi-Paxos*).Paxos ensures both safety and liveness, and it supports changes in cluster membership. Its correctness has been proven, and it is efficient in the normal case.
>
> 
>
> Unfortunately, Paxos has two significant drawbacks.The first drawback is that Paxos is exceptionally difficult to understand. The full explanation is notoriously opaque; few people succeed in understanding it, and only with great effort
>
> 
>
> The second problem with Paxos is that it does not provide a good foundation for building practical implementations. One reason is that there is no widely agreed-upon algorithm for multi-Paxos. Lamport’s descriptions are mostly about single-decree Paxos; he sketched possible approaches to multi-Paxos, but many details are missing.
>
> Systems such as Chubby have implemented Paxos-like algorithms, but in most cases their details have not been published
>
> 
>
> Furthermore, the Paxos architecture is a poor one for building practical systems; this is another consequence of the single-decree decomposition.
>
> 
>
> Another problem is that Paxos uses a symmetric peer-to-peer approach at its core

所以，结果是什么？

> As a result, practical systems bear little resemblance to Paxos. Each implementation begins with Paxos, discovers the difficulties in implementing it, and then develops a significantly different architecture. This is time consuming and error-prone, and the difficulties of under standing Paxos exacerbate the problem. Paxos’ formulation may be a good one for proving theorems about its correctness, but real implementations are so different from Paxos that the proofs have little value.
>
> 
>
> Because of these problems, we concluded that Paxos does not provide a good foundation either for system building or for education. Given the importance of consensus in large-scale software systems, we decided to see if we could design an alternative consensus algorithm with better properties than Paxos. Raft is the result of that experiment.

### 4 Designing for understandability

讲了一下设计Raft时的各种目标，讲了在选择某个设计点的替代方案时的做法（基于可理解性选择，选好理解的）

> We had several goals in designing Raft: 
>
> it must provide a complete and practical foundation for system building, so that it significantly reduces the amount of design work
>
> required of developers; 
>
> it must be safe under all conditions and available under typical operating conditions; and it must be efficient for common operations. 
>
> But our most important goal—and most difficult challenge—was *understandability*. It must be possible for a large audience to understand the algorithm comfortably. In addition, it must be possible to develop intuitions about the algorithm, so that system builders can make the extensions that are inevitable in real-world implementations.

### 5 The Raft consensus algorithm

> Raft is an algorithm for managing a replicated log of the form described in Section 2. Figure 2 summarizes the algorithm in condensed form for reference, and Figure 3 lists key properties of the algorithm; the elements of these figures are discussed piecewise over the rest of this section.

Raft怎么实现共识：

- 先选出一个Leader，然后将管理复制的日志的责任全交给它。
- Leader从客户端接收LogEntry，然后在其他的服务器上复制这些LogEntry，并且告诉这些服务器什么时候可以安全地将LogEntries应用到它们的状态机上。

> The leader accepts log entries from clients, replicates them on other servers, and tells servers when it is safe to apply log entries to their state machines.

- 一个Leader可以故障或者与其他服务器失去连接，在这种情况下一个新的Leader被选出。

选出一个Leader可以简化ReplicatedLog的管理：

> Having a leader simplifies the management of the replicated log. For example, the leader can decide where to place new entries in the log without consulting other servers, and data flows in a simple fashion from the leader to other servers. 

在有了Leader方法之后，Raft将整个共识问题划分为了三个相对独立的子问题：

> - Leader election: a new leader must be chosen when an existing leader fails (Section 5.2).
> - Log replication: the leader must accept log entries from clients and replicate them across the cluster, forcing the other logs to agree with its own(Section 5.3).
> - Safety: the key safety property for Raft is the State Machine Safety Property in Figure 3: if any server has applied a particular log entry to its state machine,then no other server may apply a different command for the same log index. Section 5.4 describes how Raft ensures this property; the solution involves an additional restriction on the election mechanism described in Section 5.2.

在描述了共识算法之后，还讨论了可用性的问题，以及计时在系统中的角色。

#### 5.1 Raft basics

一个Raft集群包含多台服务器，在任意时间，每个服务器都处于以下三个状态之一：

- Leader
- Follower
- Candidate
- 在一般的操作的情况下，只有一个Leader，其他的服务器都是Follower。
- Follower是被动的一方：从不主动发送请求，只响应来自Leaders和Candidates的请求。
- Leader处理所有来自客户端的请求（如果某个客户端向Follower发出了请求，Follower将其重定向到Leader去）
- Candidate是可以成为Leader的候选者，用来在 5.2 节描述的选举新领导人时使用
- Figure 4展示了不同状态之间的过渡

Raft将时间分为任意长度的任期（*Terms*），如Figure 5。任期使用连续的整数来标序号，每段任期以一次选举开始，一个或者多个候选人尝试成为领导人。如果一个候选人赢得选举，然后他就在接下来的任期内充当领导人。在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内，最多只有一个领导人。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301301951752.png" alt="image-20230130195001381" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301301951976.png" alt="image-20230130195129826" style="zoom:67%;" />

不同的服务器可能会在不同的时间观察到任期的转换，在某些情况下，某些服务器也可能观察不到一次选举或者整个任期。

任期在Raft中充当逻辑时钟，可以使得服务器节点检测到过期的信息，比如过期的领导人。

每个服务器节点存储一个随时间单调递增的当前任期号。每次服务器之间进行通信时都会交换任期号，如果一个服务器的当前任期号比其他服务器的要小，那么它将它的当前任期号更新为更大的那个。如果一个候选人或者领导人发现其任期过了，就立即恢复为跟随者状态。

如果服务器收到一个任期号过期的请求，它会直接拒绝这个请求。

Raft服务器之间使用RPCs来进行通信，基本的共识算法只需要两种类型的RPC：

- RequestVote RPCs：请求投票RPC，由候选人在选举期间发起。
- AppendEntries RPCs：追加条目RPC，由领导人发起，用于复制日志和提供心跳机制。
- 第七节加了一种用于在服务器之间传输快照的RPC。
- 当服务器没有及时的收到RPC的响应时，会进行重试，并且为了性能会并行发起RPC。

#### 5.2 Leader election

Raft使用心跳机制来触发选举。

当服务器启动时，它以追随者的身份开始。一个服务器只要收到来自Leader或者Candidate的合法的RPCs，它就继续保持追随者的状态。

领导人定期给所有的跟随者发送心跳包（不带有日志条目的AppendEntries）来维持自己的权威。

如果一个跟随者在一段时间内没有收到任何的消息（这段时间叫选举超时），它就认为没有可用的领导人，并发起选举以选出新的领导人。

为了开始一次选举，跟随者需要做如下几件事：

1. 将自己的当前任期号递增，转换到候选人状态
2. 给自己投一票，并且并行地向集群中的其他服务器发出RequestVote RPCs
3. 持续保持候选人的状态，直到以下三件事之一发生：
   1. 他赢得了这次选举，成为领导人
   2. 另外一个服务器赢得了选举成为了领导人
   3. 一段时间过去，但是没有产生赢家，也就是没有产生领导人。

接下来对这三种情况一一讨论：

第一种情况：赢得选举：当候选人收到了整个集群中大部分服务器针对同一个任期号的选票，他就成为了领导人。

- 在一个给定任期内，每个服务器最多给一个候选人投票，按照先来先服务的原则（note: Section 5.4 adds an additional restriction on votes)
- 大多数规则确保了一个特定任期内最多产生一个领导人（the Election Safety Property in Figure 3)
- 一旦一个候选人赢得选举，它就成为领导人。然后新的领导人会给所有其他服务器发送心跳消息以建立权威，并阻止新的选举



第二种情况：另外一个服务器赢得了选举，成为了领导人：问题：其他人是怎么知道自己的选票数的？

在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导人的附加条目（AppendEntriesRPC）RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号，那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。



第三种情况：没有服务器赢得选举。

- 如果很多服务器同时成为候选者，那么选票可能会被瓜分，以至于没有人能够得到大多数的选票。
- 这种情况下，所有的候选者都会超时，然后各自递增当前任期号并发出另一轮的RequestVote RPCs以开始新一轮的选举。
- 但是，如果没有其他措施的话，选票瓜分可能会无限重复

Raft是如何确保第三种情况基本不会发生，即使发生也很快就会被解决的：

- 为了阻止选票起初就被瓜分，使用在某个固定区间内的随机的选举超时时间（比如150-300ms内的一个随机时间）。
- 这样把服务器分散开，于是大部分情况下只会有一个服务器选举超时。然后它赢得选举并在其他服务器超时之前发送心跳包。
- 同样的机制被用于处理选票瓜分的情况：每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。
- 9.3节说明了这种措施是很有效的

最后一段讲了讲可理解性原则如何指导设计，并提了一嘴最初的候选人排名设计。

#### 5.3 Log replication

一旦一个领导被选举出来，它就立即开始服务客户端的请求。每个客户端请求包含一个要被复制状态机执行的命令。领导人把这条指令作为一条新的日志条目附加到日志中去，然后并行地发起附加条目 RPCs 给其他的服务器，让他们复制这条日志条目。当日志条目已被安全复制之后，领导人将日志条目应用到自己的状态机，并将结果返回给对应的客户端。如果跟随者崩溃或者运行缓慢，再或者网络丢包，领导人会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。



如下图，每一个日志条目存储一条状态机指令和领导人收到这条指令时的任期号。日志中的任期号用来检查是否出现不一致的情况，同时也用来保证图 3 中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301311140095.png" alt="image-20230131114007914" style="zoom:67%;" />

领导人来决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为**已提交**。

Raft算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。

- 也就是说已提交不等于已执行

在领导人将创建的日志条目复制到大多数的服务器上的时候，日志条目就会被提交（例如在图 6 中的条目 7）。同时，领导人的日志中，这条条目之前的所有日志条目也都会被提交，包括由其他领导人创建的条目。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301311140095.png" alt="image-20230131114007914" style="zoom:67%;" />

领导人跟踪它所知道的最高的要被提交的索引，并且它会将这个索引值包含在未来所有的AppendEntries RPCs (包含心跳)中，这样其他服务器最终会知道。一旦一个跟随者知道一条日志条目已被提交，它就将这个条目应用到本地的状态机（按日志顺序）。

>  The leader keeps track of the highest index it knows to be committed, and it includes that index in future AppendEntries RPCs (including heartbeats) so that the other servers eventually find out.Once a follower learns that a log entry is committed, it applies the entry to its local state machine (in log order).

为了维护不同服务器日志之间的高层次的一致性， Raft 的日志机制维护着以下的特性，这些特性共同组成了图 3 中的**日志匹配特性（Log Matching Property）**：

> Not only does this simplify the system’s behavior and make it more predictable, but it is an important component of ensuring safety
>
> - If two entries in different logs have the same index and term, then they store the same command.
> - If two entries in different logs have the same index and term, then the logs are identical in all preceding entries.

- 如果在不同日志中的两个日志条目有相同的索引和任期号，那么这两个日志条目存储了相同的指令。

  - 因为一个领导人在给定任期内的给定索引号下，最多只能创建一个日志条目，并且条目的在Log中的位置永远不会改变。

- 如果在不同日志中的两个日志条目有相同的索引和任期号，那么这两个条目之前的所有前置条目也完全一致。

  > The second property is guaranteed by a simple consistency check performed by AppendEntries. When sending an AppendEntries RPC, the leader includes the index and term of the entry in its log that immediately precedes the new entries. If the follower does not find an entry in its log with the same index and term, then it refuses the new entries.
  >
  > 简单来说就是在发送新的日志项的时候，也把新日志项的前面一个日志项是谁发过去。如果直接前置日志项对不上（找不到），就拒绝请求。
  >
  > 这很像数学归纳法，一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查在日志扩展的时候保护了日志匹配特性。因此，每当附加日志 RPC 返回成功时，领导人就知道跟随者的日志一定是和自己相同的。

在正常的操作中，领导人和跟随者的日志保持一致性，所以附加日志RPC的一致性检查从来不会失败。

- 空日志，选举出第一个领导——操作不出错（完全复制所有的条目到所有的跟随者）——任期结束——结束的时候所有服务器的Log是一致的——开始新的任期——选出新的领导——选出领导的这个时刻，所有服务器的Log都还是一致的——如果后面不出差错，那么Log的一致性会一直保持

> However, leader crashes can leave the logs inconsistent (the old leader may not have fully replicated all of the entries in its log)

这种不一致问题会在领导人和跟随者的一系列崩溃下加剧。下图图7，演示了一种失败的可能性：跟随者可能会丢失一些在新的领导人中存在的日志条目，他也可能拥有一些领导人没有的日志条目，或者两者都发生。丢失或者多出日志条目可能会持续多个任期。

- 可以看到abcde都缺少了任期2和3内的日志条目。
- 这种情况可能发生在：f在任期2做领导人，然后本地追加了3个条目，然后还没来得及给abcde发出RPC，就崩溃。然后f快速恢复，又做了任期3的领导人，然后本地追加了5个条目，然后没来得及发出RPC又崩溃了，并且没有再恢复上线。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301311208261.png" alt="image-20230131120852103" style="zoom:67%;" />

那么领导人在发现不一致性之后，如何解决？

- 领导人是强制跟随者直接复制自己的日志来处理不一致性。
- 这意味着在跟随者中的冲突的日志条目会被领导人的日志覆盖。
- 这不一定安全，所以在5.4节增加了一条限制来使得这个操作安全 

使得跟随者的日志变得和领导人一致的具体步骤：

- 领导人找到最后一个二者达成一致的日志条目的位置（比如在第N个索引是最后一个一致的，0-N都是一致的）
- 删除跟随者那个点之后的所有的日志条目（删除跟随者中N+1及以后的所有条目）
- 将领导人那个点之后的所有日志条目发送给跟随者（发送领导人中N+1及以后的所有条目）
- 所有的这些操作都在进行附加日志RPCs的一致性检查时完成

领导人针对每一个跟随者维护了一个 **nextIndex**，这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导人刚获得权力的时候，他初始化所有的nextIndex值为自己的最后一条日志的index加1（图7中的11）。如果一个跟随者的日志和领导人不一致，那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后，领导人就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导人和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导人保持一致，并且在接下来的任期里一直继续保持。

> 如果需要的话，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如，当附加日志 RPC 的请求被拒绝的时候，跟随者可以(返回)冲突条目的任期号和该任期号对应的最小索引地址。借助这些信息，领导人可以减小 nextIndex 一次性越过该冲突任期的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。

通过这种机制，领导人在获得权力的时候就不需要任何特殊的操作来恢复一致性。

- 领导人从来不会覆盖或者删除自己的日志

总结：

> This log replication mechanism exhibits the desirable consensus properties described in Section 2: Raft can accept, replicate, and apply new log entries as long as a majority of the servers are up; in the normal case a new entry can be replicated with a single round of RPCs to a majority of the cluster; and a single slow follower will not impact performance.

#### 5.4 Safety

> The previous sections described how Raft elects leaders and replicates log entries. However, the mechanisms described so far are not quite sufficient to ensure that each state machine executes exactly the same commands in the same order. 

之前的机制并不足以保证安全，比如：一个错过了某些日志条目的跟随者可能会成为新的领导而覆盖其他服务器的日志。

> For example, a follower might be unavailable while the leader commits several log entries, then it could be elected leader and overwrite these entries with new ones; as a result, different state machines might execute different command sequences.

本节对于哪些服务器能够被选举为领导人增加了一些限制，完善了Raft算法，保证了任意给定任期内的领导人都包含了全部已提交的条目。

> This section completes the Raft algorithm by adding a restriction on which servers may be elected leader. The restriction ensures that the leader for any given term contains all of the entries committed in previous terms (the Leader Completeness Property from Figure 3)

在给定了选举限制之后，我们更加清晰地阐述提交规则。最后我们对领导人完整特性（**Leader Completeness Property**）做简要证明，并说明该特性是如何引导复制状态机做出正确行为的

##### 5.4.1 Election restriction

- 在任何基于领导人的一致性算法中，领导人都必须存储所有已经提交的日志条目。
- 某些一致性算法中可以选举一开始没有包含完整日志的领导人，但是需要额外的机制来识别和传输缺失的日志条目。

>  In some consensus algorithms, such as Viewstamped Replication, a leader can be elected even if it doesn’t initially contain all of the committed entries. These algorithms contain additional mechanisms to identify the missing entries and transmit them to the new leader, either during the election process or shortly afterwards.

但是Raft使用了一种更加简单的方法，它可以保证在选举的时候新的领导人拥有之前所有任期中已经提交的日志条目，而不需要传送这些日志条目给领导人。这意味着日志条目的传送是单向的，只从领导人传给跟随者，并且领导人从不会覆盖自身本地日志中已经存在的条目。

Raft使用投票的方式来阻止一个候选人赢得选举，除非这个候选人包含了所有已经提交的日志条目。

一个候选人为了被选上，必须联系集群中的大部分的服务器，这意味着每个已经提交的日志条目都会在至少一个服务器上出现。如果候选人的Log至少和集群中的大部分的服务器的一样新，那么它就持有所有已提交的条目。

> If the candidate’s log is at least as up-to-date as any other log in that majority (where “up-to-date” is defined precisely below), then it will hold all the committed entries.

RequestVote RPC实现了这个限制：RPC中包含了候选人的日志信息，投票者如果发现自己的日志比候选人更加新，那么就不投给它。

“新”的标准是什么：比较两个Log中的最后一项的索引值和任期号，任期越晚的越新，任期相同，日志越长越新。

> Raft determines which of two logs is more up-to-date by comparing the index and term of the last entries in the logs. If the logs have last entries with different terms, then the log with the later term is more up-to-date. If the logs end with the same term, then whichever log is longer is more up-to-date.

##### 5.4.2 Committing entries from previous terms

> As described in Section 5.3, a leader knows that an entry from its current term is committed once that entry is stored on a majority of the servers. If a leader crashes before committing an entry, future leaders will attempt to finish replicating the entry

如果一个条目被存储在了集群的大部分服务器中，它就是已提交的。如果一个领导人在提交条目之前崩溃，未来的领导人会试图重新完成对这个条目的复制。

但是，一个领导人不能断定一个来自之前任期的日志条目被保存到大多数服务器上的时候就一定已经提交了。如下图Figure 8，因为即便是以及被保存到大多数服务器上的日志条目，也可能会被新的领导人覆盖掉：

- S1到S5是5个服务器，第一个任期无事发生，5个服务器都存了一个日志条目。
- 第2个任期，S1作为领导，在将索引的第二个条目复制到S2之后就寄了，任期结束。
- 第3个任期，S5收到S345的选票当选，在索引2的地方放了另外一个条目，然后S5寄了，任期结束。
  - 这里本质上就是因为前一个任期黄色的项没有在它作为最新的任期的项的时候成为大多数，不然S5也不可能当选
- 第4个任期，S1重启，收到S1234的选票当选（在S34看来S1比他们更新，因为S1最后一项的任期更晚），然后把索引的第二项复制给S3（此时第二项已经被“大多数”存储了），然后又寄了，任期结束，如(c)。
- 第5个任期，S5收到S2345的选票当选（(c)中S234的最后一项比S5的最后一项旧），发现S1234存在不一致性，于是强制复制，直接覆盖了原有的索引第二项，如(d)。
- 但是，如果S1动作足够快，把(c)中索引为2和3的项都复制给了集群的大多数（也就是5个服务器中的3个），那么S5无法当选，这些项就是已提交的。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301311651295.png" alt="image-20230131165140112" style="zoom:67%;" />

为了消除图 8 里描述的情况，Raft永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目可以通过计算副本数目的方式提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。

- 概括一下，当前任期的日志条目可以用“大多数”原则判断是否已提交，而前任期的条目不可以，否则会导致被覆盖的风险
- 某些情况下也可以通过计算副本数目的方式判断旧的条目，比如所有的服务器上都存了这个条目。

Raft采用的方法：当领导人复制之前任期里的日志时，Raft 会为所有日志保留原始的任期号。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft的方法更容易辨别日志，因为日志的任期号会一直保持不变。

##### 5.4.3 Safety argument

安全性论证

来证明一下领导人完全性特性。

使用反证法，先假定特性不成立，然后引出矛盾。

假定任期T的领导人LeaderT在它的任期内**提交了**一个日志项，但是那个日志项并没有被未来的某些领导人保存下来。

设大于T的最小任期为U， U的领导人LeaderU没有这条日志条目：

1. LeaderU在当选的时刻一定没有LeaderT提交的那个条目（领导人从不删除或者覆盖自身的条目）
2. 既然LeaderT提交了那一项，那么LeaderT肯定已经在集群的大多数节点复制了这个条目。类似的，既然LeaderU当选了，那么它肯定得到了集群中大多数节点的选票。因此，至少有一个服务器节点（“the voter”，比如图9的S3），同时处于这两个集合中。这个投票者是矛盾的关键
   - 很简单，因为“大多数”肯定是超过了一半，那么这两个“超过了一半”构成的集合，其中必然会有元素重合，它们的交集必定不是空集。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/202301311816936.png" alt="image-20230131181647754" style="zoom: 67%;" />

3. 这个投票者（The Voter）一定是在投票给LeaderU之前就接收了LeaderT发来的条目，否则它会直接拒绝来自领导人 T 的附加日志（AppendEntries PRC)请求（因为此时他的任期号会比 T 大）。
4. 投票者在给LeaderU投票时依然保存有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有在和领导人冲突的时候才会删除条目。
5. 这个投票者把自己的选票投给了LeaderU，那么LeaderU的Log一定和这个投票者的一样新。这就导致了两者矛盾之一
6. 首先，如果LeaderU和TheVoter的最后一个日志条目具有相同的任期号，那么LeaderU的日志的长度大于等于TheVoter的日志长度，并且领导人U的日志一定包含投票者的所有日志。而我们最开始的假设是LeaderU中不包含LeaderT提交的那一项。矛盾出现
7. 否则，另外一种情况，LeaderU的最后一个日志条目的任期号大于TheVote的。并且，LeaderU的最后一项的任期号大于T，因为TheVoter的最后一条日志的任期号至少和T一样大（他包含了来自任期 T 的已提交的日志）。创建了LeaderU最后一条日志的前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人U是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，LeaderU一定也包含那条被提交的日志，这里产生矛盾。
8. 因此，所有任期比T大的领导人一定包含了所有来自T的已经被提交的日志。

> Given the Leader Completeness Property, we can prove the State Machine Safety Property from Figure 3, which states that if a server has applied a log entry at a given index to its state machine, no other server will ever apply a different log entry for the same index. At the time a server applies a log entry to its state machine, its log must be identical to the leader’s log up through that entry and the entry must be committed. Now consider the lowest term in which any server applies a given log index; the Log Completeness Property guarantees that the leaders for all higher terms will store that same log entry, so servers that apply the index in later terms will apply the same value. Thus, the State Machine Safety Property holds.

Raft 要求服务器按照日志中索引位置顺序应用日志条目。这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。

##### 5.5 Follower and candidate crashes

> Follower and candidate crashes are much simpler to handle than leader crashes, and they are both handled in the same way

如果一个跟随者或者候选者崩溃，那么未来发给他们的RPCs都会失败，Raft则会通过无限重试来处理这些失败。

- 如果服务器重启，那么RPC会成功完成
- 如果服务器在完成一个RPC之后，发出响应之前崩溃，那么它会在重启之后收到同一个RPC。
- Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。

##### 5.6 Timing and availability

Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性无可避免地要依赖时间。举个例子：服务器之间交换消息的时间要长于服务器两次故障之间的间隔时间，那么服务器之间就永远无法交换信息，选举将没有办法成功进行，无法产生领导人，Raft不可用。

> One of our requirements for Raft is that safety must not depend on timing: the system must not produce incorrect results just because some event happens more quickly or slowly than expected. However, availability (the ability of the system to respond to clients in a timely manner) must inevitably depend on timing. 

领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求：

> *broadcastTime* ≪ *electionTimeout* ≪ *MTBF*
>
> 广播时间 << 选举超时时间 << 平均故障时间

- 广播时间：从一个服务器并行的发送RPCs给集群中的其他服务器并接收响应的平均时间；
- 选举超时时间：就是在 5.2 节中介绍的选举的超时时间限制；
- 平均故障间隔时间：就是对于一台服务器而言，两次故障之间的平均时间。
- 广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。
- 选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。

广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。
