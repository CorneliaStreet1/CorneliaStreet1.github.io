# 前置知识，概论

## 什么是Internet？

- E2E：End to End，端到端。IP（网络层）提供的是端到端的服务

- P2P：Point to Point，点到点。数据链路层提供点到点的服务。
- 端到端由很多个相邻的点到点构成。网络层需要依靠数据链路层提供相邻的点到点的传输服务来提供端（主机）到端（主机）的服务。
- 传输介质可以说是第0层，物理层看做第一层的话，物理层是在传输介质“提供的服务”之上建立的。
- 主机节点和数据交换节点：主机节点就是一台主机（可以是服务器，PC），而数据交换节点？数据交换节点，比如路由器与交换机，它既不是数据的源也不是数据的目标，它是数据的中转节点。来了分组从一个端口进来，按照一定的方式把它再转发出去（比如交换机根据Mac地址，比如路由器查路由表），通过这些中转接点的相互配合，最终完成源节点到目标节点的传输。
  - 路由器工作在网络层，交换机工作在MAC层。
  - 把节点连在一起的叫链路，链路把主机和交换节点连在一起，把交换节点和交换节点连在一起。
- 链路又可以分为两种：接入链路和主干链路
  - 接入链路是主机连接到互联网的链路。比如主机通过网线接入到离它最近的一台交换机。
  - 主干链路是交换节点与交换节点相连的链路。
- 什么是协议？对等的实体在通信的过程中应该遵守的规则的集合，包括了语法、语义和时序。
  - 协议定义了在两个或多个通信实体之间交换的报文格式和次序，以及在报文传输和/或接收或其他事件方面所采取的动作
- Internet的标准是以RFC的形式由IETF发布。
  - RFC: Request For Comment，请求评述
  - IETF: Internet Engineering Task Force

## 网络边缘

按照组成的类型，可以将互联网分为一个个的子系统：

- 网络边缘（Edge）：所有的主机和运行在主机上面的（分布式的）应用程序。逻辑上看他们都处于网络的边缘，是数据包的起点或者终点（天涯和海角）。
- 网络核心（Core）：由交换节点构成的，能够形成链路连接边缘的不同主机的那一部分。核心负责将所有的边缘节点接在一起。下一节。
  - 网络核心的作用是数据交换作用。
- 接入网（Access）：接入链路。接入负责将网络边缘接入网络核心的部分。下下节。

![image-20230331201224303](https://i.imgur.com/0S8ZqRN.png)

网络边缘的应用进程之间通信的模式：

- C-S：客户端-服务器模式。
- Peer to Peer：对等体到对等体的模式。去中心化的，分布式的。每个节点既可以是客户端，也可以是服务器，几乎没有一个专门的服务器。



面向连接的服务：两个网络边缘的应用进程之间通信之前，先握个手打招呼，底层的协议栈做好准备（缓冲区、计时器、控制变量置位等等），之后才开始通信。

- TCP协议。可靠的服务，保证顺序的服务，有流量控制和拥塞控制。
- 可靠：不重不漏、不失序、不乱序。
- 流量控制：发送方发送太快，接收方会给发送方一些反馈，让发送方降低发送的速率。反之，接收方有余力，可以让接收方发快点。
- 拥塞控制：网络路径（链路）的通行能力不行的时候，让发送方降低发送的速率。链路通畅的时候，让发送方发送快点。
- 流量控制和拥塞控制之间的区别：用快递和高速公路来比喻
  - 快递：数据包
  - 快递的卖家：发送方
  - 快递的买家：接收方
  - 送快递的车子+高速公路：互联网的负责传输的基础设施，比如交换机和线缆
  - 流量控制：买家不能接收卖家以那么快的速率发过来的快递，就让卖家发快递发慢点，否则可以让卖家发快点。
  - 拥塞控制：快递要从买家到卖家，要走高速公路。但是这个世界上不止一个卖家也不止一个买家，大伙的快递都要走这条高速公路，高速公路上的送快递的车子多了，高速公路就堵车了，堵车了快递就会丢（交换机丢弃收不下的帧），为了不让高速公路堵车，卖家要降低发送快递的速率。

无连接的服务：两个应用进程之间通信，通信之前不握手不打招呼，直接通信，只要发出去的UDP报文符合协议规范就可以了，对方收到了就马上应答。

- UDP协议。无连接，不可靠，没有流量控制，也没有拥塞控制。
- 实时性相比TCP好，因为TCP要握手，要给数据包编号，丢了要重传，超时要重传，收到的乱序要排序，又要考虑流量控制，又要考虑拥塞控制。
- 如果采用TCP，连接过去，连接回来，连接建立，查询，结果。你有这个建立连接的时间，UDP查询结果都回来了。
- 使用UDP的应用，没有流量控制没有拥塞控制，上面应用发多快，UDP就发多快。想象一下使用TCP，上面有一堆要发的时候你掐着脖子不让他发，等到网络通畅了，你跟他说你可以发了，他说我没那么多数据可以发。

使用TCP的应用：

- FTP
- HTTP
- SMTP

使用UDP的应用：

- 流媒体（视频）
- 实时会议
- DNS

## 网络核心

网络核心：路由器的网状网络

网络核心负责将数据从一个网络边缘主机传输到另外一个网络边缘主机。问题是：数据怎样通过网络进行传输？

有两种方式：

- 电路交换：比如固定电话网
- 分组交换：以分组为单位，存储-转发的方式。

### 电路交换

- 两个主机（比如电话）在通信之前要建立一个独享的线路，之后双方利用独享的线路进行通信。
- 如果呼叫没有数据发送，那么分配的资源就被浪费。
- 一旦连接建立，性能就可以保证。
- 通常被传统的电话网络采用。
- 电路交换不太适合计算机网络通信，计算机网络通信的突发性比较强，有时候有有时候没有，不像打电话，接通了就会一直说话直到挂电话。比如从服务器GET了一个HTML文档之后，就在本地浏览网页了，这个时候没有通信发生，如果采用电路交换，资源被浪费。另外一个方面就是，电路交换，2秒钟建立端到端的连接，俩计算机1毫秒搞定通信。

![image-20230331221550960](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230331221550960.png)

分片方式：

- FDM，频分：在链路的有效通信频率的覆盖范围内，每个连接可以在不同的频率区间上（小片）通信
- 时分，TDM：将时间分槽，每个连接（用户）在各自对应的时间槽通信。第一个用户使用第一个时槽，第二个用户使用第二个时槽....

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230331220333692.png" alt="image-20230331220333692" style="zoom:67%;" />

- 波分：采用光纤的物理传输介质。将可用的波段分为若干个小的波段，每个用户使用其中的某个小波段。
- 码分，CDM：

一个计算的例子：

- **10.5秒末并不意味着B已经收到了全部的比特**
- 10.5秒末只是A将所有的比特都发出去的时刻。
- A和B之间是有一定的物理距离的，比特在传输介质上跨越这段距离需要时间，称作传播延迟。
- 第一个比特在0.5秒末立刻被A发送出去，然后经过传播延迟的时间，在0.5秒+传播延迟的时刻到达B
- 最后一个比特在10.5秒末被A发送出去，在10.5秒+传播延迟末到达B。
- 而且，每个比特的传输并不是一瞬间的事，它需要$\frac{1}{传输带宽}$的时间，在这里就是64K分之一的时间，进行传输。而在这个时间内，空间上这个比特所跨越的距离又需要乘上介质中的光速。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230331220735706.png" alt="image-20230331220735706"  />



### 分组交换

不像电路交换，主机与主机之间的通信，在越过每一段通信链路（每一跳的时候），不再使用二十四分之一的带宽，而是带宽的全部。

并且主机和主机之间通信的数据，被分成一个个的单位，叫做分组（Packet，包）。包在越过每一个通信链路的时候，使用带宽的全部。

以分组为单位，在每一个交换节点进行存储-转发，存储-转发，最终传输到目标主机。

**发送和接收是同一个事情的两个方面，算时间的时候不能两个方面加起来，只能算一次，不能把发送时间和接收时间加起来**

- 存储-转发：在转发之前，节点必须收到整个分组。
- 如果变成直通式的话，那和电路交换也没什么区别，电路交换就是节点收到一个比特就立刻转发出去。
- 好处：按需使用，有数据的时候占用时间，没数据的时候不占用，给其他用户用。（信道不再是两方独享了，而是谁都可以用）
- 坏处：由于把整个分组完全存下来，然后再转发，在每个节点耽误的时间是接收整个分组的时间，所以延迟会比电路交换大。
- 排队时间：想要从某个链路把分组转发出去，但是这个链路上已经有一个或者多个分组待转发，需要排队。
- 排队延迟也是要耽误的时间，而且是不确定的延迟时间。
- 丢失：如果分组到达的速率大于链路输出分组的速率，分组将会排队（队列还可能越来越长，后来的分组比早来的分组要经历更长的排队延迟）。并且如果路由器的缓存用完（队列长度到极限了），有一部分分组会被抛弃（丢包了）。

分组交换的代价：为了获取共享性所付出的代价

- 不确定的排队延迟
- 存储整个分组再转发耽误的延迟
- 分组丢失的风险



网络核心的两个功能：路由、转发

- 转发是局部的。路由器转发要查路由表，决定往哪个方向（哪条链路）转发。
- 路由是全局的。路由表怎么来的呢？路由负责计算出路由表。路由器之间交换信息，算出路由表。
- 靠路由器这种局部和全局功能的配合，最终完成将源主机的分组转发到目的主机的伟大事业。

分组交换的复用方式：统计时分复用

- 是时分复用，但是时间上的复用没有固定的模式（没有固定的时间槽，基本上是随机的，但是还是划分了时间片，甚至时间片长度都不固定）

下图：在分组交换的那百分之零点零四的Hold不住的情况下（多于10个用户，但是最多只能同时往外传10个用户的数据），用缓存来存贮溢出来的分组，度过这个艰难时刻。然后在不艰难的大多数时光，把缓存的分组发出去。

![image-20230331231523405](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230331231523405.png)

分组交换是突发数据的胜利者：第三个的Q由于时间关系没讲，在多媒体那一章会讲（但是我也不会看？）

![image-20230331231735741](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230331231735741.png)

分组交换按照有无网络层的连接分为两种方式：

- 数据报方式：源主机发给目标主机的分组，携带了目标主机的完整地址，交换节点根据分组的目标地址来存储转发。两个主机通信前不需要握手，每个分组独立转发。
  - 路由表可能变，所以路径可能不同。
  - 独立转发每个分组，所以可能会失序。
  - **路由器不维护主机与主机之间的通信状态**。

- 虚电路的方式：主机跟目标主机通信之前握个手，在交换节点之间保持它们通信的状态，建立起一条虚电路，每个分组携带虚电路号，而不是目标主机的完整地址，每个分组按照虚电路号来标识，进行存储转发。
  - 同一条虚电路在不同交换节点上的虚电路号是不一样的。因为同一条虚电路，对于一个交换节点来说可能是它这个节点上的第一条虚电路（虚电路号为1），但是对于另外一个繁忙的热点交换节点来说，可能是第十条虚电路（虚电路号为10）。如果还保持同一个虚电路号1，那存储转发的时候就转发到错误的虚电路上去了。
  - 虚电路上的每个交换节点都会体现这个连接，以虚电路号/虚电路表的方式。


<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401135242604.png" alt="image-20230401135242604" style="zoom:67%;" />

- 数据报无连接，每个分组独立传送。虚电路则两个主机通信之前要先建立起一个网络层的连接，要在路径上的每个交换节点之间存储相应的标识（虚电路号），每个分组传送路径一致（也是存储-转发）。

![image-20230331232318142](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230331232318142.png)

## 接入网和物理媒体

接入网负责将网络边缘的主机接入网络核心。

物理媒体指的实际上是物理层的传输介质。

这一节大概就是讲了讲物理层的接入方式的事情，不算重点。

*Q:* 怎样将端系统和边缘路由器连接？

- 住宅接入网络
- 单位接入网络 （学校、公司）
- 无线接入网络

*注意：*

- 接入网络的带宽 (bits per second) ？

- 共享/专用？共享带宽不稳定，专用带宽稳定

### 接入网

![image-20230401140107361](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401140107361.png)![image-20230401140919679](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401140919679.png)![image-20230401140934961](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401140934961.png)![image-20230401141036630](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401141036630.png)

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401141417679.png" alt="image-20230401141417679" style="zoom:80%;" />![image-20230401141428721](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401141428721.png)

### 物理媒体

第零层。物理层基于物理传输介质来传输比特。可以是光纤、同轴电缆、以太网网线、开放的空间传输电磁波。

导引型媒体: 信号沿着固体媒介被导引：

- 同轴电缆、光纤、 双绞线

非导引型媒体：开放的空间传输电磁波或者光信号，在电磁或者光信号中承载数字数据。

- 电磁信号在导引型媒体中传输的距离比在开放空间中要远得多。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401142459681.png" alt="image-20230401142459681" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401142509672.png" alt="image-20230401142509672" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401142416387.png" alt="image-20230401142416387" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401142425028.png" alt="image-20230401142425028" style="zoom:80%;" />

## Internet结构和ISP

端系统通过接入ISPs (Internet Service Providers)连接到互联网 

- 住宅，公司和大学的ISPs 

接入ISPs相应的必须是互联的

- 因此任何2个端系统可相互发送分组到对方

导致的“网络的网络”非常复杂

- 发展和演化是通过经济的和国家的政策来驱动的

ICP：互联网内容提供商(Internet Content Providers)，比如Baidu、Google。ISP只提供网络的接入，ICP提供内容。

- ICP要依靠ISP提供的互联网服务来接入网络。
- 但是ICP可以不仅仅满足于ISP提供的服务（比如ISP收费太贵，体验还不够好），可以自己组建自己的专用网。
  - 比如在世界各地部署自己的数据中心机房，然后使用专用线缆将这些数据中心连起来。

## 分组延时、丢失和吞吐量

分组丢失和分组延时是怎样发生的？

分组丢失：

- 每条链路在路由器中对应一个缓冲区，缓冲区中是排队的分组。
- 当分组到达链路的速率大于链路输出分组的速率，缓冲区队列溢出了，那么就会发生分组丢失。
- 为什么不把排队的队列弄长一点，这样就不会丢分组了？弄太长了排队延时高，分组没丢，用户受不了延迟跑了。

四种分组延迟：

1. 节点处理延时：检查bit级差错 + 检查分组首部和决定将分组导向何处（指比如提取目标IP加查路由表）。
2. 排队延时：在输出链路上等待传输的时间。依赖于路由器的拥塞程度。一般是随机的，可长可短，取决于网络状况。
3. 传输延时: R=链路带宽(bps)，L=分组长度(bits)。将分组发送到链路上的时间= L/R（将分组从节点输入到链路上所需的时间，存储-转发延时）。
4. 传播延时:d = 物理链路的长度，s = 在媒体上的传播速度($~2 * 10^8 m/sec$)。 传播延时 = d/s。（比特流在长长的物理介质上从一端传播到另一端的时间）

因此，节点的延迟 = 处理延时 + 排队延迟 + 传输延迟 + 传播延迟。这只是每个节点的延迟时间，经过很多跳，每一跳都要耽误这四个延时的组成。

- 处理延时现在一般比较短，路由器上会有专门的CPU负责提取目标地址和查路由表之类的工作
- 排队延迟取决于拥塞程度
- 传输延时取决于L和R
- 传播延时取决于d和s

![image-20230401154044781](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401154044781.png)

### 排队延时

排队延迟取决于流量强度，流量强度 = $\frac{每个分组的长度 * 单位时间内到达的分组的数量}{带宽}$。分子分母的量纲相同（$\frac{比特/个分组 * 个分组/秒}{比特/秒}$），商得到一个无量纲的纯数字，流量强度。

- 流量强度一定在零到一之间，因为带宽是没办法突破的，就算分子超过了分母，实际上能打出去的比特的速率也就是带宽拉满，速度不可能超过带宽。
- 研究表明，流量强度趋近于1时，分组的排队延迟会非常大，趋近于无限大，如右图。所以不能设计一个流量强度接近于1的系统。

![image-20230401155105228](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401155105228.png)![image-20230401155120073](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401155120073.png)

### Traceroute的工作原理（Win下是tracert命令，源主机是发出tracert命令的主机，目标主机是给定的命令行参数）

Traceroute可以用于探测分组在从源主机到目标主机中到达的每一个交换节点的IP是什么，到这个交换节点的RTT（RoundTripTime，往返时间是什么）。

原理是基于ICMP协议（互联网控制报文协议）：

我们知道IP包有一个字段叫TTL，在发出分组的时候，会将TTL设置一个初始值，每到达一个节点，TTL就会被减一，当到达某个节点，分组的TTL减为零的时候，就会被这个节点丢弃。丢弃分组的节点会给源主机发一个ICMP控制消息，告诉源主机，我把你的报文丢了，我的IP是啥，你来找我算账，源主机收到这个ICMP报文的时候，就知道这个交换节点的IP是啥，以及通过发送分组和收到ICMP的时间差，算出RTT。

- 测试第一个交换节点的IP以及RTT：将TTL设为1。第二个？TTL设为2，第三个？第四个？
- 如何判断到达了目标主机？将分组的端口号设为一个在目标主机上没有进程监听的端口号，同时将TTL设置得无限大（当然是一个夸张的意思），这样肯定能到达目标主机。目标主机收到分组之后，一解析，发现目标端口号不可达，也会给源主机发送一个ICMP消息，说你这个目标端口不可达啊，源主机收到这个消息，就知道到达目标主机了。



发过去的：Echo类型（也称作`ping`类型，因为ping发送的也是Echo包）

转发节点回复的：Time to live exceeded in transit 类型，或者是目标主机端口不可达类型。

- 端口不可达类型，从我抓包来看，似乎是源主机发出的Echo包里，选定了一个极大的端口号（本次是52152），所以不可达。

<img src="https://i.imgur.com/LOvXK9d.png" alt="image-20230823132628932" style="zoom:80%;" />

<img src="https://i.imgur.com/kH0Om9L.png" alt="image-20230823132716618" style="zoom:80%;" />

分组丢失了怎么办？三种命运：

- 如果链路是可靠的（比如可靠的协议，比如可靠的物理介质光纤），那由上一跳的节点重传
- 如果链路不可靠（比如以太网），那由源主机重传
- 如果是UDP，那么丢了就丢了，根本不重传。



### 吞吐量

吞吐量: 在源端和目标端之间传输的速率（数据量/单位时间） 

- 瞬间吞吐量: 在一个时间点的速率 
- 平均吞吐量: 在一个长时间内平均值

吞吐量具有水桶效应（短板效应），成为短板的那条链路是瓶颈链路。

需要注意的是每条链路都可能不止一对源-目标主机对在使用，所以瓶颈链路不一定是吞吐量最小的链路，而是**能分到的吞吐量**最小的链路。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401163052016.png" alt="image-20230401163052016" style="zoom:67%;" />

## 协议层次和服务模型

服务( Service)：低层实体向上层实体提供它们之间的通信的能力 

- 服务用户(service user) 
-  服务提供者(service provider)
- 服务是垂直方向的，下层向上层提供。

原语(primitive)：上层使用下层服务的形式，高层使用低层提供的服务，以及低层向高层提供服务都是通过服务访问原语来进行交互的——形式



服务访问点 SAP (Services Access Point) ：上层使用下层提供的服务通过层间的接口——地点。

- 服务访问点用于区分不同的上层用户。有很多个上层用户，它们都使用下层提供的服务，下层服务提供者通过服务访问点来区分这些不同的用户。

- 例子:邮箱 
- 地址(address)：下层的一个实体支撑着上层的多个实体，SAP有标志不同上层实体的作用
- 可以有不同的实现，队列
- 例子:传输层的SAP: 端口(port)。
  - 传输层是应用层的服务提供者，应用层是传输层的服务用户。
  - 不同的应用层协议（传输层的不同服务用户）使用不同的端口，比如80是HTTP，DNS是端口53。

服务的类型：面向连接的服务和无连接的服务

- 面向连接的服务( Connection-oriented Service) 

  - 连接(Connection)：两个通信实体为进行通信而建立的一种结合 

  - 面向连接的服务通信的过程：建立连接，通信，拆除连接

  - 面向连接的服务的例子：网络层的连接被称为虚电路 

  - 适用范围：对于大的数据块要传输; 不适合小的零星报文

  - 特点：保序

- 无连接的服务：两个对等层实体在通信前不需要建立一个连接，不预留资源；不需要通信双方都是活跃；

  - 不需要握手，上来就直接发出请求。
  - 特点：不可靠、可能重复、可能失序
  - IP分组，数据包

服务与协议的区别：

- 服务(Service)：低层实体向上层实体提供它们之间的通信的能力，是通过原语(primitive)来操作的，垂直
- 协议(protocol) ：对等层实体(peer entity)之间在相互通信的过程中，需要遵循的规则的集合，水平

服务与协议的关系：

- 本层协议的实现要靠下层提供的服务来实现。
- 本层实体通过协议为上层提供更高级的服务。

### 数据单元(DataUnit)

上层来的SDU，经过接口，在SDU的前面加上本层的头部（Header），形成本层的PDU。

如果上层来的SDU比较大，那么可能会将SDU分成多个部分，每个部分的前面加上一个本层的头部，形成多个PDU。

如果上层来的SDU比较小，那么可以将多个SDU合在一起，在前面加上一个Header，形成一个PDU。

![image-20230401204033020](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401204033020.png)![image-20230401204913045](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401204913045.png)



每一层的PDU都有不同的称呼：

- 应用层：应用报文，Message。
- 传输层：报文段，Message Segment。
- 网络层：分组、数据报，Packet。
- 链路层：帧，Frame。

![image-20230401220233528](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401220233528.png)

### Internet协议栈(TCP/IP的五层协议栈)

物理层：传输比特。

- 发送方：上层交下来的帧，将帧中的比特将其变成物理信号，在介质中传播。
- 接收方：做逆向的事，把物理传输介质上承载的信号还原为原来的比特。

链路层：在**相邻两点间**传输以帧为单位的数据，在比特流中区分帧的开始和结束，中间就是一个帧。

- Point to Point的传输，点到点的传输。
- 万一要传输数据的两点不相邻呢？怎么办？这就是网络层解决的问题。
- 一般链路层和物理层会被封装在同一张网卡当中，链路层和物理层的协议是配套的。

网络层：在链路层提供的相邻两点之间数据传输服务的基础上，传输以分组为单位的，源主机到目标主机的，端到端的数据传输。

- 也就是说，借助相邻两点的传输服务，完成不相邻的两点之间的数据传输服务。

- 链路层只能完成相邻两点间的传输，但是我们需要的是源主机到目的主机的端到端的传输，网络层负责干这个事。

- 仅仅靠相邻两点间的传输没有办法完成源主机到目标主机的传输。
- 但是端到端的传输路径是由很多对相邻的两点构成的，在相邻的两个点之间的传输，又是借助链路层的服务的。

传输层：借助网络层提供的端到端的数据传输服务，提供源进程到目标进程的数据传输。（以及基于网络层提供的不可靠的服务，来提供可靠的服务）

- 网络层只能提供主机到主机的数据传输，但是我们主机上跑了好多个进程，所以主机到主机还不够细致，要把数据传输的粒度细化到进程到进程。
- 另外一个问题就是，网络层提供的服务是不可靠的服务，是尽力而为的，所以传输层还要在网络层的不可靠的服务的基础上提供可靠的数据传输。

应用层：在传输层提供的服务的基础上，完成应用报文和应用报文之间的交互。完成之后想干嘛干嘛。

### OSI的七层网络模型

在传输层和应用层之间多了会话层和表示层。

- 表示层主要负责表示管理，语义方面的信息。
- 会话层负责会话管理，建立会话，拆除会话，维持会话。

在TCP/IP的五层网络模型下，会话层和表示层的工作由应用层自己去做，也就是相当于把会话层和表示层合并入了应用层。

![image-20230401211707513](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401211707513.png)

### 封装与解封装

一个应用层报文的一生：

- 应用层将应用层消息交给传输层，传输层加上这一层的头部，形成段（报文段）
- 传输层将段交给网络层，网络层加上网络层的头部，形成分组
- 网络层将分组交给数据链路层，数据链路层加上数据链路层的头部（和帧尾校验和），形成帧
- 数据链路层将帧交给物理层，物理层将帧比特转换为物理信号，传输到物理传输介质上去。
- 到了交换机的物理层，物理层将物理信号还原成比特，将帧取出来，交给链路层。链路层查看帧头部的目标Mac地址，查交换表，决定往某个端口把载荷部分转发出去。
- 这个端口的网卡，将收到的载荷部分重新封装成帧，交给这个端口的物理层。
- 某个路由器的网卡收到了前一步的网卡发出的帧，路由器的网卡将帧的载荷部分（也就是分组）交给路由器的网络层，路由器查看分组的目标IP和转发表，然后决定往哪里转发出去，分组交给那里的网卡，封装成帧，交给物理层发出去。
- 就这样一跳一跳，到达目标主机，目标主机物理层将比特还原成帧交给链路层，链路层将帧还原成分组交给网络层，网络层将分组还原成报文段交给传输层，传输层将报文段还原成应用层消息交给应用层，应用层的进程收到消息，结束了这个报文的一生。

**数据到达交换机要做一个到链路层的解封装和再封装（然后发出去），到路由器要做一个到网络层的解封装和再封装（封装完然后再发出去）**。

![image-20230401212017787](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230401212017787.png)

# 应用层

## 应用层原理

### 网络应用的体系结构

- 客服端-服务器架构

![image-20230402123057417](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402123057417.png)

- 对等体架构（P2P）：难以管理，每个对等体只有在上线的时候才能体现其服务能力，但是对等体的上下线没有规律。

![image-20230402123124327](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402123124327.png)

- 混合架构：P2P和CS架构混合
  - Napster原理：
    - 客户端运行起来，给中心服务器发消息，告诉中心服务器，我上线了，我的IP是什么，我有哪些可用的MP3。
    - 有些客户端需要下载音乐，下载之前，先向中心服务器查询，我要下载的MP3谁有？服务器告诉有的主机的IP地址。
    - 下载音乐的时候，就是客户端到客户端之间的P2P的传输。
  - 即时通信：
    - 用户上线时，向中心服务器注册其IP，告诉服务器我上线了。
    - 用户想要和好友聊天时，向服务器查询好友的IP。服务器告诉用户，它的好友哪些在线，它们的IP分别是什么。
    - 用户之间聊天时，是P2P的。

![image-20230402123233038](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402123233038.png)

### 分布式进程通信需要解决的问题

别忘了，**应用层不负责区分收到的报文是交给哪一个进程，这个工作是传输层做的，传输层区分并交给对应进程**。

问题1：进程标示和寻址问题（服务用户）：主机IP、TCP还是UDP、端口号

- 你在哪个机器上？IP是什么
- 你在这个机器上，是在TCP上跑，还是UDP上跑？协议是什么
- 在TCP上有好多进程在跑，你在哪个端口上？端口号是什么
-  一个进程：用IP+port标示，端节点。本质上，一对主机进程之间的通信由2个端节点构成 

问题2：传输层-应用层提供服务是如何（服务）

- 需要在层间传输的信息：
  - 上层的应用层报文本身（对本层来说，SDU）
  - 谁传的：上层的发送方进程的IP + TCP/UDP（协议类型）+端口号
  - 传给谁：目的主机的接收方进程的IP + TCP/UDP （协议类型）+ 端口号
- 但是每次发送都要传输这三个信息很烦，后两个（在一段时间内）是不会变的，只需要传输一次就够了。
- 解决办法：在本地使用Socket来标识一个通信关系（通信的单方或者双方）。
  - Socket是一个整数，**并且是本地的，对方并不知道我们的Socket**，同一个连接在连接的双方，各自持有的Socket很可能不一样。
  - 无论UDP还是TCP都需要用Socket。
- TCPSocket代表一个四元组（发送方IP，发送方端口号，接收方IP，接收方端口号），指定了会话的双方。
  - 以TCP为例，OS有一个Socket表，这个表的每一行的表项，在建立连接的时候会逐步填充。OS每收到一个TCP报文段，查表就知道应该把Body部分交给应用层的哪个进程。
  - ![image-20230402131459899](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402131459899.png)![image-20230402132011248](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402132011248.png)![image-20230402132449401](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402132449401.png)<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402132935479.png" alt="image-20230402132935479" style="zoom: 70%;" />
- UDP Socket：UDP Socket**只代表本端，是二元组（源IP，源端口号）**。在传输报文时需要额外提供目标IP和目标端口号。
  - UDP传输需要三样东西：货物本体（应用层的报文）、UDP Socket、一个（目标IP，目标端口号）的二元组。
  - 而TCP只需要两样东西：货物本体、TCP Socket。因为UDP Socket只标识了本端，目标端需要二元组来给出。
  - 这也决定了，同一个本地UDP Socket，连续两次发送报文出去，完全可以是发给不同的主机，只需要给不同的IP（和端口号）。
  - <img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402133538310.png" alt="image-20230402133538310" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402133544939.png" alt="image-20230402133544939" style="zoom: 80%;" />

![image-20230402133941993](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402133941993.png)

问题3：如何使用传输层提供的服务，实现应用进程之间的报文交换，实现应用（用户使用服务）

- 定义应用层协议：报文格式，解释，时序等
- 编制程序，使用OS提供的API ，调用网络基础设施提供通信服务传报文，解析报文，实现应用时序等；
- 不同厂商按照公开协议实现的应用，是可以相互操作的。私有协议则做不到互操作。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402134713256.png" alt="image-20230402134713256" style="zoom:67%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402134910626.png" alt="image-20230402134910626" style="zoom:67%;" />

###  传输层提供的服务

- UDP不提供：可靠性、流量控制、拥塞控制
- TCP不提供：吞吐量下限保证、时间保证
- UDP存在的理由：不建立连接，不对上层进程卡脖子限制其发送速度（流量控制和拥塞控制），不做可靠性工作。
- **TCP和UDP都不提供安全性的保证，都是明文传输**。
- SSL（Secure Socket Layer）是在TCP和应用层之间的一层（划分不算明确，往上合并或者往下合并都可以），可以给TCP连接加密。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402135428497.png" alt="image-20230402135428497" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402135436348.png" alt="image-20230402135436348" style="zoom:80%;" />

## Web和HTTP协议

### WireShark抓包问题

默认情况下，抓到的HTTPS包都以TLS包的形式存在，也就是加密后的HTTP报文。而WireShark默认情况下是没办法解密的，所以搜的时候才基本上搜不到HTTP报文。

https://blog.csdn.net/Enderman_xiaohei/article/details/99441895

设置一下即可

### 一些术语

- URL的格式：
  - `协议名`：是HTTP还是HTTPS？
  - `用户:口令`：可以没有，支持匿名访问。
  - `主机名`：一般以域名的形式给出
  - `路径名`：你要的文件在这台主机的文件系统的哪个位置。
  - `端口号`：一般都不给出，HTTP的知名端口是80。
- 以URL`http://www.someSchool.edu/someDepartment/picture.gif`为例：
  
  其中的 `www.someSchool.edu` 就是主机名，`/someDepartment/picture.gif`就是路径名  
- 浏览器拿到一个Web页，这个HTML文件中的其他对象的链接，浏览器又通过这些链接去访问对应的对象，把它拿过来，渲染到屏幕上。

![image-20230402140807693](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402140807693.png)

### HTTP协议

超文本传输协议：**传输的不一定就只是HTML文档，也可以是其他的数据。**

- C-S模式：
  - 客户端请求、接收和显示Web对象
  - 服务器收到请求，将请求的Web对象封装成HTTP报文，发给客户端。
- 服务端最开始会有一个守候Socket，负责监听80号端口，并同意来自客户端的连接请求，连接建立的时候会创建一个连接Socket，代表建立的连接，原来的守候Socket依然守候在80号端口监听。
- HTTP是无状态协议，服务器不维护关于客户端的任何信息。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402141508300.png" alt="image-20230402141508300" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402144648556.png" alt="image-20230402144648556" style="zoom:80%;" />



### HTTP连接（持久连接&非持久连接，流水线&非流水线）

HTTP1.0使用非持久的HTTP连接，而HTTP1.1使用持久的HTTP连接（默认流水线）。

- 非持久HTTP连接：TCP连接请求==>连接确认（建立连接）==>传输对象==>关闭连接。
  - 一个HTTP连接只传输一个对象。
  - 在非持久性的HTTP连接，获取一个对象的最少需要：两个RTT（一个连接请求和确认，一个发请求收响应）+对象本身的传输时间。
- 持久的HTTP连接：连接请求==>连接确认==>传输对象==>不关闭连接，如果后续还有对象从这个服务器传输，仍然通过这个连接。
  - 一个HTTP连接可以传输多个对象。
  - 非流水方式的持久HTTP连接：假如浏览器发现HTML文档有10个对象处于同一个主机
    - 建立连接==>请求对象1==>对象1回来==>请求对象2==>对象2回来==>请求对象3==>.....
  - 流水线方式的持久HTTP连接：假如浏览器发现HTML文档有10个对象处于同一个主机
    - 建立连接==>请求对象1、2、3、4、5、6、7...==>对象1、2、3、4、5、6、7.....回来。**可能请求还没发完，就已经有对象回来了也说不定**

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402150152063.png" alt="image-20230402150152063" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402150208115.png" alt="image-20230402150208115" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402150332731.png" alt="image-20230402150332731" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402150555270.png" alt="image-20230402150555270" style="zoom:80%;" />

### HTTP请求报文

HTTP报文有两种类型：请求和响应。

**HTTP报文都是ASCII编码的，是人可以直接阅读的**。

HTTP请求报文的第一行叫作请求行（request line）,其后继的行叫作首部行。

请求报文的格式：

```py
# 请求行
GET/POST/HEAD/PUT  /Path/To/File/index.html HTTP/1.1 # URL，但是不需要主机名，已经建立了连接了。
# Path/To/File/index.html：这台主机上，哪个目录的哪个文件
# 首部行开始
Host: www.someschool.edu 
User-agent: Mozilla/4.0 #用户代理:浏览器/版本
Connection: close  # 让HTTP1.1使用非持久连接
Accept-language:fr # 
# 首部行结束
			# 一个额外的换行符，表示头部结束
# 可选的实体部分，GET没有,POST提交表单的时候，表单内容就放入实体部分
EntityBody
```

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402152243584.png" alt="image-20230402152243584" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402152810554.png" alt="image-20230402152810554" style="zoom:80%;" />

### 提交表单输入

向服务器提交内容有两种方式，POST请求和URL方式。

- POST请求，将相应的要提交的表单放入报文的实体部分。
- 采用GET方式，在URL中附上相应的参数值（以Key=Value的形式，多个Key=value之间使用&符号连接），问号分割URL和参数。

![image-20230402153532073](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402153532073.png)

### 方法类型

HTTP1.0：

- GET
- POST
- HEAD：获取HTML文档的头部。可用于搜索引擎建立索引

HTTP1.1：

- GET，POST，HEAD
- PUT：将实体主体中的文件上载到URL字段规定的路径
- DELETE：删除URL字段规定的文件

### HTTP响应报文

- `server`：服务器版本

- `last-modified`：请求的对象最后一次被编辑的时间，相当于一个版本号。
- `content-length`：数据的长度。
  - TCP向上层提供的是无边界的字节流服务。
  - 发送端上层交给TCP的带边界报文，在接收端TCP那里收到的是区分不了边界的字节流。需要上层自己来维护和区分报文的边界，所以需要这个字段。往下交俩15K的报文，TCP传递给对方的是连续30K的字节，对方的上层应用需要自己在这30K字节中划分出两个报文。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402154537507.png" alt="image-20230402154537507" style="zoom:67%;" />

### HTTP响应状态码

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402155618840.png" alt="image-20230402155618840" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402160327191.png" alt="image-20230402160327191" style="zoom:67%;" />

### 用户-服务器状态：cookies

HTTP是一个无状态协议，不维护客户端的任何信息，Cookies是为了弥补这个小问题。

客户端第一次给服务器发送请求（没有Cookie）==>服务器发现来了个新家伙，在响应报文的头部塞个Cookie值（Set-Cookie:Value），同时把Cookie本体保留在数据库里==>客户端收到响应报文，把Cookie存在本地==>下次客户端再发请求，就在请求里带上Cookie值。

Cookies能带来什么：用户验证、购物车、推荐、用户状态 (Web e-mail)

- 隐私问题

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402161537633.png" alt="image-20230402161537633" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402161644067.png" alt="image-20230402161644067" style="zoom:80%;" />

### Web缓存 (代理服务器)

目标：不访问**原始**服务器，就满足客户的请求。

- 客户端发出请求时，请求先被发送到代理服务器，代理服务器检查自己是否缓存了被请求的对象。如果没有，那么代理服务器向原始服务器发出HTTP请求，请求相应的对象。原始服务器将对象封装成HTTP响应报文，发送给代理服务器，代理服务器将对象缓存到本地，同时发送HTTP响应报文给客户端。
- 好处：客户端响应快，降低了原始服务器的负载。
  - 2-8定律，最终被百分之八十的人访问的那百分之二十的内容会被缓存到代理服务器。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402162413528.png" alt="image-20230402162413528" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402162426184.png" alt="image-20230402162426184" style="zoom: 80%;" />

问题：缓存和原始服务器的一致性问题。

解决：条件式GET。

- 缓存未命中，代理第一次访问原始服务器的时候，将对象以及这个对象的最后一次修改时间缓存。

- 后续用户再请求这个对象，代理给原始服务器发送条件式GET。
- 条件式GET的头部`If-Modifed-Since`给出一个时间点，如果原始服务器的对象在这个时间点之后被修改过，那么原始服务器发给代理修改后的对象，否则原始服务器只发送一个响应，告诉代理，没有改变。
- 代理得到响应之后，给用户发送响应。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402170233369.png" alt="image-20230402170233369" style="zoom:67%;" />

## FTP

文件传输协议（File Transmission Protocol）：用于向远程主机查看、上载或者下载文件。

- FTP服务端进程监听21号端口。

- FTP客户端进程向服务端21号端口发出连接请求，建立TCP连接，这个连接称作控制连接。
- 客户端通过控制连接，传输用户名和密码（**明文**），完成身份认证。
- 客户端完成身份认证后，通过控制连接发送命令浏览远程主机的文件系统。
- 服务器收到一个文件传输命令时，**主动**向客户端的**20**号端口建立一个**数据连接**，并传输数据，数据传输完毕后关闭连接。
  - 控制连接一直没有断开，用于传输客户端的控制命令。
- **FTP是有状态协议，会在服务端维护用户的当前路径、用户账户与控制连接的对应关系等客户端状态**。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402171830022.png" alt="image-20230402171830022" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402171840673.png" alt="image-20230402171840673" style="zoom:80%;" />



## Email

电子邮件主要包含三个组成部分：

- 用户代理
  - 发送接收电子邮件的客户端软件，浏览器也可以做Web邮箱应用的代理。
- 邮件服务器
  - 用户代理配置好邮件服务器的IP和端口号，将邮件发给服务器，通过邮件服务器发邮件。SMTP协议
  - 邮件先被排入邮件服务器的发送队列，邮件服务器再沿着队列将邮件投递到目标邮件服务器。SMTP协议
  - 目标邮件服务器收到邮件后，将邮件放入收件人的邮箱目录。
  - 收件人的用户代理，从目标邮件服务器拉取自己的邮件。POP3
- 简单邮件传输协议：
  - **使用持久的TCP连接，如果客户端有多封邮件要传，同一个连接就一起传了**。不会一封邮件一个连接。
  - SMTP使用TCP在客户端和服务器之间传送报文，端口号为25。
  - 直接传输：从发送方服务器到接收方服务器
  - 传输的3个阶段
    - 握手
    - 传输报文
    - 关闭
  -  命令/响应交互
    - 命令：ASCII文本
    - 响应：状态码和状态信息
  - **报文必须为7位ASCII码**（传中文怎么办？）

### 报文格式

- 为了解决报文中包含非ASCII字符的问题：使用Base64编码，使用MIME（多媒体扩展）。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402192342944.png" alt="image-20230402192342944" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402192944366.png" alt="image-20230402192944366" style="zoom:80%;" />

### 邮件访问协议

- **发送方把邮件传输给发送方的邮件服务器、发送方的邮件服务器把邮件传输给目标邮件服务器都是SMTP**
- 客户端从邮件服务器拉取属于自己邮箱的邮件，使用POP3/IMAP/HTTP协议。

![image-20230402193321058](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402193321058.png)

## DNS协议

域名解析系统。



DNS的必要性

- IP地址标识主机、路由器。但IP地址不好记忆，不便人类使用(没有意义)。人类一般倾向于使用一些有意义的字符串来标识
- 存在着“字符串 ”——IP地址的转换的必要性。人类用户提供要访问机器的“字符串”名称。由DNS负责转换成为二进制的网络地址。
- 应用使用的是域名，但是往下交给传输层的实际上还是IP地址。

DNS系统需要解决的问题：

- 问题1：如何命名设备。
  - 用有意义的字符串：好记，便于人类用使用
  - 解决一个平面命名的重名问题：层次化命名
- 问题2：如何完成名字到IP地址的转换
  - 分布式的数据库维护和响应名字查询
- 问题3：如何维护：增加或者删除一个域名（公司倒闭了没人交钱了），需要在域名系统中做哪些工作

### DNS(Domain Name System)总体思路和目标

DNS的主要思路

- 分层的、基于域的命名机制
- 若干分布式的数据库完成名字到IP地址的转换
- 运行在UDP之上端口号为53的应用服务
- 核心的Internet功能，但以应用层协议实现。在网络边缘处理复杂性

DNS主要目的：

- 实现主机名-IP地址的转换(name/IP translate)
- 其它目的：主机别名到规范名字的转换：Host aliasing
- 邮件服务器别名到邮件服务器的正规名字的转换：Mail server aliasing
- 负载均衡：Load Distribution

### DNS名字空间(The DNS Name Space)

NDS采用层次树状结构的命名方法。Internet根被划为几百个顶级域(top lever domains)，每个(子)域下面可划分为若干子域(subdomains)，树叶是主机

- 通用的(generic)顶级域：.com; .edu ; .gov ; .int ; .mil ; .net ; .org.、firm ; .hsop ; .web ; .arts ; .rec ; 
- 国家的(countries)：.cn ; .us ; .nl ; .jp

域名(Domain Name)：从本域往上，直到树根中间使用`.`间隔不同的级别。

- 域的域名：可以用于表示一个域，`cs.yale.edu`
- 主机的域名：一个域上的一个主机，`robot.ai.cs.yale.edu`

域与物理网络无关

- 域遵从组织界限，而不是物理网络
- 一个域的主机可以不在一个网络，一个网络的主机不一定在一个域
- 域的划分是逻辑的，而不是物理的

![image-20230402205511992](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402205511992.png)

### 名字服务器(Name Server)

将DNS的命名空间划分为很多个互不相交的区域，每个区域都是域名系统树的一部分。每个区域由一个权威名字服务器负责维护着它所管辖区域的权威信息。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402212301576.png" alt="image-20230402212301576" style="zoom: 80%;" />

每个权威服务器需要维护域名到IP的映射，以及其他的信息（比如别名），这些东西统称资源记录。

资源记录(resource records)：

- 作用：维护 域名-IP地址(其它)的映射关系
- 位置：Name Server的分布式数据库中

RR格式: `(domain_name, ttl, type,class,Value)`

- Domain_name: 域名
- TTL: time to live : 生存时间(权威，缓存记录)。权威记录的TTL是无限大，而缓存记录的TTL基本上就是一个保质期的概念。过期了就不能用缓存的项了，会被删掉。
  - 缓存是为了性能和效率，删除是为了保持一致性和准确性。

- Class 类别 ：对于Internet，值为IN（现在也基本上只有Internet了）
- Value值：可以是数字，域名或ASCII串
- Type 类别：资源记录的类型。
  - 可以是域名到IP的转换，可以是别名到正规名字的转换，可以是邮件服务器到正规名字的转换。
  - NS：NameServer，Name字段是域名，Value字段是这个域名的权威服务器的域名。
  - MX：MailBox

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230402215301379.png" alt="image-20230402215301379" style="zoom: 80%;" />

### DNS解析过程

- 应用调用名字解析器，解析器作为客户代理，向Local Name Server发出UDP报文询问，Local Name Server返回响应报文(域名/IP)。
  - Local Name Server是提前配置的，手工配置或者DHCP自动配置。
  - 一台机器上线时，其IP、默认的DNS服务器、子网掩码、默认的Gateway都需要配好，自动或者手动。
  - Gateway是离开子网内部的出口。
- Local Name Server：并不严格属于层次结构，一般处于子网的内部。每个ISP (居民区的ISP、公司、大学）都有一个本地DNS服务器，也称为“默认名字服务器”，当一个主机发起一个DNS查询时，查询被送到其本地DNS服务器。Local Name Server起着代理的作用，将查询转发到层次结构中。
  - Local Name Server可以作为缓存，缓存之前查询过的DNS域名。

Local Name Server是怎么查的？

- 有缓存：直接使用缓存来响应。（过期的缓存会被删掉）
- 无缓存：迭代查询或者递归查询

递归查询：在美国解析www.ustc.edu.cn：中科大。

1. 从树根开始，顺着树根往下捋。
2. 先问`.cn`，`.cn`是顶级域名，全球的根服务器IP是预先定义的。
3. `.cn`知道`edu.cn`的权威名字服务器
4. `edu.cn`知道`ustc.edu.cn`的权威名字服务器
5. `ustc.edu.cn`的权威名字服务器返回对应的IP给`edu.cn`。
6. `edu.cn`把得到的结果返回`.cn`
7. `.cn`把得到的结果返回给Local Name Server

迭代查询：在美国解析www.ustc.edu.cn：中科大。

1. Local Name Server先问`.cn`的根服务器，它说我不知道答案，但是你可以去问`edu.cn`，我知道`edu.cn`的权威服务器IP，我给你。
2. Local Name Server拿到`edu.cn`的权威服务器IP，给`edu.cn`发送查询报文，`edu.cn`的权威服务器说我不知道，但是你可以去问`ustc.edu.cn`的权威服务器，我知道它的IP，我给你。
3. Local Name Server拿到`ustc.edu.cn`的权威名字服务器IP，去问它，`ustc.edu.cn`的权威名字服务器把IP返回给Local Name Serve。

如下图，递归查询的箭头指向构成的控制链比较类似递归函数调用的调用链。

- 递归查询：Local Name Server问根服务器，根服务器问子域服务器，子域服务器再问它的子域服务器，直到问到结果，子域的子域把结果告诉子域，子域把结果告诉根服务器，根服务器把结果告诉Local Name  Server。
- 迭代查询：Local Name Server问根服务器，根服务器告诉它你找谁去查，然后Local Name Server去找那个谁，然后那个谁又告诉它去找谁谁去查，一直到Local Name Server找到了知道答案的服务器，然后知道答案的服务器直接把结果返回给Local Name Server。
- 从迭代查询的过程来看，查询不一定要从根服务器开始，如果我提前缓存了根服务器告诉我的那个TLD服务器的IP，那我可以直接从TLD开始查。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230403130416576.png" alt="image-20230403130416576" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230403130436686.png" alt="image-20230403130436686" style="zoom:80%;" />

### DNS协议、报文

查询报文和响应报文的格式是相同的。

- ID：如果没有ID的话，LocalNameServer只能一次发送一个查询，等查询结果返回，才能接着发出下一个查询。有ID的话就可以同时查询多个，查询结果回来的时候直接根据ID号来找到对应的查询。
  - 这个在WireShark里抓的包，貌似叫dns.id（Transaction ID）

- 查询和响应的报文格式相同，靠标志位来标识这是一个查询还是响应

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230403131259550.png" alt="image-20230403131259550" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230403131317038.png" alt="image-20230403131317038" style="zoom:80%;" />

### 提高性能：缓存

一旦名字服务器学到了一个映射，就将该映射缓存起来。TLD服务器通常都在本地服务器中缓存着，使得根服务器不用经常被访问。

- 目的：提高效率

- 可能存在的问题：如果情况变化，缓存结果和权威资源记录不一致
- 解决方案：TTL（默认2天）

### 维护问题：新增一个子域

如果我要在某个域名之下，新增一个子域，我需要做哪些维护和修改？

- 在上级域的名字服务器中增加两条记录，指向这个新增的子域的域名 和 域名服务器的地址
  - 在上级域的名字服务器上插入两条记录：
  - 一条记录的类型为NS，维护子域域名==>子域名字服务器的名字的映射（这个子域的名字服务器的名字是什么）
  - 一条记录的类型为A子域名字服务器的名字==>服务器的IP。（这个子域的名字服务器的IP是什么）

- 在新增子域 的名字服务器上运行名字服务器进程，负责本域的名字解析： 名字==>IP地址

![image-20230403132518252](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230403132518252.png)

## P2P留坑

## CDN留坑

## TCP Socket编程

服务器首先运行，等待连接建立：

1. 服务器进程必须先处于运行状态
   1. 创建欢迎socket
   2. 和本地端口捆绑（`bind()`）
   3. 监听（listen()，如果有多个连接建立请求，listen会将其放入等待队列）
   4. 在欢迎socket上**阻塞式等待**接收用户的连接（调用`accept()`来等待连接）
2. 客户端主动和服务器建立连接：
   1. 创建客户端本地套接字（隐式捆绑到本地port，OS会负责，找一个当前没用的端口给你绑定）
   2. 指定服务器进程的IP地址和端口号，与服务器进程连接（调用`connect()`）
3. 当与客户端连接请求到来时：
   1. 服务器接受来自用户端的请求，解除阻塞式等待，欢迎Socket的`accept()`函数返回一个新的socket（与欢迎socket不一样，返回的这个ConnectionSocket代表着服务器与客户端之间的TCP连接），与客户端通信 
   2. 允许服务器与多个客户端通信 。使用源IP和源端口来区分不同的客户端
4. 连接API调用有效时，客户端P与服务器建立了TCP连接

### 结构体 sockaddr_in

```c
//IP地址和port捆绑关系的数据结构（标示进程的端节点）
struct sockaddr_in {
    short sin_family; //AF_INET，地址族，是IPX还是TCP/IP。创建结构体的时候将其赋值为AF_INET
    u_short sin_port; // port，端口号
    struct in_addr sin_addr ; // IP address, unsigned long，IP地址
    char sin_zero[8]; // align，起到内存对齐的作用
}; 
```

### 结构体 hostent

```c
//域名和IP地址的数据结构
struct hostent {
    char *h_name; //主机域名
    char **h_aliases; //主机一系列的别名
    int h_addrtype; 
    int h_length; /*地址长度*/ 
    char **h_addr_list; //IP地址的列表
    #define h_addr h_addr_list[0];
} 
/*
作为调用域名解析函数时的参数
返回后，将IP地址拷贝到 sockaddr_in的IP地址部分
*/
```

## UDP Socket编程

UDP: 在客户端和服务器之间没有连接 

- 没有握手
- 发送端在每一个报文中明确地指定目标的IP地址和端口号
- 服务器必须从收到的分组中提取出发送端的IP地址和端口号
- UDP: 传送的数据可能乱序，也可能丢失

![image-20230403150208618](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230403150208618.png)

# 传输层

## 概述和传输层服务

传输层提供的服务：为运行在不同主机上的应用进程提供逻辑通信。

传输协议运行在端系统：

- 发送方：将应用层的报文分成报文段，然后传递给网络层。如果应用层的报文较长，可能会分割成多个报文段。
-  接收方：将报文段重组成报文，然后传递给应用层。**TCP传递给应用层的是无边界的字节流**，TCP只保证流是无差错的，但是不保证报文之间的边界。

### 传输层 vs. 网络层

传输层提供进程到进程的通信，网络层提供主机到主机的通信。

网络层提供的服务是不可靠的，不可靠意味着数据会丢失，到达的数据可能会出错，数据到达的顺序会乱序，数据可能会重复。

而传输层（TCP）就要基于网络层提供的这种不可靠的服务，实现可靠的传输服务，保证不重不漏，顺序不乱。

![image-20230403152509530](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230403152509530.png)

### Internet传输层协议

可靠的、保序的传输： TCP 

- 多路复用、解复用 
- 拥塞控制
- 流量控制
- 建立连接

不可靠、不保序的传输：UDP 

- 多路复用、解复用
- 没有为尽力而为的IP服务添加更多的其它额外服务。
- UDP也是尽力而为的，只不过相比IP，细分了进程到进程的区分。除此之外没有增加其他的工作。

**都不提供的服务**：得加钱

- 延时保证
- 带宽保证

## 多路复用和解复用

端口号机制实现多路复用和解复用。

TCP的Socket和四元组相捆绑，UDP的Socket和二元组相捆绑。每个Socket和持有这个Socket的进程的PID相捆绑。



TCP的复用和解复用：

- 源端：应用层进程往下交应用层报文的时候，除了报文，还把Socket交给传输层。传输层往下交的时候，除了报文段本身，还有源IP、目标IP，都要交给网络层。

- 目标端：网络层收到源端发来的分组（IP数据包），将Body部分（是一个TCP的报文段），**和源IP、目标IP**都往上交给传输层。传输层的报文段头部含有源端口和目标端口，四元组凑起来查表，可以查到谁是这个报文的接收进程。

UDP的复用和解复用：

- 源端：应用层进程往下交应用层报文，除了报文，还要把UDP Socket、目标IP、目标端口号一起交给传输层。传输层将应用层报文封装成报文段（头部含源端口、目标端口），将报文段、源IP、目标IP交给网络层。网络层将报文段封装成分组，发给目标端。
- 目标端：网络层收到源端发来的分组（IP数据包），将Body部分（是一个UDP的报文段），**和源IP、目标IP**都往上交给传输层。传输层的报文段头部含有源端口和目标端口，四元组凑起来查表，可以查到谁是这个报文的接收进程。
- 因为UDP是无连接的，所以我在创建UDP Socket的时候，我是不知道要和谁通信的，所以UDP Socket只和源IP、源端口号绑定。

## 无连接传输UDP

UDP: User Datagram Protocol [RFC 768]

相对于IP，可以说仅仅新增了一个端口号的机制。所以和IP一样，是尽力而为的，不可靠的服务。

- “尽力而为”的服务，报文段可能丢失，送到应用进程的报文段可能乱序

无连接：

- UDP发送端和接收端之间没有握手
- 每个UDP报文段都被独立地处理（路由）

UDP 被用于: 

- 流媒体（丢失不敏感，速率敏感、应用可控制传输速率）
- DNS
- SNMP

在UDP上可行可靠传输: 只能靠应用层增加额外的机制来保证

- 在应用层增加可靠性
- 应用特定的差错恢复

### UDP报文结构

8个字节的头部：

1. 2字节的源端口号：0-65535
2. 2字节的目的端口号
3. 整个报文段的长度，包含头部。头部也是2个字节，所以理论上最大的长度是65535字节。
4. 校验和

剩下的是报文段（载荷）。

头部开销小，只有固定的8个字节。TCP20个字节。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230403161639376.png" alt="image-20230403161639376" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230403162702174.png" alt="image-20230403162702174" style="zoom:80%;" />

## 可靠数据传输的原理

数据链路层和传输层都需要可靠数据传输

### 可靠数据传输1.0

下层的信道是完全可靠的：

- 没有比特出错
- 没有分组丢失

发送方和接收方的状态机：

- 发送方将数据发送到下层信道：
  - 接收来自上层的数据单元，封装成本层的数据单元，交给下层发送出去。
- 接收方从下层信道接收数据：
  - 等待下层递交一个本层数据单元，然后解封装，递交给上层。

实际上什么都不用干，封装解封装就行了。

### 可靠数据传输2.0

下层信道可能会出错：将分组中的比特翻转

- 用校验和来检测比特差错。校验和对不上就认为数据出错了，否则认为分组没出错。

问题：怎样从差错中恢复： 

- 确认(ACK)：接收方显式地告诉发送方分组已被正确接收
- 否定确认( NAK): 接收方显式地告诉发送方分组发生了差错，发送方收到NAK后，发送方重传分组

rdt2.0中的新机制：采用差错控制编码进行差错检测

- 发送方做差错控制编码、缓存发送出去的分组（以备重传）。发送出去后，等待接收方的ACK或者NAK（等待状态）：
  - 如果收到ACK，发送方继续等待上层调用，以便继续发送下一个分组。
  - 如果收到NAK：发送方重传出错的分组。
- 接收方使用校验和检错：
  - 如果分组正确（检错过了），那么给发送方发送ACK。将分组解封装，递交给上层。
  - 否则给发送方发送NAK。

### 可靠数据传输2.1：发送方处理出错的ACK/NAK

新的问题：ACK也是有校验和的，如果ACK或者NAK出错怎么办？毕竟带数据的分组可以出错，那没有理由认为ACK或者NAK一定不会出错。发送方收到一个来自接收方的数据包，解析出来是既不是ACK也不是NAK，而是哼哼哼啊啊啊啊啊啊啊（发出数据包出错的声音.jpg）怎么办？

**一定要记得ACK/NAK也是需要经过校验和校验的，校验不通过就是哼哼哼啊啊啊啊啊**。

解决方法：

- 发送方给每个发送出去的分组编号，每个分组一个序号，如果收到的ACK或者NAK是出错的（即解析不出来是ACK还是NAK），那么直接重传刚才发出去的分组P_0。
- 如果刚才出错的是ACK：那么接收方会收到一个重复的P_0，它看见重复的P_0，可推测ACK出错了，重发一个ACK。接收方收到这个ACK，如果这个ACK没出错，接收方就可以接着发下一个分组P_1。**当然，接收方收到的那个重复的P_0直接会丢弃**。
- 如果刚才出错的是NAK：那么重传恰好就是发送方应该做的事情。

至此我们发明了停止-等待协议：一次发一个，等ACK或者NAK回来（或者哼哼哼啊啊啊回来），再发下一个（下一个可能是重传也可能是新的）。

- 我们的分组的序号只需要一个比特来表示即可：因为一个比特既可以表示一件事：是新的分组，或者不是新的分组
- 接收方和发送方开始通信前需要同步，是从等待0号分组开始，还是从等待1号分组开始，假定从0号分组开始 。
- 假如从0开始，发送方发送0号分组，等待ACK。
- 接收方接收，校验，发送ACK，解封装，向上交付，接下来接收方预期收到的是1号分组。
  - 如果又来了个0号分组，肯定是刚才的ACK出了问题，接收方再给对方一个ACK。重复的分组则不会向上交付。

- 发送方收到ACK，发送1号分组。

**接收方并不知道发送方是否正确收到了其的确认（ACK或者NAK，NAK是否定的确认）**，没有安排确认的确认。

- 为什么？很简单，那既然你都安排确认的确认了，那是不是也要安排一下确认的确认的确认？确认的确认的确认的确认？没完没了了是吧。

- 接收方只能根据发送方后面的表现来推断发送方是否收到了其确认（比如发送方发送新的分组了，就可以反推其收到了ACK）

### 可靠数据传输2.2：无NAK协议

功能上和2.1相同，但是把NAK去掉了，只使用ACK，**ACK有编号**。

接收方只对**最后**正确接收的分组发ACK，以替代NAK。

当收到重复的ACK（如：再次收到ack0）时，发送方与收到NAK采取相同的动作：重传当前分组。

- 接收方发出的ACK必须显式地包含被正确接收分组的序号。
- 举个例子，接收方已经收到了0号分组，在等待1号分组。然后接收方收到一个出错的分组，它不给发送方发送NAK，而是发送ACK0.
  - 意思是说，发送方那边发送了1号分组，但是收到的来自接收方的应答是它收到了1号前面的0号分组，发送方就可以推断1号分组出错了，于是重传。
- 相当于说，发送方发送了第N+1号分组，但是接收方跟它说我只收到了N号分组，潜台词就是没收到N+1号分组，所以发送方重传。
- 对当前分组的反向确认，可以用对前一个分组的正向确认来替代。

举个具体的例子：

1. 发送方发送Packet0
2. 接收方收到，校验成功，回应ACK0.
3. 发送方发送Packet1
4. 接收方收到，校验失败，回应ACK0.（什么？你发了1号分组吗？我不到啊，我只收到了0号分组.jpg）
5. 发送方重传Packet1（什么？我发了1你给我确认0是吧，看来是没收到，那我再发一遍）
6. 接收方收到，校验成功，回应ACK1.

举个ACK出错的例子：这里没有NAK了

1. 发送方发送Packet0
2. 接收方收到，校验成功，回应ACK0.
3. 发送方收到一个哼哼哼啊啊啊啊啊，不知道啥意思，那我重传Packet0吧。（你在说啥，我听不懂啊，不管了开摆，直接重传吧.jpg）
4. 接收方收到一个重复的Packet0，丢掉，再发一个ACK0.
5. 发送方收到ACK0，这下听懂了捏。发Packet1。

为后面的一次发送多个数据单位做一个准备：

- 一次能够发送多个分组的情况下，如果对每一个分组都要发送ACK或者NAK，会很麻烦。
- 使用对前一个数据单位的ACK，代替本数据单位的NAK
- 确认信息减少一半，协议处理简单



### 可靠数据传输3.0：具有比特差错和分组丢失的信道

新的假设：下层信道可能会丢失分组（数据**或ACK**）

具有比特差错这个问题我们已经解决了，使用校验和检测比特差错，使用ACK和重传机制，重传出错的分组。

分组走到信道半路上丢失的问题我们还没解决。

- 分组丢失的原因很多，比如路由器的队列满了，多出来的分组就只能被丢弃了。

如果不添加新的机制，分组丢失会导致死锁：

1. 发送方发送P0，等待ACK0
2. 接收方接收P0，发送ACK0，等待分组P1。
3. 发送方收到ACK0，发送P1，等待ACK1.
4. P1在路上丢失，接收方一直等待分组P1，收不到P1就发不了ACK1。接收方一直等待ACK1。
5. 死锁。

增加一个机制：超时重传。发送方将分组发出去的同时，启动一个超时定时器，如果定时器超时了，还没有收到ACK，那么发送方重传分组（重传也要启动超时定时器）。

- 超时定时器的超时时间，比正常往返一个来回的时间还要多一点。如果超时了对方的ACK还没来，那大概率就是发送方发送的分组丢失了。
- 如果发送方发送的分组没丢，但是仅仅是ACK丢失了呢？
  - 接收方必须指明被正确接收的序列号
  - 发送方仍然会重传，接收方会收到一个重复的分组，但是没关系，有序号，可以分辨出这是一个重复的分组。
  - ACK丢失导致的结果其实和ACK到达发送方但是出错的结果是一样的，都是发送方没有收到正确的ACK。
  - 根据2.1的协议，然后接收方会重发一遍ACK。

举几个例子：

- 发P0，等ACK0
- 收P0，校验过，回应ACK0
- 收到ACK0，发P1，等待ACK1.
- 收P1，校验出错，回应ACK0
- 收ACK0，可以立即重传P1。也可以等超时定时器超时了，让超时重传P1。
  - 这里收到ACK0，根据2.1的机制是可以立即重传P1的。但是超时器因为没收到ACK1会一直等到超时为止，然后超时重传，所以也可以直接让超时重传机制来做重发P1。只不过是一个时间早晚的问题，也晚不了多少，因为超时时间只比往返时间多一点点，收到ACK0之后没多久就会超时。

如果定时器设置得不好，会导致定时器过早超时。但是也能正常工作，重传的分组可以用序号来分辨。 

- P0过去
- ACK0回来，没超时
- P1过去，ACK1没及时回来，超时，重传P1
- ACK1迟到了，但是还是到了，发送方收到ACK1，发送P0。
- 重传的P1到了接收方，接收方丢弃，但是还是要发送一个ACK1。
- 又到了一个ACK1，发送方又发送一遍P0。
- 接收方先后收到两个P0，先后发送两个ACK0。
- 发送方先后收到两个ACK0，先后发送两个P1。
- 就这样重复下去，可以发现有一半的分组和ACK是重复的。所以效率很低。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230404143546158.png" alt="image-20230404143546158" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230404143601581.png" alt="image-20230404143601581" style="zoom:80%;" />

3.0可以工作，但是性能很差：

- 信道看做高速公路，分组看做是一辆载满货物的车
- 停等式协议的问题就在于，很长很长的一条高速公路，一次只允许一辆车过去，确认了才能放行下一辆车。
- 信道容量小的时候没有这样的问题，就像车尾刚出收费站，车头就到了目的地。但是信道容量大的时候问题很大，车尾出收费站，车头离目的地还远得很，路上明明可以同时容纳非常多辆的车，这种情况下效率极低的。

利用率的计算：

从信道中任取一点，一个分组的头到达这一点，到这个分组的尾部离开这一点，这段时间内信道中的这一点是利用上的，其他时间都是空闲的。

- 相当于一辆长度为1KB的车以1Gbps的速度经过这一点，需要大约8微秒。
- 端到端的延迟是15ms，一个来回30ms，加上那8微秒，是分母。分子是那8微秒。

如果放宽限制，允许高速公路上一次有两三辆车，那么高速公路的利用率变高，如果一直放宽，那么高速公路上的每一点在每时每刻都有车经过，高速公路的利用率到达百分之一百，瓶颈变成了车辆的速度（链路的带宽）。

- 这种情况就是发送方不停地啪啪啪啪发送分组，然后接收方的ACK不停地回来，信道上任意一点每时每刻都有分组经过。
- 这就是流水线。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230404144659238.png" alt="image-20230404144659238" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230404150657006.png" alt="image-20230404150657006" style="zoom:80%;" />



### 流水线协议

流水线：允许发送方在未得到对方确认的情况下一次连续发送多个分组

- 必须增加序号的范围:用多个bit表示分组的序号
- 在发送方/接收方要有缓冲区 
  - 发送方缓冲：缓存未得到确认的分组，以备可能需要重传；
  - 接收方缓存：上层用户取用数据的速率≠接收到的数据速率；接收到的数据可能乱序，排序交付（可靠）

流水线协议有两种：GoBackN和SelectiveRepeat，回退N和选择重传

但是首先，先讲通用的滑动窗口算法。发送方的缓冲区就是发送窗口，接收方的缓冲区就是接受窗口。

GBN和SR是滑动窗口协议的两个特殊版本

###  通用：滑动窗口协议（Slide Window）

停等协议：发送窗口和接收窗口的大小都为1。

GBN协议：发送窗口大小大于1，接收窗口大小为1。

选择重传：发送窗口大于1，接收窗口也大于1。

发送方的发送窗口大于1的时候，称为流水线协议。GBN和SR协议的差别在于，接收方窗口一个等于1（GBN），一个大于1（SR）。



发送缓冲区形式：内存中的一个区域，落入缓冲区的分组可以发送

- 功能：用于存放**已发送，但是没有得到确认的分组**，**或者是待发送的分组**（已发送但未确认的分组落入的是**发送窗口**，不是发送缓冲区）
- 必要性：需要重发时可用
- 发送缓冲区的大小：一次最多可以发送多少个未经确认的分组。
  - 停止等待协议=1
  - 流水线协议>1，合理的值，不能很大，链路利用率不能够超100%
- 落入发送缓冲区中的分组 
  - 未发送的：可以直接连续发送出去； 
  - 已经发送出去的、等待对方确认的分组：发送缓冲区的分组只有得到确认才能删除，否则要保留以备重传。
- 如果发送缓冲区用完了，上层就不能继续向下交付数据报。

发送窗口：发送缓冲区内容的一个范围，由那些已发送但是未经确认分组的序号构成的空间，**是发送缓冲区的一个子集，不一定是发送缓冲区本身**。

- 发送窗口的尺寸最大值<=发送缓冲区尺寸的值
- 一开始：没有发送任何一个分组，发送窗口的后沿等于前沿，前后沿之间为发送窗口的尺寸，为0。
- 每发送一个分组，前沿前移一个单位。
  - 发送窗口前沿移动的极限：不能够超过发送缓冲区
- 发送窗口后沿移动：
  - 条件：收到最靠近后沿的老分组的确认
    - （或者说从最贴近前沿的分组开始的连续多个分组的确认，此时可以连续移动多个单位）
    - 具体情况根据采用的协议而定，如果有累计确认的话，那么假如收到3号分组的确认（1和2号没收到ACK），后沿可以直接挪到4号分组处。
  - 结果：发送缓冲区罩住新的分组，来了分组可以发送
  - 移动的极限：不能够超过前沿

如下图：

- 绿色的边框代表一个长度为5的内存缓冲区，我们采用缓冲区移动，分组不动的形式。
- 绿色的缓冲区代表一段可发送的权力
- 红色的是发送窗口
- 当发送窗口的后沿往前移动时，绿色边框的后沿也往前移动，保证始终对齐发送窗口的后沿。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230404195743896.png" alt="image-20230404195743896" style="zoom:80%;" />





接收窗口：**等于**接收缓冲区（发送窗口是发送缓冲区的一个子集，但是接收窗口一定是接收缓冲区本身）

- 接收窗口用于控制哪些分组可以接收； 
  - 只有收到的分组序号落在接收窗口内才允许接收 
  - 若序号在接收窗口之外，则丢弃；
- 接收窗口尺寸等于1，则只能顺序接收；
- 接收窗口尺寸大于1，则可以乱序接收；
  - 但提交给上层的分组，要按序

接收窗口等于1的情况：GBN协议：**只能顺序接收**

- 最开始接收窗口笼罩在0的位置，等待0号分组的到来
- 0号分组到来，发送ACK0，接收窗口往前挪一个位置，笼罩1。
- 如果这时候来了2号分组，那么接收并丢弃（就是丢弃），并且再发送一个ACK0。发送方收到ACK0，就会重发1号分组。
- **只有GBN是累计确认的**：发送ACKn，说明前N个分组全部都收到了。发送连续收到的序号最大的**那一个**分组的确认。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230404201133759.png" alt="image-20230404201133759" style="zoom:80%;" />

接收窗口大于1的情况：SR协议：**可以乱序接收**

- **ACK不具备累计确认的含义，收到哪个分组，就只给哪个分组确认，不对序号在这个分组之前的分组确认。**
- 独立确认，ACKN只意味着第N号分组到了，并不意味着前N个分组全部都收到了。
- 如下图：接收方窗口长度为4。最开始接收窗口后沿在0左侧，红色边框。
- 收到0号分组，接收窗口整体往前挪动一个单位，同时发送ACK0，紫色边框。
- 收到2号分组，发送ACK2，收到3号分组，发送ACK3。将收到的分组缓冲，**但是接收窗口不挪动，因为更低序号的1号分组还没有收到**。
  - 如果这里是1号分组最先到来的话，那么可以直接接收窗口整体向前移动一个单位。
- 收到1号分组，发送ACK1，同时将刚才收到的1/2/3号分组排序、解封装、递交上层。**接收窗口整体往前移动3个单位**，蓝色边框。
- 这里的每一个ACK都仅对收到的**那一个**分组做确认，是单独确认，而不是累计确认前面所有的分组。
  - 实际上也很容易理解为什么这里不是累计确认。假如2号分组到达的时候，发送ACK2是累计确认，那么暗示1号分组也收到了，但是实际上不是这样的，而在GBN中，ACK2确实意味着1号分组（2号及以前的）肯定收到了。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/2de248990ea88ea55b91397530ab0be.jpg" alt="2de248990ea88ea55b91397530ab0be" style="zoom:80%;" />



GBN协议为什么叫GBN？

- 假如发送方连续发送个8分组，0-7号。
- 然后接收方连续收到了1,2,3,4号分组，累计确认，只发送ACK4，接收方窗口笼罩5。
- 发送方收到ACK4，发送窗口后沿移动到5处，前面1,2,3,4的定时器被关闭。
- 5号分组因为不明原因丢失了，发送方收到6和7号分组，直接丢弃，并且每收到一个分组，重发ACK4。
- 发送方由于收到的是ACK4，无法向前移动发送窗口的后沿，并且由于收到的是ACK4，类比2.2节的无NAK协议，发送方会重传：发送窗口中，4号分组以后的全部分组。所以为什么叫GBN呢？因为这里发送方回退到第4个分组，重传了第4个分组之后的全部已发送分组。
- GoBackN，不是回退N个，而是回退到第N个，重传它之后的。

另外一种情况，假如5号分组成功到达了，但是ACK5丢失了（不考虑6和7，6和7还没到）：

- 由于发送方迟迟收不到ACK5，于是没办法前移发送窗口的后沿，于是最靠近发送窗口后沿的5号分组的定时器首先超时，触发超时重传机制，重传5号分组及其以后的6和7号分组（即**重传所有已发送但是未确认的分组**）。



SR协议为什么叫SR？我们同样来考虑一下出错的时候SR的行为：

- 假如发送方窗口为5，接收方窗口为4。
- 最开始接收方窗口可以接受0-3号分组。
- 发送方连续发送4个分组，0,1,2,3。
- 接收方最先收到3，发送ACK3（单独确认3号分组），然后收到2，发送ACK2.
- 然后收到1号分组，发送ACK1。
- 接收方则依次收到ACK3、ACK2、ACK1，然后依次关闭3,2,1号分组的定时器。**但是发送窗口的后沿不能移动**
  - 因为发送方窗口存放的是**已发送但未确认的分组**。
  - 此时后沿在0号分组的左侧，虽然1,2,3号分组都已经确认了，但是不能移动窗口后沿。
  - 因为一移动窗口后沿，为了把1,2,3号分组排除在外，后沿必然在3号的右边，这样就会把0号分组也排除到发送窗口之外，表明0号分组已经被确认了，而这与事实不符合。所以不能移动后沿。
- 0号分组丢了，接收方没收到，只好先在接收窗口缓存好1，2，3号分组。
- 发送方迟迟收不到0号分组的ACK0，0号分组的超时器超时，触发0号分组的超时重传。
- 所以发送方是**选择性**地重传了0号分组。

考虑另外一种情况：0号分组没丢，ACK0丢了，同样触发超时重传。

再考虑一种情况：0号分组没丢，但是校验和对不上，发送方选择不发送ACK0（因为就是没收到正确的0号分组啊），触发超时重传。

- 为了加速，应该也可以发送NAK0？加速重传。

**SR，每发送一个分组，就要启动一个对应的计时器，每收到某个分组的确认（ACK直接确认），就要关闭其定时器**。

**GBN，发送方只为最靠近发送窗口后沿的那个分组维护一个定时器**（因为这一个就够了）。

- 到底是每个分组一个定时器，还是只维护那一个？我觉得如果只维护那一个，万一那一个没超时，后沿前移一个单位，那新的后沿分组又没有定时器了，怎么判断它超没超时？ChatGPT说是前者。我也认为是前者。

**似乎不管是GBN，还是SR，都不使用2.2节的ACK反向作为NAK的机制了？**SR不用我可以理解，但是GBN跟停等一样是顺序接收的，所以是可以用的？

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230404214231293.png" alt="image-20230404214231293" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230404214249426.png" alt="image-20230404214249426" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230404220048464.png" alt="image-20230404220048464" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230404220127637.png" alt="image-20230404220127637" style="zoom:80%;" />

### 窗口大小问题

如果使用n个比特来记录分组的序号的话，那么发送窗口的尺寸的最大值：

- GBN：$2^n - 1$
- SR：$2^{n-1}$

## 面向连接的传输：TCP

### 概述

TCP提供点到点的双向的通信。

- 全双工数据： 在同一连接中数据流双向流动。
- 点对点：进程到进程。一个发送方，一个接收方

可靠的、按顺序的字节流：没有报文边界。发两个小一点的报文，对方可能收到一个大一点的报文。应用进程的报文之间的界限，需要进程自己去维护。

管道化（流水线）：TCP拥塞控制和流量控制设置窗口大小。发送方可以在未经接收方确认的情况下，连续发送很多个TCP的报文段。

- 发送（超时重发、检错重发）和接收缓存（SR或者GBN）用于实现流水线的发送（滑动窗口协议）。接收方缓冲区存在是因为接收的速率和上层应用读取的速率可能不一致。
- 应用进程交给TCP的报文，到了TCP这里之后，会被TCP按照MSS的大小，将报文分成很多个大小（最大）为MSS的报文段，每个报文段还要加上TCP的头部。



MSS：最大报文段大小（Max Segment Size）：应用层的报文太大的时候（比如超过以太网的MTU，大于1500字节），在TCP层加上TCP的头部，在IP层加上IP的头部，它就没有办法被整体封装在物理网络（比如以太网，MTU是1500字节）的**一个**帧的载荷部分。所以在应用层报文被交给TCP的时候，应用层的报文就会被切分成多个（不大于）MSS的报文段，（大小为MSS的）之后再加上TCP头，传递给网络层，加上IP头，作为载荷传递给数据链路层，正好能够被封装在物理网络的一个MTU里面。

- 比如以太网的MTU是1500字节，IP头部是20字节，TCP头部是20字节。剩下的1460字节，就是MSS。应用层交下来的报文，会按照1460为最大单元切分为一个个的报文段。大小为1460字节的报文段，加上TCP和IP头部，正好能被封装在一个载荷为1500字节大小的以太网帧里面。
- 这样就不需要在更低层面对分组进行分片。



面向连接： 在数据交换之前，通过握手（交换控制报文） 初始化发送方、接收方的状态变量

有流量控制： 发送方不会淹没接收方

### TCP报文段结构

20字节的头部：

- 2字节的源端口、目的端口。
- **序号**：**是以字节为单位的序号**，而不是前几节当中举例时讲的PDU的序号（比如第0/1/2/3个分组）。TCP的报文段分为Header（头部）和Body（载荷）部分，Body部分就是应用层的报文片段。Body部分的第一个字节，在发送方 发送的 全部的应用层报文 **所构成的字节流中** 的偏移量，就是这个TCP报文段的序号。
  - 因为上层应用层交下来的应用层报文可能会被分成N个MSS大小的报文段，为了将属于同一个应用层报文的N个报文段正确地拼接回原来的报文，所以需要这N个报文段的序号。利用序号可以将这N个报文段正确地拼接回原来的报文，使得报文段按顺序构成完整报文。
  - 另外一方面，TCP层可能会收到M个乱序的报文段，并且这些报文段分别属于不同的应用层报文，为了将这M个报文拼接成一个有序的字节流（由多个正确拼接好的报文组成的无边界字节流），也需要这个序号。
    - 举个例子，应用层发送两个报文，分成了4个报文段，第一个报文段的序号是X，后面三个报文段的序号分别是X+MSS，X+2MSS，X+3MSS（我们很自然地知道，前两个报文段属于同一个报文，后两个报文段属于同一个报文，否则我们拼接得到的是错误的字节流）。接收方收到四个报文段之后，就可以按照其序列号排列，解封装，将Body部分取出来，拼接成由两个正确的应用层报文组成的无边界字节流。
  - 概况一下说就是，我们看作应用层发送的报文会组成一个字节流，这个字节流会被TCP分成很多个MSS大小的报文段，发送到目标进程去。目标主机的TCP陆陆续续乱序收到很多个报文段之后，需要根据报文段中的序列号，将报文段拼接复原成发送方的发送的字节流的样子。
  - 发送的第一个报文段的序号不一定是零（实际上一定不是0，为了防止老的连接的报文段对新的连接的影响，在讲TCP建立连接的时候会细讲），可以是X，第二个报文段的序号就是X+MSS。
- 确认号（ACK Number）：使用累计确认机制，总是确认已收到的最小的字节序号（因为TCP的流水线协议是GBN和SR的一个混合体）。假如接收方发送了一个ACKNumber为555的包，意思是，接收方已经收到了第554字节以及554前面的**所有字节**（解释和序号遥相呼应）。
- 首部长度：因为头部是可变的（有可选项），所以需要。
- 保留位没用。
- 标志位：RST、SYN、FIN是用于建立TCP连接和拆除连接的。A那个标志位需要置1，ACKNumber才有效。
- 接收窗口：用于流量控制。接收窗口等于某个值的话，意味着可以接受那么多字节的数据。
- 紧急数据指针现在也基本上不用。
- **除了可选项之外的头部，加起来是20个字节**，可选项的长度，用首部长度减去20。
- **接收方如何处理乱序的报文段-没有规定**。可以缓冲，也可以抛弃掉。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406152111477.png" alt="image-20230406152111477" style="zoom:67%;" />

### TCP往返延时（RTT）和超时

怎样设置TCP超时？

- 比RTT要长。但RTT是变化的？
- 太短：太早超时。不必要的重传，效率降低一半左右。 
- 太长：对报文段丢失。反应太慢，消极



怎样估计RTT？SampleRTT：测量从报文段发出到收到确认的时间。

- 我们知道TCP可以短时间内发出很多个报文段，第一个作为SampleRTT，用于测量，后面的没必要用于测量。

- 如果有重传，忽略此次测量。
- SampleRTT会变化，因此估计的RTT应该比较平滑。对几个最近的测量值求平均，而不是仅用当前的SampleRTT。

因为RTT本身就是不稳定的，所以定时器的**超时时间也不能设定成固定的值**。两个应用进程在TCP通信的时候，**TCP的超时定时器的设置并不是一个固定的值**，而是一个会变化的值。

- 使用**指数加权移动平均值**来估计当前的RTT。
- $EstimatedRTT = (1-\alpha) * EstimatedRTT + \alpha * SampleRTT$。
  - EstimatedRTT：本次测量RTT得到的RTT估计值，也会作为当前定时器的超时值
  - $(1-\alpha) * EstimatedRTT$：前一次采样的估计时间，乘以系数1-alpha。
  - SampleRTT：由本次发出的测试报文段得到的RTT测量值。
  - $\alpha$：推荐值0.125。$\alpha$的值的改变可以改变本次测量值在计算估计值时所产生的影响的大小。
  - 过去样本对本次计算的影响呈指数衰减。可以推导展开看一下：
    - 记第i次测量的估计值为$ER_i$，第i次测量的测量值为$SR_i$。
    - 公式可以改写成：$ER_i = (1-\alpha) * ER_{i-1} + \alpha * SR_i$
    - 然后按照这个公式，将ER5展开成由SR0到SR5组成的多项式，就知道什么叫指数衰减了。

但是这个值并不能直接作为定时器的超时值，我们还要考虑到如果RTT的变化波动比较大（方差比较大），超时时间就不能设置得太短。我们需要给定时器的超时值一个安全边界时间。

边界安全时间的计算：$DevRTT = (1-\beta) * DevRTT +\beta *|SampleRTT-EstimatedRTT|,\beta = 0.25$。

**超时时间间隔 = 估计RTT + 超时时间**。公式：$TimeoutInterval = EstimatedRTT + 4 * DevRTT$

### 可靠数据传输

TCP是一个流水线协议，但是TCP既不是GBN也不是SR，而**是两者的一个混合体。**

- TCP有累计确认（就像GBN）
- 只有单个重传定时器（GBN）
- 是否可以接受乱序的，没有明确规定（接收窗口大于1，SR）。
- **TCP的ACK只对顺序到来的最后一个字节确认（和GBN很像）**

何时触发重传：

- 超时重传，只重传最早的那个未确认的报文段（很像GBN，回到丢失的最老的分组，重发）
- 超时器还没超时，但是连续收到三个冗余的（相同的）ACK确认。第一个ACK是正常的确认，之后又收到三个相同的冗余的ACK。**快速重传**

TCP基于IP提供的不可靠的服务，实现了可靠的数据传输。



首先考虑简化情况下的TCP发送方：不考虑重复ACK和拥塞控制：

- 初始化，发送方选定一个初始序号X（并告知接收方，这一步是在建立连接的时候做的），NextSeqNum = X，SendBase = X（SendBase是发送窗口的左沿）。
- 从应用层收到报文，创建报文段，其序号为NextSeqNum，将报文段递交给IP层。同时更新**NextSeqNum = NextSeqNum + 数据的长度（Body部分的长度，不是整个TCP报文段的长度）**。相当于发送窗口的右沿向右滑动。
- 如果定时器没有启动，启动它。
- 如果超时事件发生，那么重发最老的报文段，重启定时器。
- 如果发送方收到一个ACK，比如ACK555（当然，**确认号要大于当前的SendBase**，毕竟你总不可能让左沿左滑回去），说明接收方已经收到了554以及之前的全部字节，要将SendBase移动到555的位置（发送窗口左沿右滑）。每次移动之后，都要判断：**如果SendBase = NextSeqNum,说明发送窗口后沿和前沿靠拢，当前没有已发送但未确认的字节，需要关掉计时器**，反之需要启动计时器。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406191558698.png" alt="image-20230406191558698" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406191648327.png" alt="image-20230406191648327" style="zoom:80%;" />

```java
NextSeqNum=InitialSeqNum;//发送窗口前沿
SendBase=InitialSeqNum;//发送窗口后沿
while(true){
    switch(event)
        event:data received from application above//从上层收到数据
			create TCP segment with sequence number NextSeqNum;//封装报文段，序列号是NextSeqNum
			if(timer currently not running){//如果定时器未启动，启动定时器
                start timer;
            }
			pass segment to IP;//传递报文段给网络层
			NextSeqNum=NextSeqNum+length(data);//更新序列号。根据序列号的定义可得更新只需NextSeqNum加上发送的Body部分的长度即可
        	break;
	    event:timer timeout//时钟超时
			retransmit not-yet-acknowledged segment with smallest sequence number;//重传最老的未确认的报文段
    		start timer;//重启定时器
    		break;
        event:ACK received,with ACK field value of y//收到ACKy，说明y字节之前的字节（不含y）都已收到。
			if(y>SendBase){//更新发送窗口的后沿
			SendBase=y;
            }
			if(there are currently not-yet-acknowledged segments){//if(SendBase != NextSeqNum)
                //there are currently not-yet-acknowledged segments:如果当前还有未确认的段，即Base还没移动到Next
                start timer;
            }
} /* end of loop forever */
```

重传：从左往右依次三种情况：

第一种：ACK丢失

1. A发送8字节数据（92-99共8字节），序列号92。
2. B发送ACK100，但是丢失了
3. A定时器超时，重发序号为82的8字节数据
4. B收到重复的数据，丢弃，重发ACK100。
5. 发送方把发送窗口后沿移到100的位置。

第二种：过早超时

1. A发送序号92的8字节数据
2. B发送ACK100，A发送序号100的20字节数据。
3. B发送ACK120。
4. ACK100还没到A，A的定时器超时，A重发序号92的8字节数据。
5. B收到重复的序号92的8字节数据。但是B目前已经收到了序号为120的字节之前的数据，所以**重发ACK120（不是ACK100）**

第三种：累计确认

1. A发送序号92的8字节数据。
2. B收到92号数据，发送ACK100。A发送序号100的20字节数据
3. ACK100丢失了。B收到序号100的数据，发送ACK120。
4. 但是定时器还没超时。ACK120及时到达了A，确认20字节数据的同时，顺便累计确认了第一次发送的8字节数据。
5. A将发送窗口后沿前移到120的位置。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406195027298.png" alt="image-20230406195027298" style="zoom: 90%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406200739480.png" alt="image-20230406200739480" style="zoom:90%;" />

**RFC关于接收方产生ACK的一些建议：**每行接收方事件和同一行的接收方动作对应

第一种情况：紫色的报文段按序到达，所有在紫色之前的红色报文段都已经确认（即紫色报文段第一个字节紧贴接收窗口后沿，左边是后沿，因为向右是前方）

- 这个时候按理可以直接发送ACKy1的，但是我们先不发，我们等一小会，设置一个辅助定时器500毫秒。
- 如果在500毫秒内，与紫色报文段直接相邻的蓝色报文段也到达了（即下一个报文段也是按序到达的），那么利用累计确认，直接发送ACKy2。
- 否则，500毫秒内没到，或者到了另外一个乱序到达的报文段，那就只能发ACKy1。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/c2eb08109ceb7c96f05892ae3c72335.jpg" alt="c2eb08109ceb7c96f05892ae3c72335" style="zoom: 33%;" />

第二种情况：第一种的另外一个角度，即我们已经按下了一个报文段的ACK没发（紫色的ACKy1），然后又按序到来了下一个报文段（蓝色的）.立即发送ACKy2，以累计确认。

第三种情况：本来期望的是序号Y1的段来的，但是序号比它大的段乱序先到了（紫色）。这个时候数据流中存在间隔（叫做gap，即紫色左边界和后沿之间有空白）。前面的没到，后面的反倒先到了，那我肯定觉得前面的是不是丢了，所以立即重发ACKy1，让发送方赶紧把这个段补给我。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/fdd01cee3fd62a7257c110b82c05b6c.jpg" alt="fdd01cee3fd62a7257c110b82c05b6c" style="zoom:33%;" />

第四种情况：在第三种情况的基础上，又到达了一部分的报文，把间隔（Gap）部分补齐了（但是中间还是空了一点），那么立即发送ACKy3。如果之后到达的报文把gap全部补齐了，那么立即发送ACKy2。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/677e175c32de90e1be3aebe57b68c58.jpg" alt="677e175c32de90e1be3aebe57b68c58" style="zoom: 33%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406202103578.png" alt="image-20230406202103578" style="zoom:80%;" />



**快速重传：定时器还没超时，但是收到连续三个相同的冗余的ACK，发送方立即重传**。

举例：

- 先收到序号40的段，然后陆陆续续收到序号60/70/80的段，但是序号50的段迟迟没到。
- 收到序号40的段的时候发送ACK50是正常确认，后面每收到一个段，都发送一个ACK50（TCP只对顺序到来的最后一个字节确认），后面三个ACK就是连续三个冗余的ACK，这时候（还没超时）发送方就会快速重传。
- 连续收到三个段，但是中间缺了一块。

<img src="https://i.imgur.com/PFl66CZ.jpg" alt="2ae6cbce80891dcbc415a94febcefdd" style="zoom: 33%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406205344560.png" alt="image-20230406205344560" style="zoom:67%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406205404953.png" alt="image-20230406205404953" style="zoom:80%;" />

快速重传的算法伪代码

```java
int dupNum = 0;//记录收到的重复ACK的数目
event: ACK received, with ACK field value of y 
if (y > SendBase) { 
    SendBase = y;//y大于SendBase，那么把发送窗口后沿移动到y的位置
    dupNum = 0;
if (there are currently not-yet-acknowledged segments)
    start timer;
}
else {//y不可能小于SendBase，不是大于就是等于。这里就是y等于SendBase。等于说明收到了重复的ACK，所以要开始记录重复个数。
    dupNum ++;//increment count of dup ACKs received for y;
    if (dupNum == 3) {//count of dup ACKs received for y = 3。收到连续三个冗余ACK，就要快速重传了。
        resend segment with sequence number y;
    }
```

### TCP流量控制

任何一个TCP实体，既是发送方也是接收方，不过我们讲述的时候只讲单向的即可。

流量控制：发送方控制其发送的速度，使得接收方不会被数据淹没。

机制：接收方使用捎带技术（类似捎带确认一样，因为本质上发送方也是接收方，接收方也是发送方），将其接收窗口中（接收窗口大小恒等于接收缓冲区大小）还有多少空闲空间告知发送方（TCP的头部有个接收窗口字段，只需要在某个返回发送方的TCP报文段中填一下这个值就行了，坐个顺风车），发送方控制自己发送的字节数不超过空闲空间的大小就行了。



空闲缓冲区大小的计算：

- 假定TCP直接丢弃乱序到达的报文。这样会使得空闲的空间是连续的，而不会被乱序到达的报文分割成几个部分。
- 我们维护两个变量：一个是应用层已经读到了哪个字节，一个是最后一个接收的字节的位置，二者一减就是还剩下的未读取的字节数。再用缓冲区大小减掉这个字节数即可。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406212930973.png" alt="image-20230406212930973" style="zoom:67%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406212959232.png" alt="image-20230406212959232" style="zoom:67%;" />

### TCP连接管理

两个应用进程在通信之间需要先建立连接，需要握手。两个应用进程在通信完毕之后，需要拆除连接。

握手，本质上是为了两件事：

- 双方都同意建立连接（每一方都知道对方愿意建立连接）
- 双方协商各种连接参数。为通信准备好各种资源（发送缓冲区，接收缓冲区，等等），有些控制变量需要初始化，置位。（比如发送的初始序号X，发送窗口有多大，接收窗口有多大，窗口的前后沿的初始化），然后还要互相告知这些信息（你的初始序号X告诉我，我的Y告诉你。你的初始化接收缓冲区大小告诉我，我的告诉你）。

二次握手（连接请求==>连接确认（ACK）为什么不可以？

失败场景一：服务器端维护了半个连接。

1. 客户端发出连接请求
2. 连接请求走的比较慢，直到定时器超时了还没走到服务器（但是没丢，只是滞留在网络中）。
3. 客户端超时，重发连接请求。这次走得很快，服务端很快回复连接确认，连接建立起来。
4. 一段时间后双方关闭了连接。
5. 再过一段时间，滞留的请求终于到达了服务端。服务器认为这是一个新的连接请求，于是接受了这个请求，维护了半个连接。
6. 而客户端对服务器维护了一个半连接一无所知。

失败场景二：老的数据被当成新数据接受了

1. 客户端连接请求。服务器ACK到的比较晚，定时器超时了，重发了请求。ACK姗姗来迟。
2. 连接建立。此时重发的连接请求还在路上。
3. 客户端给服务器发数据。数据的ACK也走得很慢，数据也超时重发了。
4. 数据的ACK终于到了客户端，客户端和服务器关闭连接。但是此时重发的数据还在路上。
5. 因为重发的连接请求发得更早，所以它先一步到达服务器，服务器又维护了一个半连接。
6. 重发的数据也终于到了服务器，被服务器的半连接接收。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406220846398.png" alt="image-20230406220846398" style="zoom:67%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406220941963.png" alt="image-20230406220941963" style="zoom:67%;" />

TCP3次握手：

为什么需要三次连接呢？光双方相互告知自己选择的初始序号X和Y，就需要三次握手：

1. 我把我选择的传输报文段时的初始序号X告诉你。
2. 你给我发一个ACKx+1
3. 你把你选择的初始序号Y告诉我
4. 我给你发一个ACKy+1。

2和3使用捎带，合并成一次，就是三次握手。

3次握手的过程：两个TCP实体A和B

1. A选择初始序号X，发送TCP的SYN报文（将头部的SYN比特置为1），报文中头部的序列号比特置为X。
2. B收到报文，选择初始序号Y，发送ACK/SYN报文（ACK比特和SYN比特都置为1），头部的ACKNumber = X + 1，头部的序列号部分置为Y。
3. A收到报文，发送ACK报文，ACKNumber = Y+ 1，并且Body部分可能含有应用层的数据。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406222415530.png" alt="image-20230406222415530" style="zoom:67%;" />



3次握手是如何解决2次握手存在的问题的？

第一个问题是半连接，第二个问题是不仅半连接，而且这个半连接还接收老的数据。只要解决了半连接问题，这两个问题就都不存在了。

1. 客户端连接请求（第一次握手），发送序号X。超时重发一个连接请求
2. 服务器发送ACKx+1和序号Y。
3. 客户端发送ACKy+1（和可能的应用层数据）。
4. 传数据，传完，关闭连接。
5. 重发的连接请求终于到达了服务器。
6. 服务器接收请求，发出第二次握手。
7. 服务器不知道这是重复的请求，但是客户端知道呀，客户端就拒绝这个请求。半连接就建立不起来。
8. 半连接建立不起来，即使旧的数据到达了服务器，也不会被接收。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406224848231.png" style="zoom:67%;" />

补充：**为什么每次建立连接都要随机选择序号X和Y，而不是使用固定的从0开始的序号（或者从别的固定值）**?

场景构建：

1. 源端口555，目的端口80。
2. 源和目的建立连接，源发送序号为0的数据。这个数据的TCP头，源端口是555，目标端口是80。然后超时重发了0号数据。
3. 源和目的立即断开连接，超时重发的数据此时还没到达目的。（第一次发的并不是丢了，只是ACK走得比较慢）
4. 然后源和目的又立即重新建立连接，源端口555，目标端口80。
5. 重发的数据终于到了目的。它的源端口和目标端口都完全一致，并且序号也是对的。于是被目标接收。
6. 于是目标接收了一个老的数据。

**每次随机选择序号X和Y就是为了尽量避免这种情况，随机选择的情况下，老的数据的序号范围和新的连接的序号范围重叠的可能性很小（至少实践证明是可行的）**



TCP连接释放： 

释放很简单。服务器和客户端是双向通信的，所以连接关闭的时候，要分别在两个方向关闭：

1. 客户端发出连接拆除请求，一个TCP的FIN报文。
2. 服务器端确认连接拆除请求，同意连接拆除，一个ACK报文。这时客户端向服务器发送数据的通道关闭，但是服务器还可以向客户端发送数据。
3. 服务器向客户端发送连接拆除请求，也是向客户端发一个TCP的FIN报文。
4. 客户端同意请求，发一个ACK给服务器。这时服务器向客户端发送数据的通道也被关闭。整个连接被拆除。

TCP的连接拆除存在所谓的[两军问题](https://blog.csdn.net/weixin_29170327/article/details/119068664)。但是无所谓了，解决不了的，不然没完没了了。



<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406231034485.png" alt="image-20230406231034485" style="zoom:67%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230406231119817.png" alt="image-20230406231119817" style="zoom:67%;" />

## 拥塞控制原理

拥塞:

- 非正式的定义: “太多的数据需要网络传输，超过了网络的处理能力
- 与流量控制不同
- 拥塞的表现:
  - 分组丢失 (路由器缓冲区溢出)
  - 分组经历比较长的延迟(在路由器的队列中排队)。会导致不必要的**超时重传**
- 拥塞的代价：
  - 为了达到一个有效输出，网络需要做更多的工作（重传）
  - 没有必要的重传，链路中包括了多个分组的拷贝。这些拷贝是那些没有丢失，经历的时间比较长（拥塞状态）但是超时的分组。链路中重复的分组比较多，降低了的“goodput”（有效的输出）
  - 当分组丢失时，任何“关于这个分组的上游传输能力”都被浪费了。好不容易历经十几跳，却在最后一跳前被路由器丢失了，前面所有路由器的传输工作都是白费。

### 拥塞控制方法

2种常用的拥塞控制方法：

- 端到端拥塞控制：没有来自网络的显式反馈。端系统根据延迟和丢失事件推断是否有拥塞。
  - **TCP采用的方法**。
- 网络辅助的拥塞控制：路由器提供给端系统以反馈信息。端系统根据网络的反馈信息，决定是不增加速率还是降低速率还是提高速率。
  - 单个bit置位，显示有拥塞 (SNA, DECbit, TCP/IP ECN, ATM)
  - 显式提供发送端可以采用的速率

### ATM ABR 拥塞控制

ABR: available bit rate。

提供一个“弹性服务”：

- 网络轻载的时候，发送方就尽可能使用可用带宽。
- 如果发送方的路径拥塞：发送方限制其发送的速度到一个最小保障速率上。（吃低保）

ATM网络的数据单元叫信元。信元分两种：数据信元和资源管理信元。

- ATM网络使用资源管理信元（RM信元）做拥塞控制。
- RM信元由**发送端**发送，在数据信元中间隔插入。
- RM信元中有标志位，这些标志位由网络中的交换机进行设置（“网络辅助”嘛）。
  - NI bit: no increase in rate (轻微拥塞)发送端的发送速率不要增加了。
  - CI bit: congestion  indication 拥塞指示。
- 发送端发送的RM信元被接收端返回, 接收端不做任何改变。发送方收到回收的RM信元，就知道网络的拥塞状况如何。
- 在RM信元中的2个字节 ER (explicit rate)字段。这个字段用于显式告知发送端，网络可以保证提供给它的速率是多少。
  - 拥塞的交换机可能会降低信元中ER的值。比如依次经过ABC三个交换机，A将ER设置为100kbps，但是B拥塞，只能提供50kbps，C更拥塞，只有25kbps，那么RM信元中的ER字段就会由100变为50，再变为25（但是如果B是150kbps，大于ER当前值，B则不会改变ER的值）。然后RM信元被接收端原样返回给发送端，发送端收到RM信元，就知道应该将自己的发送速率限制在多少以下。
  - 发送端发送速度因此是最低的可支持速率。

## TCP拥塞

TCP是典型的端到端的拥塞控制，网络不提供任何辅助信息。

- 路由器不向主机有关拥塞的反馈信息。路由器的负担较轻，符合网络核心简单的TCP/IP架构原则
- 端系统根据自身得到的信息，判断是否发生拥塞，从而采取动作

拥塞控制的几个问题：

如何检测拥塞？

- 轻微拥塞
- 拥塞

控制策略？

- 在拥塞发送时如何动作，降低速率。轻微拥塞，如何降低？ 拥塞时，如何降低？
- 在拥塞缓解时如何动作，增加速率？

### TCP 拥塞控制：拥塞感知

发送端如何探测到拥塞?



某个段超时了（丢失事件 ）：拥塞

- 超时时间到，某个段的确认没有来。
- 原因1：网络拥塞（某个路由器缓冲区没空间了，被丢弃）。概率大。
- 原因2：出错被丢弃了（各级错误，没有通过校验，被丢弃）。概率小
  - **校验动作肯定不仅仅是在接收方会做的，每到达一个节点都会做。因为把已经出错的数据继续传递下去只会浪费链路的传输能力**。
- 一旦超时，就认为拥塞了，有一定误判，但是总体控制方向是对的



有关某个段的3次重复ACK（即触发了快速重传）：轻微拥塞 

- 段的第1个ack，正常，确认绿段，期待红段 
- 段的第2个重复ack，意味着红段的后一段收到了，蓝段乱序到达 
- 段的第2、3、4个ack重复，意味着红段的后第2、3、4个段收到了，橙段乱序到达，同时红段丢失的可能性很大（后面3个段都到了，红段都没到） 
- 网络这时还能够进行一定程度的传输，拥塞但情况要比第一种好

![image-20230407153705655](https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407153705655.png)

### TCP 拥塞控制：速率控制方法

如何控制发送端发送的速率？

- 维持一个拥塞窗口的值：CongWin（CongestionWindow）。拥塞窗口的值除以RTT（单位：字节/秒），就是限制发送方的发送速率。
- 发送端限制已发送但是未确认的数据量（的上限）小于等于拥塞窗口的值。从而粗略地控制发送方的往网络中注入的速率。

### TCP 拥塞控制：速率控制方法

如果发生超时：将拥塞窗口的大小变为一个MSS，进入慢启动阶段。然后逐渐增加拥塞窗口的值，每一个RTT加一倍。当拥塞窗口的值到达原窗口值的一半，进入拥塞避免阶段。拥塞避免阶段，每个RTT，拥塞窗口的值增加一个MSS。

如果收到3个重复ack ：拥塞窗口降为原来的值的一半，然后直接进入拥塞避免阶段。

- 3个重复的ACK表示网络还有一定的段传输能力。超时之前的3个重复的ACK表示“警报

如果一切正常：先慢启动，然后拥塞避免，逐步增加拥塞窗口的值。



**为了同时满足流量控制和拥塞控制的要求，发送方实际发送的字节数，是拥塞窗口和接收窗口中较小的那一个**。

- 为了不淹没接收方，发送的字节数要不超过接收方的接收窗口大小（从来自接收方的TCP报文段头部可读）
- 为了拥塞控制，发送方的字节数要不超过拥塞窗口的大小
- 为了同时满足二者，取两个窗口中较小的那一个值，作为实际发送的字节数。

### TCP 拥塞控制：策略概述

拥塞控制策略:

- 慢启动（SlowStart，慢启动）
- AIMD：线性增、乘性减少
- 超时事件后的保守策略



TCP 慢启动：

- 连接刚建立，拥塞窗口的值设置为一个MSS。
- 然后发送报文段。
- 每个过RTT，拥塞窗口的值加倍。
  - 等效于，每收到一个ACK，拥塞窗口的值加一。一开始1个MSS，收到1个ACK，拥塞窗口变为2。发出去2个MSS，收回来两个ACK，拥塞窗口变为2+2 = 4。发出去4个MSS，收回4个ACK，拥塞窗口变为8。和每过一个RTT，拥塞窗口加倍是等效的。

- 总结: 初始速率很慢，但是加速却是指数性的。指数增加，SS时间很短，长期来看可以忽略。

拥塞窗口很快就会变得很大，所以毫无意外地会发生丢失事件：

- 发生超时事件后，直接将拥塞窗口的值重新设置为一个MSS，重新进入慢启动阶段。同时将原拥塞窗口的值的一半，作为新的临界阈值。
  - 1==>2==>4==>8==>16(超时)==>1==>2==>4==>8==>9==>10....（基本上稳定）
  - 因为网络是在8到16之间发生拥塞的，16的前一个值是8，所以将8设置为临界警戒阈值。
- 当拥塞窗口的值到达临界阈值，进入拥塞避免阶段（CA，CongestionAvoidance）。每个RTT，拥塞窗口的值增加一个MSS。

当就这样不断改进，拥塞窗口的值使得发送方不会出现超时事件，但是会收到连续三个冗余ACK（触发快速重传，说明轻微拥塞）时：

- 收到连续三个冗余ACK，说明触发快速重传。将拥塞窗口的值设置为刚才的值的一半（拥塞窗口值减半）。
- 然后进入拥塞避免阶段，**没有慢启动阶段**。
  - 有没有发现这里也没有所谓的临界值，临界值就是从慢启动切换为拥塞避免的临界点
  - 因为这里直接没有慢启动阶段，也就不需要那个临界值。而且拥塞窗口直接被置为了（本来是临界值的）那个值。

**如果没有超时，直接收到了三个冗余ACK，那么直接拥塞窗口的值减半，直接进入CA阶段**。

- 3个重复的ACK表示网络还有一定的段传输能力。超时之前的3个重复的ACK表示“警报

总结：

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407163310876.png" alt="image-20230407163310876" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407164202048.png" alt="image-20230407164202048" style="zoom:80%;" />

### TCP的公平性

公平性目标: 如果 K个TCP会话共享一个链路带宽为R的瓶颈，每一个会话的有效带宽为R/K。

**TCP是公平的**（大致公平的）。

红框里的分母应该是20，不是2。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407170533458.png" alt="image-20230407170533458" style="zoom:80%;" />

#  网络层：数据平面

## 导论

网络层提供的服务：将来自传输层的TCP报文段或者是UDP数据报，封装成IP分组（IP数据报），在发送主机和接收主机之间传送。

- 尽力而为的服务：不保证带宽、不保证不丢失、不保证顺序不乱、不保证延迟和延迟差、也不提供关于网络拥塞程度的反馈

- 提供主机到主机的服务，IP数据报一跳一跳地从源主机传到目标主机。
- 发送端将段封装在数据报中。
- 接收端解封装，将段递交给传输层的协议。
- **网络层协议存在于每一个主机和路由器**。
- **路由器检查每一个经过它的IP数据报的IP头部**
  - 路由器到达路由器，链路层将帧解封装，得到IP数据报，交给网络层，网络层查看数据报的源IP和目标IP，决定路由转发方向。
  - 然后将IP数据报递交下去，由下层重新封装，转发出去。
  - 最后到达目标主机，再完成一个大的解封装。



网络层功能：

- 转发：将分组从路由器的输入接口转发到合适的输出接口。局部的功能
  - 我是一个路由器，我插了很多个物理网卡，接入了很多个物理网络之中，比如一个以太网，一个ATM网，一个802.11。
  - 我从这些网络中取分组，解封装，查路由表，然后决定转发到另外一个网络。分组被封装成那个物理网络的帧，再转发出去。
  - 转发出去的时候需要重新封装，并且每一个输出接口通过网卡接入的链路层网络可能是不一样的，需要做不同的链路层封装。
- 路由：使用路由算法来决定分组从发送主机到目标接收主机的路径。全局的功能
  - 路由选择算法
  - 路由选择协议

**转发是数据平面的功能，路由是控制平面的功能**。转发依赖于路由表，路由表是由控制平面的路由功能算出来的。



数据平面： 本地，每个路由器功能。决定从路由器输入端口到达的分组如何转发到输出端口

转发功能： 

- 传统方式：基于目标地址+转发表：
  - 路由器上插了很多网卡，通过网卡接入很多不同的物理网络，网卡负责数据链路层的工作，将帧解封装，得到IP数据包递交给网络层。
  - 网络层查看分组当当中的目标IP取出来，查路由表，决定从哪个端口放出去。
  - 决定从哪个端口放出去，就把分组交给对应的网卡，让这个网卡将分组封装成这个物理网络对应的帧，然后发出去。
- SDN方式：基于多个字段+流表

控制平面：网络范围内的逻辑。决定数据报如何在路由器之间路由，决定数据报从源到目标主机之间的端到端路径

- 2个控制平面方法:
  - 传统的路由算法: 在路由器中被实现
  - software-defined networking (SDN): 在远程的服务器中实现

传统方式下，每个路由器既实现了数据平面也实现了控制平面。路由器上的路由实体，与其他路由器的路由实体交换信息，算出路由表交给IP实体，IP实体查表匹配，然后做转发。

**路由表是控制平面和数据平面的黏合剂，路由表由控制平面计算，被数据平面使用**。

- 问题：
  - 数据平面和控制平面耦合。寻求解耦——SDN。

网络层的服务模型：

- 对于单个数据报的服务:

  - 可靠传送

  - 延迟保证，如：少于40ms的延迟

- 对于数据报流的服务:

  - 保序数据报传送
  - 保证流的最小带宽
  - 分组之间的延迟差

## 路由器组成

输入端口：输入

输出端口：输出

把输入端口和输出端口连在一起的是交换机，通过交换机转发到另外一个路由器的输入端口。

**实际上任何一个端口既是输入端口，也是输出端口**。

### 输入端口

**输入端口有输入缓冲队列**。

输入端口的数据链路层收到由物理层递交给它的帧，判断一下帧当中的目标MAC和自己的MAC是否相等，如果不相等就丢弃。

相等的话，然后将帧的载荷部分（一个IP数据报）递交给网络层。网络层的分组在输入端口的缓冲区排队，排到队头，根据分组的目标IP地址，查路由表进行转发。

为什么在输入端口需要有一个队列来作为缓冲？因为头部阻塞的原因，可能会导致短时间内输入端口输入的速度稍快于交换（转发）的速度。

- 头部阻塞：排在队列头部的数据报阻塞了队列中其他数据报向前移动。
- 比如下图，有两个红色分组都想往同一个输出端口转发，那么必然会有一个红色分组被暂时阻塞。
- 分组运气好排在对头，运气差排在队尾，运气再差，缓冲区溢出了，分组就丢了。可能在输入队列会被丢弃掉，也可能在输出队列被丢弃掉。
- 当然缓冲区也没必要太大，太大的缓冲区，排在后面的分组可能早就超时了。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407214632969.png" alt="image-20230407214632969" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407215230188.png" alt="image-20230407215230188" style="zoom:80%;" />



### 交换结构

功能：将分组从输入缓冲区传输到合适的输出端口

交换速率：分组可以按照该速率从输入传输到输出。

运行速度经常是输入/输出链路速率的若干倍： 

- N个输入端口：交换机构的交换速度是输入线路速度的N倍比较理想，才不会成为瓶颈。



通过内存交换的路由器：是软件实现的路由，路由器就是一台通用计算机。

- 问题：分组要经过系统总线两次，总线成为瓶颈。速度不是那么高。

通过总线交换：输入端口输出端口都挂在总线上，所有端口都能看见所有的分组。

- 输出端口查看它们的目标端，如果和自己的端口匹配，转发出去，否则丢弃。

通过互联网络交换：看图吧

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407220114417.png" alt="image-20230407220114417" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407220206330.png" alt="image-20230407220206330" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407220416455.png" alt="image-20230407220416455" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407220435582.png" alt="image-20230407220435582" style="zoom:80%;" />

### 输出端口

输出端口这边同样有网络层、数据链路层、物理层。

物理层负责将帧的每一个比特变换成物理信号打出去。

链路层：成帧，给网络层传递下来的IP数据报加上帧头帧尾，附上源MAC地址和目标MAC地址。

在输出端口也要排队，排到对头，然后进行转发。

为什么要排队？因为到达某端口的速率可能比从该端口转发出去的速率要大。所以需要一个队列来缓冲。**如果队列缓冲区溢出了，那么也会丢弃分组**

- 端口有很多，每个队列一个输出队列，但是一次只能有一个对列的分组被路由器转发出去，所以需要调度，也需要队列做缓冲。
- 调度规则可以对一些高优先级的分组优先进行传送，从而达到一些对服务质量的支持。
- 就类似OS的CPU的调度。

### 调度机制

调度机制，除了选择下一个要通过链路传输的分组以外，还有一个问题需要考虑：缓冲满了需要丢弃分组的时候，丢弃哪一个？

- FIFO
- 优先级：具体不展开了，研究生课程
- RR：轮转着来
- 加权公平队列：类似多级反馈队列调度？

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407223511154.png" alt="image-20230407223511154" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407223653494.png" alt="image-20230407223653494" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407224359891.png" alt="image-20230407224359891" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230407224413307.png" alt="image-20230407224413307" style="zoom:80%;" />



## Internet Protocol(IP)

### IP数据报格式

固定20字节的头部，当然还有一些可选的选项，选项也属于头部，所以头部是可变长的。

- IP协议版本号：IPv6（0110）/IPv4（0100）
- 头部长度：**以4字节为一个单位，值最少是5（20字节的固定头部，4*5 = 20，没有载荷部分和选项部分）**。
- 服务类型（Type Of Service）：基本上废弃不用了。
- 数据报总长（Length）：数据报的总长度
- 16比特标识符、flag、fragmentOffset：用于分片、重组的
-  **标志位（Flags）**：3位字段，用于控制数据包分片和重组。包括：
  - Reserved：保留位。目前没用
  - **DF（Don't Fragment）**： 1位，如果设置为1，则数据包不允许进行分片。
  - **MF（More Fragments）**： 1位，如果设置为1，表示后续还有分片。

- TTL：每过一个路由器减一，到达零时分组会扔掉。路由器发出一个ICMP错误报告给源主机。
- UpperLayer：IP的载荷部分应该交给传输层（也可能是网络层，ICMP）的哪个协议？UDP/TCP？上层用户的一个标识。
- 校验和：**头部**的校验和，数据部分不由它校验。判断头部在传输过程中是否出问题。
  - **校验和每经过一个路由器就要重新计算，因为TTL变了**。

- 32位的源IP和目标IP。
- 可选的选项，变长。
- 最后是数据部分的载荷。TCP或者UDP的报文段。

<img src="https://i.imgur.com/qWvaxlW.png" alt="image-20230410103411927" style="zoom:67%;" />

### IP分片和重组

为什么需要分片？因为给网络层提供服务的数据链路层，它具有一个叫做最大传输单元（MTU）的属性。

MTU：链路层的帧的载荷部分的最大长度。比如以太网是1500个字节的MTU，那么以太网的帧的载荷部分的IP数据报的长度就不能超过1500个字节。

但是有的时候会从传输层传递一个很大很大的报文段，如果整个报文段都封装在一个IP数据报，会超过链路层的MTU。

解决方法：将报文段分片，分成多个独立的IP数据报，独立路由每个数据报，到达目标主机再进行重组。

举个例子：假如有一个4000字节的IP数据报（20字节IP头部 + 3980字节的载荷部分），想要通过以太网帧传输出去。

- 单个数据报超过了以太网的MTU，对数据报的载荷部分分片：
  - 第一个分片：20字节的IP头部（修改16比特标识符、标志位MF = 1、片偏移量 = 0） + 1480字节的数据部分。
  - 第二个分片：20字节的IP头部（16比特标识符和第一个分片相同，标志位MF = 1、片偏移量 = 185） + 1480字节的数据部分。
  - 第三个分片：20字节的IP头部（16比特标识符和前两个分片相同、标志位MF变为0、片偏移量 = 370） + 1020字节的数据部分。

16比特标识符：用于辨认分片之前属于同一个分组（数据部分来自同一个传输层数据）的分片。来自同一个地方的分片的标识符相同

flag：MoreFragment标志位，表示当前的IP数据报是否是全部分组的最后一个分组。

fragmentOffset：以**8字节为一个单位计算的**，片内偏移量。用于正确地重组分片。



问题：如果目标主机只收到了3个分片中的两个，丢了一个怎么办？只能全部扔了。

- 当目标主机收到一个分片，它会启动定时器。如果定时器超时了，全部分片还没到齐，那么就丢弃已经收到的全部分片。
- 因为目标主机的网络层丢掉了全部分片，那么上层传输层就收不到报文段。如果是UDP，丢了就丢了，如果是TCP，发送方会因为收不到ACK，重传。

问题：为什么不在每一跳的路由器进行重组？

- 第一，没办法保证每一个分片的路由路径是完全一样的。每一个分片是独立路由的IP数据报，对于某个路由器来说，没有办法保证所有的分片都经过它。
- 第二，即使能保证第一点，后面的路由器可能还要重新分片，在这里重组无意义，而且还会加重路由器负担（路由器需要等待全部分片到达，然后重组，然后再发出去）。 

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410105545951.png" alt="image-20230410105545951" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410105554575.png" alt="image-20230410105554575" style="zoom:80%;" />

### IP地址

IP 地址: 32位标示，对主机或者路由器的接口编址

- 一台路由器至少有2个IP地址，接入两个网络（至少有一个输入网一个输出网嘛，同一个子网内部不需要借助路由器），在不同的物理网络直接转发。

接口: 主机/路由器和物理链路的连接处

- IP地址和每一个接口关联。
- 一个IP地址和一个接口相关联

- 路由器通常拥有多个接口。所以通常有多个IP地址

- 主机也有可能有多个接口。所以主机也可能有多个IP地址，插多个网卡配多个IP。

### 子网

**互联网的路由，是以子网为单位进行路由表的计算和发布，而不是对每一个IP计算路由表**。路由也是一个网络一个网络来传，知道是哪个子网的IP数据报，往那个方向发就完事了。

IP地址：分为网络号和主机号两部分

- 子网部分(高位bits)。网络号

- 主机部分(地位bits) 。主机号

什么是子网(subnet) ?

- 一个子网内的节点（主机或者路由器）它们的**IP地址的高位部分**相同（即网络号相同），这些节点构成的网络的一部分叫做子网。

- **无需路由器介入**，子网内各主机可以在物理上相互直接到达。在链路层看，可能需要借助于（多个）交换机。但是在IP的层面看，就是只需要一跳即可到达，不需要借助更多的路由器。

**子网内部也可能还可以细分为更多个小的子网，这时每个子网的网络号要更长。很多个子网也可以聚合成一个更大的子网，这时要求每个子网的网络号的更高位部分相同（网络号也具有相同前缀）**。

- 举例，一个子网的网络号是100.101，另外一个子网的网络号是100.102。它们可以说处于一个更大的子网，网络号为100。
- 反过来，一个子网的网络号是100.101，子网内的某台主机IP是100.101.001。另外一台的IP是100.101.002。可以看做这两台主机处于一个更小的子网，其网络号是100.101.00。

### IP地址分类

A类：第一个字节的第一个比特是0，剩余七个比特是网络号，剩余3个字节主机号（$2^{24} - 2$台）。

B类：前两个字节的前两个比特是10，剩余14个比特网络号，剩余2个字节主机号。

C类：前三个字节的前三个比特是110，剩余21个比特网络号，剩余1个字节的主机号（2^8 -2 = 254台）。

D类：前四个字节的前四位是1110，剩余部分是组播地址。

E类：预留

记忆规律：ABCDEF，12345。第一类（A），前一个字节的第一个比特。第二类，前两个字节的前两个比特，C类，前三个字节的前三个比特。D类是组播地址，不属于单播地址，**ABC类是单播地址**。E类是预留的。

原来发布IP的时候是不需要区分主机部分和子网部分的，因此最开始是不需要子网掩码的。直接看目标地址的前几位，就知道是A类还是B类还是C类。

**路由器在路由的时候只关心网络号，而不是具体到每一个IP该路由到哪**。

- 单播：我到你
- 组播：我到组内所有成员
- 广播：我到局域网内的所有主机

特殊IP地址：

- 子网部分全零：本网络。主机号可以为本网络的某台主机。
- 主机部分全零：本主机。
- 子网部分和主机部分全零：本网络的本主机。当一台主机还没有被分配一个IP地址的时候，用于表示主机本身（DHCP分配IP地址的时候）
- 主机部分全1，网络号为某个特定网络号：在特定网络的广播
- 32位全1：对本网络的所有主机的广播。
- 第一个字节是127开头：回路地址，TCP或者UDP发给网络层的报文，如果目标IP是127开头，那么到了网络层，翻转朝上传递回去。

主机部分全零，只有网络号部分，那么代表的是这个网络的网络号。

来自ChatGPT：

> Q：在计算机网络的网络层中，以127.xxx.xxx.xxx开头的回环IP地址，和0.0.0.0有什么区别？
>
> A：在计算机网络的网络层中，以127.xxx.xxx.xxx开头的回环IP地址和0.0.0.0有以下区别：
>
> 1. 回环IP地址（Loopback Address）：127.xxx.xxx.xxx是一个专门保留给本机使用的IP地址段，用于在本地计算机上进行测试和通信。当应用程序向此IP地址发送数据时，数据将被送回到计算机上的同一网络接口，而不会被发送到网络中。
> 2. 0.0.0.0地址（Default Route）：0.0.0.0是一个特殊的IP地址，通常用于表示所有网络地址或未知地址。当计算机需要发送数据时，如果没有特定的路由表项匹配目标地址，就会使用0.0.0.0作为默认路由地址。
>
> 因此，回环IP地址和0.0.0.0地址有着不同的作用。回环IP地址用于本地通信和测试，而0.0.0.0地址用于路由表中的默认路由地址。
>
> 
>
> Q：那么0.0.0.0是否代表的是本主机？
>
> 不一定。0.0.0.0地址通常被用作默认路由地址，而不是本地主机地址。在计算机网络中，路由器和交换机等网络设备通常使用0.0.0.0作为默认路由地址，以便在没有更好的路由选择时将数据包发送到下一个设备。
>
> 对于计算机本身而言，0.0.0.0地址通常被用来指示某个网络接口或网络适配器的所有地址。例如，在配置网络接口时，将IP地址设置为0.0.0.0可以表示该接口可以接受任何IP地址发送的数据包。因此，0.0.0.0地址不是一个特定的本地主机地址，而是用来表示某个特定网络或接口的所有地址。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410120552789.png" alt="image-20230410120552789" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410120607033.png" alt="image-20230410120607033" style="zoom:80%;" />



内网地址：**地址空间和公网IP的不重合的**

- 永远不会被当做公网IP来分配，只在局域网的内部有意义。
- **路由器不对目标地址是内网地址的分组进行转发。**

- **内网地址在互联网的范围内是不具有意义的，只在内网有意义**。

无类域间路由：原来是按照A类B类C类去匹配，然后区分网络号和主机号，要么在第一个字节划分网络号和主机号，要么在第二个字节划分，要么在第三个字节划分，划分网络号和主机号的位置很固定。无类域间路由是，32位的IP，我可以在任何一个位置划一刀，分成网络号和主机号，按需来分配。

- 比如你只有一千台不到的设备，那你主机号部分只需要1024个值，就用后10个比特作为主机号，剩下的前22比特部分作为网络号。
- 问题：你怎么知道网络号在哪里划一刀呢？使用子网掩码。
- 子网掩码也是32位，每个比特与IP的一个比特对应。每个比特的含义是：IP地址中和这个比特对应的那个比特，是否是网络号的一部分，是的话取1，否则取0。
- **只需要用IP和其子网掩码做按位与，就可以得到网络号**。然后用网络号去查询路由表（主机号在路由的时候是没有意义的，以子网为单位查路由表和路由）

 

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410122754345.png" alt="image-20230410122754345" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410122806142.png" alt="image-20230410122806142" style="zoom:80%;" />

路由表和转发算法：

- 路由表四项：目标子网号、子网掩码、下一跳的IP、走哪个端口
- 为什么只有子网号？因为是以子网为单位做路由的。
- 来一个分组，取出其目标IP，跟每个表项的掩码做一个按位与，取出其子网号，如果子网号和表项对得上，那就找到了，如果不一样，接着找。
  - 如果都没对上，最后就是使用默认表项。
- 根据下一跳的IP，获取下一跳的网卡的MAC地址（ARP协议），将下一跳的MAC地址交给数据链路层，由数据链路层转发到下一跳。
- 到达下一跳，递归回到上面“来一个分组”。最后一跳交给相应的目标主机，只有最后一跳需要主机号。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410124751750.png" alt="image-20230410124751750" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410124801311.png" alt="image-20230410124801311" style="zoom:80%;" />

### 如何获得一个IP地址（DHCP）

手动配置：网络管理员分配好，手动配置好。需要配四个东西

- IP地址
- 子网掩码
- 默认网关（Default Gateway整个网络的出口）
- 本地域名服务器（Local Nawmw设备一启动，运行DHCP协议，从DHCP服务器获取上网所需要的四个信息。允许主机在加入网络的时候，动态地从服务器那里获得IP地址

- 重新启动时，允许重新使用以前用过的IP地址。
- 支持移动用户加入到该网络（短期在网）。
- DHCP请求**被封装在UDP段中**, 封装在IP数据报中，封装在以太网的帧中。

DHCP流程：

- 主机上线，广播一下（目标IP全1，源IP全0），发一个DHCP Discover报文。“有DHCP服务器活着吗”。
  - 主机还没有公网IP，所以源IP用0.0.0.0代表主机自己。
- DHCP服务器收到，响应一个DHCP Offer报文，告知分配给主机的IP地址和响应的配套信息（另外三个东西）。“我活着呢”。
  - 服务器对DHCP DISCOVER报文的响应，是包含有效IP地址及配置的单播（或广播）报文。
  - 主机请求IP地址：发送 “DHCP request” 单播报文。“好，这个IP我要了”
  
  - 客户端对DHCP OFFER报文的响应，表示接受相关配置。
  - 为什么需要请求报文？因为可能在一个子网内有多个DHCP服务器，可能会收到多个DHCP Offer，主机需要对外告知接受了哪个服务器的给的配置。
- DHCP服务器发送地址：“DHCP ack” 报文。“行，我知道了”
  - 服务器对客户端的DHCP REQUEST报文的确认响应报文。客户端收到此报文后，才真正获得了IP地址和相关的配置信息。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410140722227.png" alt="image-20230410140722227" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410140729824.png" alt="image-20230410140729824" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410141803859.png" alt="image-20230410141803859" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410141824138.png" alt="image-20230410141824138" style="zoom:80%;" />

来自ChatGPT：

> 以下是DHCP协议的详细步骤：
>
> 1. DHCP客户端发送DHCP发现消息广播：当DHCP客户端连接到网络上时，它会发送一个DHCP发现消息广播请求，该请求会向网络上的所有DHCP服务器广播，请求为该客户端分配一个可用的IP地址。
> 2. DHCP服务器响应DHCP发现消息广播：DHCP服务器收到DHCP发现消息广播请求后，会向DHCP客户端回复一个DHCP提供消息，该消息包含了可用的IP地址和其他配置参数。
> 3. DHCP客户端请求分配IP地址：DHCP客户端收到DHCP提供消息后，会向DHCP服务器发送一个DHCP请求消息，请求分配一个IP地址。该消息还会包含客户端MAC地址、分配的IP地址、租约时间等信息。
> 4. DHCP服务器确认分配IP地址：DHCP服务器接收到DHCP请求消息后，会向DHCP客户端发送一个DHCP确认消息，确认为其分配了一个IP地址。该消息还包含IP地址、子网掩码、默认网关、DNS等其它配置参数。
> 5. DHCP客户端完成IP地址配置：DHCP客户端收到DHCP确认消息后，完成IP地址的配置，它会将分配的IP地址和其它配置参数保存在本地，并开始使用该IP地址进行网络通信。
> 6. DHCP客户端更新IP地址租约：DHCP客户端在使用分配的IP地址时，会向DHCP服务器发送DHCP请求消息，更新IP地址租约时间。如果租约时间到期，客户端会再次发送DHCP请求消息，请求续租。
> 7. DHCP服务器管理IP地址池：DHCP服务器会维护一个IP地址池，当有新的客户端请求分配IP地址时，服务器会从IP地址池中选择一个可用的IP地址进行分配。DHCP服务器还可以为不同的客户端分配不同的IP地址，以满足不同的网络需求。

### 路由聚集（route aggregation）

**聚集之后的匹配采用最长前缀匹配**。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410145223265.png" alt="image-20230410145223265" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410145232955.png" alt="image-20230410145232955" style="zoom: 67%;" />

### NAT: Network Address Translation（网络地址转换）

动机: 本地网络只有一个有效IP地址:

- 不需要从ISP分配一块地址，可用一个IP地址用于所有的（局域网）设备——省钱
- 可以在局域网改变设备的地址情况下而无须通知外界
- 可以改变ISP（地址变化）而不需要改变内部的设备地址
- 局域网内部的设备没有明确的地址，对外是不可见的——安全

假如本地网络有800台主机，但是整个网络只有一个公网IP138.76.29.7：

- 对于来自不同主机的分组，对外将其转发出去时，要将IP头部的源IP从内网地址替换成本地网络的公网IP138.76.29.7。
  - 所有离开本地网络的数据报具有一个相同的源地址NAT IP 地址：138.76.29.7。但是具有不同的端口号。

- 对于来自外部的，目标IP为138.76.29.7的所有分组，在转发到本地网络，内部路由时，要将目标IP替换为本地网络的内网地址。



路由器如何实现NAT？

- 对于对外转发的分组：替换源IP**和源端口号**为NAT的公网IP地址和新的端口号。
  - 这个替换很容易做到，因为源端口号就在Body部分的TCP/UDP报文段的头部，改一下就行了。
  - 新的端口号是当前NAT转换表内没有被使用过的端口号。
  - 其实就是用这个新的端口号来代表内网的某个IP和相应的端口号。

- 在NAT转换表中**记住**每个转换替换对：四元组（内网IP，内网端口号，外网IP，外网端口号），为NAT表的一项。
- 对于进入子网的数据分组：替换目标IP地址和端口号，采用存储在NAT表中的mapping表项，用（内网IP，内网端口号）替换。

NAT的缺陷：

- **作为一个在网络层的实体，看到了属于传输层的内容：端口号**。破坏了层与层之间的相互隔离只对外提供接口的原则。
- **外部网络的设备没有办法直接与内网中的主机直接握手**。因为内网的机器没有公网IP，公网找不着它。要解决这个问题只能使用内网穿透。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410221436721.png" alt="image-20230410221436721" style="zoom: 67%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410221452567.png" alt="image-20230410221452567" style="zoom: 67%;" />

### 内网穿透

方案：

- 静态配置NAT表
-  Universal Plug and Play (UPnP) Internet Gateway Device (IGD) 协议
- 中继 (used in Skype)
  - NAT内网的服务器**主动**建立和中继的连接（中继服务器必须是有公网IP的）
  - 外部的客户端链接到中继
  - 中继在2个连接之间桥接

### IPv6

- 头部固定40字节。
- 传输过程当中**不允许分片**。
  - 如果来了一个太大的不分片不行的分组怎么办？扔掉，然后向源主机发送ICMPv6消息，告知数据太大，发小一点的。
- IPv6：IP地址长度128位。

与IPv4相比的变化：

- 头部校验和被去掉。提高路由器的处理速度，因为IPv4的头部校验和在每一个路由器都要重新计算和更新。
- 选项部分：NextHeader

头部：40字节固定头部

- ver：版本号，为6.
- pri：优先级，为实现不同的服务质量提供的。
- flow label：流标签，属于同一个IP的同一个会话的机制，可以打上同一个流标签，试图让网络对同一个流的数据做出同样的处理。
- payload len：载荷长度
- next header：指明交给上层的TCP处理还是UDP处理
- hopLimit：TTL
- 源IP
- 目标IP

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410223046141.png" alt="image-20230410223046141" style="zoom:75%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230410223057236.png" alt="image-20230410223057236" style="zoom:75%;" />

### 从IPv4到IPv6的平移

不是所有的路由器都能够同时升级的。没有一个标记日 “flag days”，在标记日之前是IPv4的旧世界，在标记之后是IPv6的新世界。

问题：在IPv4和IPv6路由器混合时，网络如何运转? 

- 隧道: 在IPv4路由器之间传输的IPv4数据报中携带IPv6数据报。

在ABEF的内部IPv6和IPv6直接直接使用IPv6通信，没问题。如果AB要和EF通信，需要经过CD。

将来自AB的IPv6的数据报作为载荷，封装在IPv4报文中，IPv4报文的源地址是B的IPv4地址，目标地址是E的IPv4地址。

- 来自B的IPv6数据报作为载荷被C封装成IPv4的数据报，然后到达D的时候，解封装，将载荷部分的IPv6数据报交给E。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230412102631856.png" alt="image-20230412102631856" style="zoom:67%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230412102737543.png" alt="image-20230412102737543" style="zoom:67%;" />

## 通用转发和SDN

前面的区域，以后再来探索吧。

# 网络层：控制平面

理解网络层控制平面的工作原理

- 传统路由选择算法 
- SDN 控制器 
- ICMP:Internet Control Message Protocol

以及它们在互联网上的实例和实现: 

- OSPF, BGP, OpenFlow, ODL 和ONOS控制器, ICMP, SNMP

## 路由选择算法

路由:按照某种指标(传输延迟,所经过的站点数目等)找到一条从源节点到目标节点的较好路径

- 路径：路由器的序列。

- 较好路径: 按照某种指标较小的路径。不求最好路径，代价太大。
- 指标:跳数, 延迟,费用,队列长度等, 或者是一些单纯指标的加权平均。
- 采用什么样的指标,表示网络使用者希望网络在什么方面表现突出,什么指标网络使用者比较重视

第一跳肯定是从源主机交给本子网的出口路由器（出口网关），最后一跳肯定是目标主机的子网的接入点到目标主机。



**路由的时候只关心IP的子网号部分，不关心主机号部分**。可以认为网络层的路由是子网到子网的路由。

- 网络为单位进行路由，路由信息传输、计算和匹配的代价低。

子网到子网的路由，就等价于路由器到路由器之间的路由

- 因为到了这个网络的路由器，就等于到了这个网络，至于路由器到子网内的主机之间的通信，主要由数据链路层解决。
- 在一个网络中：路由器-主机之间的通信，链路层解决

将网络的拓扑结构抽象成一张有权图，图的边代表连接两个路由器的点到点底层链路（网络基础设施），边的权值代表路由代价，图的节点代表某个路由器。

- 路由选择算法的输入：源节点、网络的拓扑结构、边的权（路由代价）
- 输出：源节点到**所有**其他节点的最短路径

路由选择算法的原则：

- 正确性(correctness):算法必须是正确的和完整的,使分组一站一站接力，正确发向目标站；完整：目标所有的站地址，在路由表中都能找到相应的表项；没有处理不了的目标站地址；
- 简单性(simplicity)：算法在计算机上应简单：最优但复杂的算法，时间上延迟很大，不实用，不应为了获取路由信息增加很多的通信量；
- 健壮性(robustness)：算法应能适应通信量和网络拓扑的变化：通信量变化，网络拓扑的变化算法能很快适应；不向很拥挤的链路发数据，不向断了的链路发送数据；
- 稳定性(stability)：产生的路由不应该摇摆。
- 公平性(fairness)：对每一个站点都公平。
- 最优性(optimality)：某一个指标的最优，时间上，费用上，等指标，或综合指标；实际上，获取最优的结果代价较高，可以是次优的。

路由算法分为两类：

- 全局的路由算法：上帝视角，每个路由器都有对整个网络拓扑结构（包括边的权）的信息。
  - 链路状态路由算法
- 分布式的路由算法：路由器只知道与它有物理连接关系的邻居路由器，和到相应邻居路由器的代价值。叠代地与邻居交换路由信息、计算路由信息。
  - 距离矢量算法。
- 现在的算法大部分是动态算法，能够根据网络拓扑结构的变化情况来自适应地变化。

### 链路状态算法

应用链路状态路由算法的路由协议：OSPF。

**链路状态路由算法可能存在链路震荡的问题**。

路由协议：

- 各点通过各种渠道获得整个网络拓扑, 网络中所有链路代价等信息（这部分和算法没关系，属于协议和实现）。

- 使用链路状态路由算法,计算本站点到其它站点的最优路径(汇集树),得到路由表。按照此路由表转发分组(datagram方式) 。
  - 严格意义上说不是路由的一个步骤（属于数据平面的事）。分发到输入端口的网络层。



在获取了网络的拓扑结构（图的邻接表和边的权）之后，计算最短路径的算法，就是Dijkstra算法。

当然，为了能够使用Dijkstra算法，首先需要取得上帝视角，获得整个网络的拓扑结构的信息。所以首先要讲的是如何把每个路由器节点变成上帝视角。

我们以网络中某个路由器的视角，来看链路状态路由算法的过程：

第一步：形成上帝视角，获得整个网络的拓扑结构。因为有权图我们习惯于使用带权的邻接表来描述，所以获得整个拓扑结构，实际上就是要构建完整的邻接表。

1. 发现相邻节点,获知对方网络地址。（获取邻接表的某一行）
   - 路由器上电之后,向所有线路（端口）发送HELLO分组。
   - 其它路由器收到HELLO分组,回送应答,在应答分组中,告知自己的名字(全局唯一)
   - 这一步实际上获得了邻接表中与这个路由器对应的那一行（但是不带权）
2. 测量到相邻节点的代价(延迟,开销)。（第一步获取的这一行，每条边的权）
   - 实测法,发送一个分组要求对方立即响应。对方回送一个ECHO分组。通过测量时间可以估算出延迟情况。
   - 这一步给上一步获得的信息补充了权值。
3. 组装一个LS（Link State）分组,描述它到相邻节点的代价情况。
   - 分组中包含：发送者名称、**序号、年龄**。和一个列表。
   - 列表: 给出它相邻节点,和它到相邻节点的延迟（代价，权）
4. 将分组通过扩散的方法发到所有其它路由器。**使用泛洪**，将这一行传递给所有的路由器。
   - 链路状态路由的泛洪是有确认的泛洪。

以上4步让**每个**路由器获得拓扑和边代价。所有的路由器都向全网发送自己的邻接情况，同时也得到除了自己的其他所有路由器的邻接情况，所以可以构建出整个网络的拓扑结构的邻接表。

第二步：通过Dijkstra算法找出最短路径（这才是路由算法）。

- 每个节点独立算出来到其他节点（路由器=网络）的最短路径
- 迭代算法：第k步能够知道本节点到k个其他节点的最短路径

链路状态路由可能存在的问题： 

- 因为所有的路由器都要泛洪自己的链路状态分组，所以可能存在广播风暴的问题。
- 解决方法：使用年龄字段和版本号（序号），年龄类似TTL，减为零的时候就被路由器丢弃。对于来自同一个路由器A的分组，路由器B会记录它转发过的A的链路状态分组的最新版本，遇见老版本的链路状态分组，就不转发。年龄是为了解决序列号的循环使用等等问题，序列号是为了解决广播风暴问题。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230412123500613.png" alt="image-20230412123500613" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230412123511585.png" alt="image-20230412123511585" style="zoom: 80%;" />

### 距离矢量算法

基本思想：各路由器维护一张路由表,结构如图(其它代价)。各路由器与相邻路由器交换路由表，根据获得的路由信息,更新路由表。

从一个路由器的角度出发，我作为一个路由器，收到了来自某个邻居路由器的距离矢量。每个邻居的距离矢量记录了这个邻居到所有他能到达的路由器的代价，我只需要测量我到这个邻居的代价，然后在距离矢量的基础上，加上我到这个邻居的代价，就能知道我到那些与我不相邻的路由器的代价。然后我收到所有邻居的距离矢量，我可以计算出我到达所有其他路由器的代价的最小值，以及他们对应的转发的方向（下一条往哪）。

举个更具体的例子：

- 我是路由器A，我收到了来自路由器X的距离矢量，X声称X到达B需要22ms的代价，而我测量我到达X的代价是10ms，于是我可以计算出目前最小的到达路由器B的路径是转发给X，代价是32ms。
- 然后我又收到了来自Y的距离矢量，它声称它只需要11ms的代价，我到它需要12ms的代价，于是我到达B需要12+11=33ms的代价，大于刚才算出的代价值，因此我不更新。
- 最后我收到了来自Z的距离矢量，它声称它到 达B需要10ms的代价，而我到达Z只需要4ms，于是我到达B的代价是14ms，于是我更新我的路由表：要到达B，下一跳是Z，代价是14ms。

如此下去可以得到一张完整的路由表。同样的，我把我的距离矢量交给他们，让他们也来算他们的路由表。

那么X/Y/Z的路由表又是怎么来的呢？也是通过同样的算法，收到来自他们的邻居的距离矢量，来计算。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413152102679.png" alt="image-20230413152102679" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413153023588.png" alt="image-20230413153023588" style="zoom:80%;" />

再举个例子：注意一下，J本身到达它本身的代价就是0，不要借助距离矢量去算，因为J没有必要借助邻居的路由到达J。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413154047652.png" alt="image-20230413154047652" style="zoom:80%;" />



距离矢量算法，本质上是一个动态规划：它的状态转移方程是递归的。距离矢量算法是迭代式地进步的，不会在一开始就得到最优的路由表，但是通过不断迭代地计算很多次，最终可以收敛到一个实际的最优解。

- **这也是距离矢量算法和链路状态路由法的一个区别：**链路状态路由法，一旦得到整个网络的拓扑结构，就可以算出当前的最优解。
- 是一个异步的算法，每个路由器自己算自己的。

- *Bellman-Ford 方程(动态规划)*
- <img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413154959800.png" alt="image-20230413154959800" style="zoom:67%;" />

触发路由表的下一次迭代的事件：任意一个都会触发迭代

- 本地链路代价变化了（比如我到我的邻居的代价变化了，那我肯定要重新计算路由表）
- 从邻居来了距离矢量的更新消息（毫无疑问要重新计算路由表）
  - 每个节点只是在自己的DV改变之后向邻居通告，然后邻居们在有必要的时候通知他们的邻居。





**距离矢量算法的特点：好消息传得快，坏消息传的慢**。

- 好消息：出现了更短的路径。
- 坏消息：D(istance)V(ector)的无穷计算问题。例子里的无穷计算，路由实际上就是在B和C之间形成了一个环路，永远循环下去。像下面这样，很容易推演，要经过无限多次的计算（所以叫做无穷计算，因为要计算无穷多次，坏消息才能传遍全网），大家才能都认为A是不可达的。
  - AB链路失败，B测量得到其到A的代价是无穷大。**但是收到了C的距离矢量，C吹牛说，你走我这里可以到达A**。于是B就相信了C，把自己到A的代价设置为C到A的代价再加一。其他的节点也有类似的情况
  - 每一次迭代，到A的代价增加1，要增加到无穷大，需要无穷次迭代。

- <img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413155914521.png" alt="image-20230413155914521" style="zoom:80%;" />![image-20230413155931471](https://i.imgur.com/p1x39Ov.png)

无穷计算的解决办法：水平分裂算法

- 我们先来看看出现无穷计算的原因是什么？
  - B收到了来自C的距离矢量，C说它可以到达A，但是并没有说它到达A的方式是要经过B。
  - 也就是说，假如C不借助B的帮助，C是没有办法到达A的，A对于C来说是不可达的。而C在发给B的距离矢量中隐瞒了这一点。
  - 所以解决方法就是，C在发给B的距离矢量中，“骗”B说，A在我这是不可达的。于是B就在这**一次**（而不是无穷多次交换之后）距离矢量的交换下立刻就得到了A不可达的坏消息。那在下一个周期呢？D会在发给C的距离矢量里告诉C，A在D这里不可达，C也就得到了坏消息。
  - 于是坏消息也能以每一次交换就向前一跳的速度向前传播。
- **水平分裂的问题:在某些拓扑形式下会失败（存在环路）**

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413160728206.png" alt="image-20230413160728206" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413161513741.png" alt="image-20230413161513741" style="zoom:80%;" />

### 两种算法的比较

**距离矢量只在两个相邻的路由器之间传播**

**而链路状态的链路状态分组，需要在全网泛洪**。

健壮性上：

由于链路状态路由算法，每个路由器可以得到整个拓扑结构的邻接表，即使有路由器下线了，也很快会反映到邻接表上。

而距离矢量算法则存在无穷计算的问题，所以健壮性上，链路状态路由算法胜出。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413161805774.png" alt="image-20230413161805774" style="zoom:80%;" />

## 自治系统内部的路由选择

实际上互联网上的路由分为两个层面：内部网关协议和外部网关协议

- 内部网关协议：自治区之内的路由选择协议（不是算法，使用的算法都是之前讲过的两种之一）。

内部网关协议分两种：RIP和OSPF，前者基于距离矢量算法，后者基于链路状态算法。



### RIP(Routing Information Protocol)

在BSD-UNIX上实现。

- 以跳数为代价，最高代价是15跳，16跳代表不可达（代价无穷大）。
- 每隔30秒就和邻居相互交换距离矢量（叫路由通告）
- 每个通告最多包含25个目标子网。RIP协议只能用于一个小网自治区内（因为最多25个目标子网以及他们各自的代价）。

触发DV传送的方式有两种：定期的交换，或者收到对方的请求。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413164723696.png" alt="image-20230413164723696" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413164732468.png" alt="image-20230413164732468" style="zoom:80%;" />

如果超过180秒没有收到某个邻居的DV，那么就认为这个邻居失效了，将坏消息传遍全网（水平分裂防止无穷计算）

RIP协议以应用进程（守护进程）的方式实现，使用UDP报文。

**也挺有意思的，RIP协议是给网络层提供支持的，但是它借助了传输层的服务，而传输层又使用了网络层的服务**。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413165347673.png" alt="image-20230413165347673" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413165355212.png" alt="image-20230413165355212" style="zoom:80%;" />

### OSPF(Open Shortest Path First)

开放最短路径优先协议。

“open”: 标准可公开获得。**不同厂商之间生产的路由器可以互操作**。

使用LS算法

- LS 分组在网络中（一个AS内部，注意，**不是全球**，是整个自治系统内部）分发。AS：自治系统
- 全局网络拓扑、代价在每一个节点中都保持
-  路由计算采用Dijkstra算法

OSPF通告信息中携带：每一个邻居路由器一个表项

- 通告信息会传遍AS全部（通过泛洪） 
- 在**IP数据报上**直接传送OSPF报文 (而不是通过UDP和TCP)。**因为是泛洪，所以不需要网络层的路由功能**，所以不存在“我的存在就是为了给网络层的路由提供支持，而我却在提供支持之前就使用了网络层的路由功能”的问题。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413170311862.png" alt="image-20230413170311862" style="zoom:80%;" />



如果自治区比较大，那么OSPF还支持层次化的路由：将整个自治区分成很多个Area，每个Area可以看做是一个较小的子网。

- 骨干路由器负责子网（Area）到（Area）之间的路由。

- 如果需要从一个Area到另外一个Area，那么需要先把分组转发到Area边界上的路由器，然后由他转发给骨干路由器，然后由骨干路由器转发到目标Area。
  - 所以边界路由器扮演了两个角色，一方面要路由Area内部的分组，另外一方面要参与骨干路由器上的分组的路由。
- 如果需要离开这个自治区，前往其他自治区，那么需要把分组先路由到自治区的边界路由器。

好处：限制链路状态分组泛洪的数量和范围，本区域内的链路状态分组只在本区域内泛洪。而假如不分层，要泛洪到其他区域。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413170530667.png" alt="image-20230413170530667" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413170546979.png" alt="image-20230413170546979" style="zoom:80%;" />

## ISP之间的路由选择：BGP

自治区之间的路由选择

自治区：AS，为什么需要有自治区？自治区的必要性是什么？

我们之前讲述的两个路由算法，不管是链路状态路由算法，还是距离矢量算法，都是假定所有的路由器都处于同一个平面，在一个平面解决路由问题。

但是这样的做法在互联网的规模下是行不通的，子网的数量太多，路由器的数量太多，如果在一个平面内解决问题，将全球的互联网作为一个平面，看做一个大网拓扑，来计算路由，计算量太大，数据量太大。而且，你怎么做到把你的链路状态分组全球泛洪，是否代价太大了？

- DV: 距离矢量很大，且不能够收敛（几百万个距离矢量，计算不知道要迭代多少次才能得到最优解）
- LS：几百万个节点的LS分组的泛洪传输，存储以及最短路径算法的计算。最短路径算法的复杂度是可以达到平方的，百万的平方是多大？上万亿

而且还存在一些管理问题：

- 不同的网络所有者希望按照自己的方式管理网络。
- 希望对外隐藏自己网络的细节，不希望外部知道自己的网络拓扑结构。
-  当然，还希望和其它网络互联。

解决问题的办法就是把互联网的路由分成两个层面：自治区内的路由和自治区之间的路由。

- 一个自治区，对外的表现就像一个点。

- 自治区：某个区域内的路由器集合，自治系统“autonomous systems” (AS)
- 一个AS用AS Number（ASN)唯一标示。
- 一个ISP可能包括1个或者多个AS。

一个层面的问题就变成两个层面内的问题：

- 第一个层面：自治区内。自治区内可以采用自己的路由协议和算法，甚至是不标准的路由选择协议都可以。
- 第二个层面：自治区与自治区之间。在这个层面上，每个自治区相当于拓扑结构当中的一个点，或者几个点。这样整个拓扑的规模也不会特别大，能处理得了。第二个层面使用边界网关协议（BGP）

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413190026514.png" alt="image-20230413190026514" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230413190044114.png" alt="image-20230413190044114" style="zoom:80%;" />

### 互联网AS间路由：BGP

只需要宏观层面上了解。

BGP (Border Gateway Protocol): 自治区域间路由协议“事实上的”标准。“将互联网各个AS粘在一起的胶水。

BGP提供给每个AS两个方法：

- eBGP：外部BGP，从相邻的ASes那里获得子网可达信息。还会检测自己内部AS的子网可达信息，然后将自己的子网可达信息转发出去。
- iBGP：内部BGP，将获得的子网可达信息传遍到AS内部的所有路由器。
- 每个网关路由器会将自己通过eBGP收集到的信息转发给与他相邻的AS的网关路由器。
  - 不仅是我自己收集到的我自己的内部AS的可达信息
  - 还有其他网关路由器告诉我的AS可达信息。不光传自己的消息，还传别人的消息。

允许子网向互联网其他网络通告“**我在这里**”

基于距离矢量算法（路径矢量）。不仅仅是距离矢量，还包括到达各个目标网络的详细路径（AS序号的列表）能够避免简单DV算法的路由环路问题。

使用TCP协议交换BGP报文。



## SDN控制平面

留坑

## ICMP没讲！！

# 数据链路层和局域网

## 引论和服务

一般来说，网卡同时集成了物理层和数据链路层。

网络层解决了一个子网如何到达另外一个子网的路由问题。

子网内部，由一个节点（主机或者路由器）到达另外一个相邻节点的问题，是由链路层的点到点传输层功能解决的。

IP层提供的子网到子网（主机到主机）的服务，是基于链路层向网络层提供的点到点的服务建立的。

- 一个分组从某个子网的网关路由器进入这个子网，然后在子网的内部，借助链路层的点到点的传输服务，从入口网关路由器，传输到出口网关路由器，然后从出口网关路由器离开这个子网，进入下一个子网。在下一个子网重复这个过程，直到分组到达目标子网。

IP是在各种各样的物理网络上跑，物理网络的组网形式又有两种：

- 点到点的链路：两个节点通过一条链路连在一起，我通过这条链路就是发给你，你通过这条链路就是发给我。
  - 点到点的链路一般用于广域网，因为距离比较远（上海到北美）。带宽大、距离远（延迟大），带宽延迟积大。
  - 点到点链路的链路层服务实现非常简单，封装和解封装就够了。因为不存在介质访问控制的问题。
  - 不存在介质访问控制的问题，因为就你和我两个节点。

- 多点到多点的链路：比如大伙都连接到一个交换机上，我发的其他人都可以收，其他人发的我也可以收。

  - 一般用于局域网。

  - 存在一个介质访问控制的问题：我发，你也发，那我们的帧在传输介质上会有碰撞，大伙的数据都坏了。所以需要MAC层。
  - 我发的，其他节点是都可以收，但是谁收呢？目标啊，MAC地址。编址的问题。

- 网卡的编址问题：在局域网中每个节点都有自己的网卡负责链路层的工作，每个网卡都需要编址，怎么样标识不同的网卡？

多点连接的建立：通过共享型的介质，或者通过网络交换机。

- 将很多个节点，都连接到同一根同轴电缆上，这样一个节点发送的帧，就可以被所有其他节点都收到。
- 大家通过一个网络交换机连在一起，我发，通过交换机可以让所有节点都收到。



为什么不在多点连接的网络中使用点到点的连接方式把任意两个节点连接起来？

- 因为这样，需要的线路是$\frac{N(N-1)}{2}$条，太多了。所以一般采用交换机或者共享型介质的方式。
- 而使用交换机或者共享型介质，就很自然的会带来一个寻址的问题。



为什么不在广域网中使用多点连接的方式？

- 因为距离远，延迟大，带宽延迟积高，意味着链路上能够同时容纳的帧数极多。
- 传播延迟高，假如北京的节点A一下发了一堆的帧，然后由于传播延迟高，北美的节点B可能没办法及时意识到链路上有其他人在发（第一帧的物理信号没那么快到达B），会认为链路上没有人在发，然后它也发一堆帧（发送的方向和A相同），然后两堆帧碰撞，损失巨大。
- 而采用点到点的连接就没这个问题，专用的链路，一人一个方向，这个方向我用，反方向你用，任意一个方向都只有一个人用。
  - 也就弱化了介质访问控制的功能，不太需要。
- 在点到点的连接下，也就没有寻址的问题，因为这一条链路上就我和你，我发了那不就一定是给你的吗。



一些术语：

- 主机和路由器是节点
- 网桥和交换机也是节点：nodes
- 沿着通信路径,连接个相邻节点通信信道的是链路：links 
  - 分类方式一：有线链路/无线链路
  - 分类方式二：点到点链路/多点连接的链路
  - 局域网，共享性链路
- 帧（Frame）：数据链路层的PDU（协议数据单元），封装了来自网络层的IP分组（IP数据报）
- 数据链路层负责从一个节点通过链路将（帧中的）数据报发送到相邻的物理节点（一个子网内部的2节点）

### 链路层提供的服务

成帧：来了一个分组，我把它加上帧头帧尾，封装成一个帧

- 将数据报封装在帧中，加上帧头、帧尾部。
- 封装和解封装

链路接入：

- 如果采用的是共享性介质，信道接入获得信道访问权
- 在帧头部使用“MAC”（物理）地址来标示源和目的（不同于IP地址）

在（一个网络内）相邻两个节点完成**可靠数据传递**：

- 已经学过了（第三章）
- 在低出错率的链路上（光纤和双绞线电缆）很少使用。
  - 出错率低，没有必要在每一个帧中做差错控制的工作，协议复杂。
  - 没有必要为了那么小的一点点出错的可能性，来付出极大的代价实现被百分之一百的可靠。
    - 因为你没有必要为了一千帧中可能存在的一帧错误帧，而对这一千帧中的每一帧都在发送方缓存，都让接收方发送一千帧的ACK回来，都设置一千个定时器。你付出这么多，仅仅就为了那一千帧中的一帧，值得么？还不如直接把重传这一帧的工作交给源主机的传输层得了。
  - 那万一，真的就那么丢了怎么办？没关系，（源主机的）传输层会负责重传的。
  - 在本层放弃可靠控制的工作，在传输层（TCP）做可靠控制的工作，或者根本就不做可靠控制的工作（UDP）
- 在无线链路经常使用：出错率高。
  - 为什么要在采用无线链路的网络上，链路层做可靠数据传输工作；还要在传输层做端到端的可靠性工作？ 
  - 原因：出错率高，如果在链路层不做差错控制工作，漏出去的错误比较高；到了上层如果需要可靠控制的数据传输代价会很大。
    - 人话：出错了，被丢弃了，如果上一个节点的链路层不重传，那么谁负责重传？只有源端传输层，从源端传输层重传要走的“路”可比从上一个节点的链路层重传多多了，代价大多了。
    - 比如源主机P，一个分组在无线链路的相邻节点A和B之间丢失了，假如A不重传（链路层不做可靠数据传输的工作），那就只能由P重传，代价比从A重传大多了。从源端重发，恢复时间长。
    - 在数据链路层实现可靠数据传输，那么就可以避免从源端重发，丢失的数据可以直接从链路层的上一个节点重传（Local Recovery），恢复比较快。
- 对于出错率低的链路，直接从源端重传丢失的那么几个分组是可以接受的，代价可以忽略不计。但是对于出错率高的链路，从源端重传的代价就极高了。

Q：为什么在链路层和传输层都实现了可靠性?

- 可靠数据传递是一般化的链路层服务。不是所有的链路层都提供这些服务。一个特定的链路层只是提供其中一部分的服务。
- 意思就是，不是所有的链路层的传输协议都实现了可靠数据传输的功能（以太网就没有），TCP不能假定它底下的数据链路层一定是实现了可靠数据传输的，一个TCP的报文段，对应的帧，在链路层可能经过WLAN传输（实现了可靠性），也可能通过以太网传输（没有可靠性），所以TCP必须自己在传输层来操心可靠数据传输的问题。

流量控制：使得相邻的发送和接收方节点的速度匹配

错误检测：

- 差错由信号衰减和噪声引起
- 接收方检测出的错误：
  - 通知发送端进行重传（实现了可靠传输的链路层协议，比如WLAN）
  - 或丢弃帧（未实现可靠数据传输的链路层协议，比如以太网），丢了的帧由传输层重传(TCP)，或者干脆丢了就丢了(UDP)。
- 差错纠正: 接收端检查和纠正bit错误，不通过重传来纠正错误。

半双工和全双工：

- 半双工：链路可以双向传输，但一次只有一个方向。
- 全双工：两个方向可以同时发

### 链路层在哪里实现？

每个主机上，插有若干网卡，每个网卡实现链路层和物理层的功能。路由器可能插多个网卡，每个网卡实现不同链路层协议和相应物理层的功能。

- 主机都可能有多个网卡，比如一个以太网网卡（负责有线网络），一个无线网卡（负责802.11）
- 网卡一般插入在主机的系统总线上，开机自动运行，是软件和硬件的结合体。

发送方: 在帧中封装数据报 ，加上差错控制编码，实现RDT和流量控制功能等。

- 来了一个分组，分组通过系统总线到达网卡（通过网卡驱动）
- 网卡收到分组，封装成帧，借助网卡的物理层功能，将比特流转换成物理信号，传输出去。

接收方：检查有无出错，执行rdt和流量控制功能等。解封装数据报，递交给上层。

- 网卡的物理层，将到来的物理信号还原成比特流，将比特流递交给链路层。
- 链路层，从比特流中辨别帧的开始和结束，将帧取出来。
- 解封装，取出分组，通过总线交给网络层。

任何一个网卡，都可以做发送方或者接收方。

## 差错检测和纠正

错误检测不是100%可靠。协议会漏检一些错误，但是很少。更长的EDC字段可以得到更好的检测和纠正效果

- 奇偶校验

循环冗余检验

- 能够检查出所有的1bit错误
- 能够检查出所有的双bits的错误
- 能够检查出所有长度 =r或者<r 位的错误出现长度为 r+1的突发错误，检查不出的概率是$\frac{1}{2^{r-1}}$
- 出现长度大于r+1的突发错误，检查不出的概率$\frac{1}{2^r}$

## 多路访问协议（介质访问控制层）

两种类型的链路：

- 点到点的链路
  - 拨号访问的PPP
  - 以太网交换机和主机之间的点对点链路
- 多点到多点的链路（又称为广播式的网络，发出去，物理上所有节点都能收到）
  - 传统以太网
  - 802.11无线局域网
- 点到点的链路不存在MAC的问题，多点链路存在。

在多点到多点的链路上，需要介质访问控制协议（MAC协议）来避免节点之间发送的碰撞。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417202814829.png" alt="image-20230417202814829" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417202853407.png" alt="image-20230417202853407" style="zoom:80%;" />



介质访问控制协议分为以下三类：从协议的角度叫MAProtocal，算法的角度叫MAControl，都是一个东西。

1. 信道划分：把信道划分成小片（时间、频率、编码，分配片给每个节点专用
2. 随机访问：信道不划分，允许冲突，冲突后恢复。
3. 依次轮流：节点依次轮流，但是有很多数据传输的节点可以获得较长的信道使用权。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419140129615.png" alt="image-20230419140129615" style="zoom: 80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419140157175.png" alt="image-20230419140157175" style="zoom: 80%;" />

### 信道划分

- 时分复用
- 频分复用
- 码分复用

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417203312900.png" alt="image-20230417203312900" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417203322782.png" alt="image-20230417203322782" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417203335885.png" alt="image-20230417203335885" style="zoom:80%;" />

### 随机访问

当节点有帧要发送时，以**信道带宽的全部 R bps**发送，**没有节点间的预先协调**。

- 有数据就发，全速发。

两个或更多节点同时传输，会发生冲突。

- 协议允许冲突，协议规定：
  - 如何检测冲突
  - 如何从冲突中恢复

随机MAC协议：

- ALOHA
- 时隙ALOHA
- CSMA、CSMA/CA（载波监听多路访问/冲突避免，802.11使用）、CSMA/CD（载波监听多路访问/冲突检测，以太网使用）

#### 时隙ALOHA

时隙ALOHA的假设：

- 所有帧是等长的
- 时间被划分成相等的**时隙**，每个时隙可发送一帧。
- 节点**只能在时隙开始时发送帧**
- 节点在时钟上是同步的。（不然各个节点没办法达成一致的时间槽划分）
- 如果两个或多个节点在一个时隙传输，所有的站点都能检测到冲突。（两个节点发和一个节点发，介质上的信号的能量强度不一样，所以可以检测到）

时隙ALOHA的协议：

- 当节点获取新的帧，在下一个时隙传输：
  - 传输时没有检测到冲突，成功。节点能够在下一时隙发送新帧
  - 检测时如果检测到冲突，失败。节点在每一个随后的时隙以概率p重传帧直到成功。

假设两个节点A和B在同一个时隙的开始同时发，发生冲突。那么在下一个时隙，有四种情况：

- A和B又同时发，再次发生冲突，回归前一个时隙的情况。
- A以概率p随机决定，决定发。B恰好决定不发。如果没有第三个节点要发，那么这次发送A成功。B在后续的下个时隙继续做决定。
- B以概率p随机决定，决定发。A恰好决定不发。如果没有第三个节点要发，那么这次发送B成功。A在后续的下个时隙继续做决定。
- A和B同时决定不发。那么下一个时槽，对于A和B来说就浪费了（如果没有出现第三个节点发送帧）。

缺点：

- 没有办法保证重传之前的等待时间的上限（假如发生碰撞，不能保证在接下来的多少多少时间之内，我一定给你重传成功）。没有兜底，运气不好可能一直决定不重传。或者老跟别人碰撞。没有延迟的保证。
- 需要时钟同步
- 即使刚发送一帧就检测到冲突，也没办法立即停止帧的发送（没办法寸止啊，已经射出来的话就不可能中途停下来了）

优点：

- 传输可以使用全部带宽
- 高度分布式的算法



<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417205200799.png" alt="image-20230417205200799" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417205215381.png" alt="image-20230417205215381" style="zoom:80%;" />

#### 纯ALOHA

**没有时隙**，什么时候有帧要发，下一刻就立刻发出去。发生冲突，那么以概率P重传。

时隙ALOHA要么帧完全碰撞，要么完全不碰撞。而纯ALOHA，两个帧的任意部分可以发生碰撞，一个帧的帧头完全可以和另外一个帧的帧尾发生碰撞（最可惜的情况，因为再晚一点点发送第二帧，两帧就都成功了）

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417205814650.png" alt="image-20230417205814650" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417205823511.png" alt="image-20230417205823511" style="zoom:80%;" />



纯ALOHA都没有做到的一件事：在发言之前，先听听看现在有没有其他人在发言。如果有人发言，那就先不发言。我们能够利用这一点来提高效率。

这就是CS：Carrier Sense，载波监听。

#### CSMA

**CSMA并不能完全避免冲突**。因为每个节点只能监听到它自己脚底下的那一小块传输介质，它没办法监听整个传输介质。

- 监听局部来推测全局。
- 最极端的情况：A和B同时决定发，此时A和B监听信道都认为可以发。

由于信号在传输介质上的传播延迟，可能导致节点可能监听不到正在进行的传输（因为信号还没传播到这个节点的脚下）

举个例子：节点A和节点B之间距离非常长，传输延迟很大，A先发送出去一个帧。过一会B也想发送一个帧，由于信号还没到达B处，B监听到传输介质上没有信号，认为没有其他人说话，于是B就开始说话。



很符合直觉的结论：传播延迟越长，发生冲突的概率就越高。因为时间越长，其他节点发送帧的可能性就越大。



#### CSMA/CD

载波监听多路访问/冲突避免

- CS是事前（发送帧之前监听一下），CD是发送中（边说边听）
- MA是目的：Multiple Access，多路访问。

CD：在发送中边发送边监听，监听到冲突，**立即停止发送**

- 已经检测到冲突了，帧剩下的部分就没必要继续发送了。

- 这也是相对ALOHA的改进。已经射出来的还能寸止停下来。
- 立即停止发送可以让信道立刻空闲下来，让别人有机会发。可以减少对信道的浪费。

CD在有形的传播介质当中还是比较容易做到的，一个节点发和两个节点发，介质上的电磁波的强度明显不一样。

#### 以太网的CSMA/CD算法

网卡获取来自网络层的分组，封装成帧，准备发送：

发送之前，监听信道（CS）：

- 如果信道是闲的，那么直接开始发
- 如果信道是忙的，那么一直等到信道空闲为止，再发。

边发，边做冲突检测（CD）：

- 如果全程没有检测到冲突，那么发送成功
- 检测到冲突：立即停止发送，之后尝试重发。

检测到冲突：除了立即停止发送外，还会发送一个冲突强化信号，防止因为信号衰减导致某些节点忽略了这个冲突。

- 之后，**凡是监听到冲突的节点，都要发送一个Jam信号**，强化冲突信号（类似着火了，发现着火了的每个人都会大喊着火了）。

参与冲突的节点的网卡，接下来进入指数退避状态：

- 二进制指数退避算法。
- 退避时间结束之后，再开始下一次重发的尝试。

二进制指数退避算法：

1. 假设A和B第一次发生碰撞：那么A和B在0和1之间随机选一个值k，连续等待k个单位的时间，然后再开始重新监听信道。
   - A和B都选0，那么立即发生第二次碰撞
   - A和B都选1，那么在1个单位时间后，发生第二次碰撞
   - A选0，B选1，那么A立即尝试发送（开始监听信道，CS），B等待一个单位的时间再CS。
2. 假如A和B连续发生第二次碰撞，那么在{0,1,2,3}中随机选一个值k，连续等待k个单位的时间，然后再重新尝试发送帧。
   - A和B发生碰撞的概率减半
   - 但是A和B的平均来说，等待时间拉长。
3. 假如连续发生第三次碰撞，那么在$[0,2^{3}-1]$之间随机选择一个值k，连续等待k个单位的时间。 
   - A和B都要随机从8个值里选一个。
   - A和B发生冲突的概率进一步降低，但是平均等待时间进一步拉长。
4. 连续第四次碰撞，就在$[0,2^4 -1]$之间随机选一个值。
5. 再次碰撞，窗口翻倍，然后在加倍的窗口之内选择。

6. 封顶为连续10次碰撞，此时有1024个值可选，如果连续发生10次以上的碰撞，可选值的区间都不再变化，固定在$[0,1023]$。

什么时候会发生这么多的连续碰撞？载荷重的时候嘛。

- 载荷比较重的情况下，连续碰撞的次数多，拉长选择区间，降低冲突概率，但是等待时间长
- 载荷比较轻的情况下，连续碰撞次数小，选择区间小，等待时间短，但冲突概率较大。
- 根据载荷自适应的分布式算法，在等待时间和碰撞次数之间取得一个较好的平衡。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417213837100.png" alt="image-20230417213837100" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230417213935186.png" alt="image-20230417213935186" style="zoom:80%;" />

#### CSMA/CA

载波监听多路访问/冲突避免

WLAN有两种模式，有基础设施模式和自组织模式。探讨第一种模式。

- 有基础设施：主机通过无线链路接入到AP（AccessPoint），然后通过AP接入到交换机。
- 自组织模式：没有AP，没有基础设施，节点和节点之间自动成网。

为什么无线网络使用的是冲突避免（CA），而不是冲突检测（CD）？

- 因为冲突检测在无线介质中不好用。
- 无线介质存在信号衰减的问题，而有线网络的传输介质基本上不存在信号衰减的问题。
- 在有线网络中做冲突检测是非常容易的，因为信号可以传输很远而不衰减。
- 在无线网络中，信号的衰减很快。而且无线网络是在开放的空间中传电磁波，来自其他同频段的其他信号干扰比较严重。

CSMA/CA：

- 发之前监听一下，看看别人有没有正在发。有人在发，就先不发。
- 发的时候就全速发送，并且发的过程当中**不做冲突检测**。
  - 以太网当中（CSMA/CD），是边发送边做冲突检测的，一旦检测到冲突，就立刻停止发送，然后二进制指数后退。

为什么无线信道（CSMA/CA）不边发送边做冲突检测？

- 做冲突检测要求发送天线和接收天线同时工作。接收天线负责接收电磁波（检测冲突），发送天线负责发送数据。
- 但是接收天线和发送天线距离非常近（就是同一个人身上的两只手），接收天线接收到的来自它自己的电磁波信号，要远远大于其他人发送的电磁波信号（衰减非常严重）。
- 而且冲突也不等于失败，不冲突也不等于成功。既然是否发生冲突和你是否成功没有关联关系，那你做冲突检测其实也没有意义。
- 结论：一是由于自身信号强于其他人的信号无法做CD，二是由于隐藏终端和暴露终端问题做了CD也没用。

在WLAN当中，发送过程中，不冲突也不等于发送成功（隐藏终端问题），冲突也不一定等于发送失败（暴露终端问题）

- 即，冲突不等于失败，不冲突不等于成功。

为什么？

ABCD四个终端，每个圆圈是其电磁波信号的覆盖范围（电磁波以终端为圆心向四面八方传播，直到衰减到为零构成的圆）

隐藏终端问题：（A和C相互隐藏）

- A向B发送信号，C向B发送，二者的信号在B处发生冲突（两个电磁波叠加）。但是由于A的信号传播不到C，C的信号传播不到A，二者都检测不到对方的电磁波信号，于是在A看来，它边发送边检测冲突，没有检测到冲突。C也如此。但是发送实际上失败了。站在每个发送方的角度看，都没有检测到冲突，但是实际上冲突就是发生了，所以说：（在发送方看来）不冲突，不等于发送成功。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419123525559.png" alt="image-20230419123525559" style="zoom:80%;" />

暴露终端：（B和C相互暴露）

- B向A发送，C向D发送，二者都边发送边检测冲突。由于B的信号恰好可以传播到C，C的信号也恰好可以传播到B。
- 于是站在B或者C的角度看，以他们第一人称的视角看，“我”边发送，边检测冲突，确实检测到了冲突。但是发送实际上成功了。
- 因为A能收到B的数据，D也能收到C的数据，只不过站在B或者C第一人称看，检测到了冲突。所以说冲突也不等于失败。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419124211520.png" alt="image-20230419124211520" style="zoom:80%;" />

CA：冲突避免怎么做？不在事中检测冲突（边发送边检测），而是在事前避免冲突（发送前避免）。

-  你有东西要发送，你在发送前先监听信道。
- 如果信道是忙的，那么你随机选择一个回退值，在信道空闲的时候，每过一个周期，值减一。值减为零的时候，发送东西。
  - **如果信道由空闲又重新变为繁忙，那么在信道忙的这段时间内，冻结回退值。**
- 这时候假如另外一个终端（和你同时）也有东西要发，它也事前监听信道，然后随机选择一个回退值。
- 你俩的回退值总有一个大一个小，回退值小的那个就先获得信道的使用权了，冲突得以避免。

如果检测到信道是空闲的，**也不是立即发送**，而是**再持续监测信道一小段的时间（整个DIFS长）**，如果信道还是保持空闲的状态，那么立即发送整个帧（无冲突检测）。

接收方：如果帧正确，那么监听信道（准备发送ACK）一小段时间（SIFS长），在信道空闲SIFS后发送ACK。

- SIFS的时间是短于DIFS的，因为ACK的优先级更高一点。

**WLAN是做了可靠数据传输工作的！！！！**

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419130124867.png" alt="image-20230419130124867" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419130140545.png" alt="image-20230419130140545" style="zoom:80%;" />

#### IEEE 802.11 MAC 协议: CSMA/CA

CA并不能完全避免冲突：

1. 两个终端可能选择相同的回退值。
2. 两个节点相互隐藏，相互侦听不到对方的信号（隐藏终端问题）

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419131734340.png" alt="image-20230419131734340" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419131749535.png" alt="image-20230419131749535" style="zoom:80%;" />

当然，也可以采用预约（CTS和RTS）：可选项

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419135737355.png" alt="image-20230419135737355" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419135837284.png" alt="image-20230419135837284" style="zoom:80%;" />

### 轮流MAC协议

像时分复用、码分复用这样的信道固定划分的协议，低负载的情况下信道利用率低，高负载的情况下信道利用率高。

像CSMA/CA这样的随机访问协议，低负载的情况下信道利用率高，高负载的情况下冲突多，信道利用率低。

轮流则集成了二者的优点，但是缺点是协议复杂。所以现在也很少用

#### 令牌环

令牌在各个节点之间来回轮转，要发送数据的节点，抓住令牌。

令牌本质上是一个特殊的帧，帧头有标志位来表明这一帧是不是令牌。

要发送数据的节点抓住令牌帧，将数据放入令牌帧的Body部分，然后将令牌标志位置零，将令牌帧变为数据帧。

然后数据帧沿着线路转一圈，被目标节点复制一份（有可能有多个接收方，所以是复制而不是直接拿走），又回到发送方，发送方将这一帧又收回来，然后发送方又抓住了令牌，如果没有数据发了，生成新的令牌放出去。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419142754494.png" alt="image-20230419142754494" style="zoom:80%;" />

#### 轮循（或者位图协议）

有一个中心节点，依次去问每个节点，你有没有数据发？对方回答有，那就让它发，发完再问下一个节点有没有数据发。

缺点：中心化的协议，Master挂了整个系统就挂了。这是网络很忌讳的问题。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419142709420.png" alt="image-20230419142709420" style="zoom:80%;" />

## LANs

MAC地址：用于使帧从一个网卡传递到与其物理连接的另一个网卡(在同一个物理网络中)

- 48bit MAC地址固化在适配器的ROM，有时也可以通过软件设定
- 理论上全球任何2个网卡的MAC地址都不相同
- 用来区分一个物理网络内部的一个网卡和另一个网卡。
- 广播地址：48为全1。

利用网络层的服务做路由转发的时候，每一跳到下一跳，中间处于子网内部，从上一跳的路由器到下一跳的路由器之间要经过很多个节点，跨越这个子网的过程是基于链路层的服务（ARP协议）。

- 从网络层的角度看，从这个路由器到下个路由器，就是一跳。
- 但是从链路层的角度来看，为了达成网络层上的一跳，可能需要链路层上的多次点到点的一跳。

从网络层的某一跳来看，一个分组到达某个路由器，路由器查路由表，决定下一跳发往哪个路由器，该往哪个端口发送，然后发出去。网络层的工作就此结束了。但是在数据链路层看，此时链路层的工作才刚刚开始。

- 上一跳的路由器的网卡拿到下一跳的路由器的IP地址，然后借助ARP协议得到下一跳的路由器的网卡的MAC地址，然后将分组封装成帧发出去。
- 帧在数据链路层的层面上可能会经过很多跳（经过很多交换机和集线器的转发），最终到达下一跳的路由器。此时网络层的一跳完成。

IP地址是分层的，同一个子网的所有主机子网号部分相同，而MAC地址是处于一个平面的，同一个物理网络内部的MAC地址之间并没有什么特殊的关系。

- MAC地址处于同一平面决定了网卡是可以随意移动和更换的，完全可以把网卡从一台机器拔下来插到另外一台机器上去。
- IP则恰恰相反，你不能把处于一个子网的IP移动到另外一个子网去。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419152220765.png" alt="image-20230419152220765" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419152228798.png" alt="image-20230419152228798" style="zoom:80%;" />

### ARP(Address Resolution Protocol)

ARP：地址解析协议。已知某个设备的IP地址，怎样得到它的MAC地址？

在LAN上的每个IP节点（主机或者路由器）都有一个ARP表。

- ARP表：包括一些LAN节点IP/MAC地址的映射：`< IP address; MAC address; TTL>`
- TTL时间是指地址映射失效的时间。典型是20min。
- 因为IP地址是由DHCP协议动态分配的，所以IP地址到MAC地址的映射关系是会变化的，所以要给ARP表的每一项一个有效期。

节点A拿到一个IP地址，想知道这个IP地址对应的设备B的MAC地址：

1. 先查表，表里有就用表里的。
2. 表里没有，发一个MAC地址为全1的数据链路层帧，所有设备都能收到这个帧。设备B的网卡收到这个帧，然后返回一个ARP报文，告知自己的MAC地址。
3. A收到B回应的ARP报文，将B的IP和MAC地址缓存到APR表中，下一次直接查表。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419154032075.png" alt="image-20230419154032075" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419154040950.png" alt="image-20230419154040950" style="zoom:80%;" />

### 路由到其他LAN

举个具体的例子，来讲讲一个网络层的分组是怎样从一个子网路由到另外一个子网的：

左边子网的主机A（一台电脑）要发送一个IP分组给右边子网的主机B（另外一台电脑）：路由器R有左右两个网卡，分别接入两个子网。

MAC地址要么查ARP表，要么使用ARP协议获得。路由器R是两个子网的网关路由器，R的IP使用DHCP协议获得。

1. A创建数据报，源IP地址：A；目标IP地址：B 
2. A创建一个链路层的帧，源MAC地址是A的网卡的MAC地址，目标MAC地址是R左边的网卡的MAC地址，该帧包含A到B的IP数据报。
3. 这个帧经过左边子网的（可能很多个）交换机（不会经过其他主机）的转发，到达R左边的网卡。
4. R左边的网卡收到帧，将其解封装，得到帧的Body部分（一个来自A的IP分组），交给R的网络层。
5. R的网络层查看路由表，决定下一跳该往右边的网卡转发。
6. R右边的网卡收到R的网络层传递下来的分组，将其重新封装成帧（记作帧R）。源MAC地址：R右边网卡的MAC地址。目标MAC地址：B的MAC地址。
   - 源IP和目标IP始终不变
7. 帧R由R右边的网卡发入右边的子网，经过交换机的转发，到达主机B的网卡。主机B的网卡取出帧的Body部分，交给网络层。网络层再取出分组的Body部分，交给传输层。传输层再交给应用层。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419154733628.png" alt="image-20230419154733628" style="zoom:80%;" />

### 以太网

**以太网发送一帧的时间至少要持续$2\tau$**，其中$\tau$是有线链路上相距最远的两个节点AB之间的传输延迟。

- 意思就是说，A如果开始发送帧，那么它发送帧的持续时间至少要等于AB之间的往返延迟。
- 因为最极端的情况下：
  - A发送的帧沿着线路传播，恰好在$\tau$时刻信号到达B
  - 而B在$\tau$之前（非常接近$\tau$的时刻）监听到信道，信道都是空闲，然后B决定发送帧，结果B恰好在$\tau$时刻发出它的信号。
  - 然后A和B的信号就恰好在B处碰撞。碰撞的信号也需要$\tau$的时间从B传播回A。
  - 如果A的帧传输时间少于$2\tau$，那么在冲突信号到达A之前，A就已经结束发送了，A不会继续检测冲突，错过了冲突信号，认为帧发送成功。
- 所以在后续的千兆以太网上，为了让传输一帧的时间不少于$2\tau$，采用了帧突发（将多个短帧级联然后一次发送）和帧填充（将帧填充到临界长度）技术。

以太网是无连接、不可靠的服务。

以太网并不做可靠传输的工作，因为以太网的线缆的错误率很低，没必要去做。

至于出错的帧，校验和没通过的话丢了就丢了，如果这个帧的上层是TCP协议，那么源主机的TCP会负责重传。如果是UDP的话，丢了就丢了，无所谓的。

以太网的MAC协议是CSMA/CD，并且是二进制指数退避的。

以太网有很多种不同的标准（快速以太网、千兆以太网、经典以太网等等），但是他们的MAC协议和帧结构都是相同的。物理层的介质不同。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419164202831.png" alt="image-20230419164202831" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419164621963.png" alt="image-20230419164621963" style="zoom:80%;" />

以太网的物理拓扑的进化历程：总线==>集线器(HUB)==>交换机（Switch）

- 总线：一个物理子网上的所有主机都连接在同一根同轴电缆上，是同一根绳上的蚂蚱。
  - 同一根绳上的蚂蚱处于同一个碰撞域，一次只能有一台主机发。
  - 可靠性差，老鼠咬断了一根电缆，所有主机都没办法发。
- 集线器：一个集线器很多个端口，每台主机通过电缆接入集线器的端口，集线器的端口和端口之间可以级联。
  - 没有缓存，级联的多个集线器之间速率一致。
  - 处于同一个集线器上的主机处于同一个碰撞域，因为集线器是从一个端口收，然后往所有端口发。
    - 这也决定了如果存在级联，那么级联上的所有主机也处于这个碰撞域。
  - 级联：一个集线器上N个端口，集线器A和B上各自连接N-1台主机，剩下一个端口将A和B连接在一起。
    - 集线器B上连接的所有主机和集线器A处于同一个碰撞域。因为A会把帧往AB相连的端口发，然后B再把来自A的帧往它的所有端口发。
  - 好处：老鼠咬不动集线器，咬断哪一根线，哪一台主机。但是如果存在级联的话，如果咬断的是级联连接的线（比如AB），那集线器上的所有主机瘫痪（比如B）。
  - 逻辑上来看，集线器也可以看做是总线型的结构，只需要将集线器看做总线。
- 交换机（有一小节细讲）：改进了集线器的缺陷，一个端口收，不会无脑往所有端口发。使得可以有多个主机并行发送。
  - 交换机更好的一点是，如果每台主机都直接用线缆和交换机的一个端口相连，那么每台主机自己处于一个碰撞域，任意两台主机之间都不存在碰撞的可能性。
  - 于是CSMA/CD在高负载情况下，碰撞率高导致信道利用率低的情况，也基本上被消解了。因为完全不会碰撞。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419161645496.png" alt="image-20230419161645496" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419161654097.png" alt="image-20230419161654097" style="zoom:80%;" />

#### 以太网帧结构

- **每个帧都有前导码**
- 源地址和目标地址都是48比特的MAC地址
  - 三种情况下网卡接收经过它的帧：目标MAC地址全1（广播帧）、目标MAC地址就是它、网卡被设置为**混杂模式**
- type：
- CRC放在载荷部分的后面：用硬件一边发出比特流一边生成，最后发出载荷的最后一个比特的时候，将校验码再插在屁股后面一起发出去就完事了。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419163415028.png" alt="image-20230419163415028" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419163426001.png" alt="image-20230419163426001" style="zoom:80%;" />

### 802.11 WirelessLAN

### Switches

交换机和集线器

#### 集线器

物理上来看是星型的拓扑结构，但是逻辑上来看是总线的结构。

下图左侧的三个级联在一起的集线器，九台主机都处于同一个碰撞域，一次只能有一个节点发送（CSMA/CD）。

速率一致，所以不能把快速以太网和千兆以太网连在一起。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419172000244.png" alt="image-20230419172000244" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419172035456.png" alt="image-20230419172035456" style="zoom:80%;" />

以太网将hub升级为了交换机，解决了Hub的级联碰撞域的问题

#### 交换机

交换机是一个**存储-转发的设备**，它从一个端口收，然后根据帧的目标MAC地址，来决定往哪个端口发，而不是往所有端口发。这样就可以同时并发多个主机往多个端口发。

- 交换机也可以级联。
- 交换机的存在对于主机是透明的。网络层看上去一跳可达，实际上在数据链路层可能要经过很多个交换机。
- 链路层其实解决了网络层最后一跳的问题：到了目标子网，怎么由路由器到达目标主机，靠链路层的转发。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419173050714.png" alt="image-20230419173050714" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419173107985.png" alt="image-20230419173107985" style="zoom:80%;" />

从某个端口来了一个帧，交换机怎么知道该往哪个端口转发？查交换机的交换表。交换表怎么来的？交换机自学习得到的。

- 交换表有三列：MAC地址，端口号，TTL。TTL不多说，因为网络的拓扑结构可能变化，MAC地址和端口号的捆绑会变。
  - 和ARP协议类似，缓存是为了快，TTL是为了适应网络结构的变化。

- 一开始表是空的，主机A从某个端口P发了一个帧到交换机。
- 交换机就反过来知道：嗷，主机A从端口P可达，那我在我的交换表加一项`(MAC_a, P, TTL)`。
  - 查源MAC地址来自学习，查目标MAC地址来转发。
- 就这么自学习。如果来了一个帧，表里不知道该往哪个端口发，那就泛洪这个帧。
- 如果来了一个帧，目标MAC是A，那么查表，交换机往端口P转发。
- 又来一个帧，源MAC是主机B的MAC，端口是P2，那交换机就知道主机B在端口P2可达，交换表加一项`(MAC_B, P2, TTL)`
- **如果源端口和目标端口相同，那么直接丢弃这一帧**

因为交换机是自学习的，所以交换机是即插即用的。

所以交换机的交换流程是这样的：

- 来了一个帧，查看其目标MAC，查表，找到目标端口。
  1. 如果表里找到了目标端口：
     - 如果目标端口和源端口不一样，那么往目标端口转发
     - 如果目标端口和源端口一样，那么丢弃这一帧。这种情况下源主机和目标主机肯定是用集线器相连的，集线器是往所有端口转发的，目标主机肯定已经收到了帧。
  2. 如果表里没找到目标端口：那么泛洪这一帧，往交换机所有端口转发（除了源端口）。
- 查看源MAC，看看是否需要更新交换表（自学习）。

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419173608171.png" alt="image-20230419173608171" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419173617295.png" alt="image-20230419173617295" style="zoom:80%;" />

### 交换机VS路由器

<img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419180543415.png" alt="image-20230419180543415" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/CorneliaStreet1/NewPicBed0/master/image-20230419180558886.png" alt="image-20230419180558886" style="zoom:80%;" />

### 虚拟局域网(VLAN)

有个概念就行了

## 链路虚拟化

本科计网不教



## 数据中心网络

也没讲。

至此我们计算机网络自顶向下的旅程就结束了。接下来以一个Web请求的例子来综述我们学到的所有东西。		
